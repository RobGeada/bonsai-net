{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00B'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from bonsai.data_loaders import load_data\n",
    "from bonsai.net import Net\n",
    "from bonsai.trainers import *\n",
    "from bonsai.helpers import *\n",
    "from bonsai.ops import commons, Zero\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "nas_schedule = {'learn_phase':16,\n",
    "                'prune_phase':16,\n",
    "                'prune_interval':4}\n",
    "hypers = {\n",
    "    'gpu_space':8.25,\n",
    "    'dataset':'CIFAR10',\n",
    "    'classes':10,\n",
    "    'batch_size':64,\n",
    "    'scale':5,\n",
    "    'nodes':4,\n",
    "    'patterns':[['r','n','na'],['n','n','na']],\n",
    "    'half':False,\n",
    "    'multiplier':1,\n",
    "    'lr_schedule':\n",
    "        {'lr_max': .01,\n",
    "         'T': 600},\n",
    "    'drop_prob':.25,\n",
    "    'prune_rate':{'edge':.5,'input':.5}\n",
    "}\n",
    "data, dim = load_data(hypers['batch_size'], hypers['dataset'])\n",
    "hypers['num_patterns']=get_n_patterns(hypers['patterns'], dim, target=2)+1\n",
    "print(hypers['num_patterns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Height/Size Ratios\n",
    "Check how a test model scales under the search params to ensure we don't overfill GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### check out a sample model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================== NETWORK ===========================\n",
      "===================== Oscar Ceylon Babel ======================\n",
      "                     :     Dim      :    Params    :   Comp   \n",
      "Initializer          :              :     160      :          \n",
      "Cell 0  (Normal)     :   32 x 32    :    9,946     :   24.1%  \n",
      "Cell 1  (Normal)     :   32 x 32    :    9,947     :   24.1%  \n",
      "Cell 2  (Normal)     :   32 x 32    :    9,948     :   24.1%  \n",
      "Cell 3  (Normal)     :   32 x 32    :    9,949     :   24.1%  \n",
      " ↳ Aux Tower         :              :   327,690    :          \n",
      "Cell 4  (Normal)     :   32 x 32    :    9,950     :   24.1%  \n",
      "Cell 5  (Normal)     :   32 x 32    :    9,951     :   24.1%  \n",
      "Cell 6  (Normal)     :   32 x 32    :    9,952     :   24.1%  \n",
      " ↳ Aux Tower         :              :   327,690    :          \n",
      "Cell 7  (Reduction)  :   64 x 16    :    32,161    :   24.7%  \n",
      "Cell 8  (Normal)     :   64 x 16    :    33,137    :   25.0%  \n",
      "Cell 9  (Normal)     :   64 x 16    :    33,138    :   25.0%  \n",
      "Cell 10 (Normal)     :   64 x 16    :    33,139    :   25.0%  \n",
      " ↳ Aux Tower         :              :   163,850    :          \n",
      "Cell 11 (Normal)     :   64 x 16    :    33,140    :   25.0%  \n",
      "Cell 12 (Normal)     :   64 x 16    :    33,141    :   25.0%  \n",
      "Cell 13 (Normal)     :   64 x 16    :    33,142    :   25.0%  \n",
      " ↳ Aux Tower         :              :   163,850    :          \n",
      "Cell 14 (Reduction)  :  128 x 8     :   113,448    :   24.1%  \n",
      "Cell 15 (Normal)     :  128 x 8     :   113,459    :   25.0%  \n",
      "Cell 16 (Normal)     :  128 x 8     :   113,460    :   25.0%  \n",
      "Cell 17 (Normal)     :  128 x 8     :   113,461    :   25.0%  \n",
      " ↳ Aux Tower         :              :    81,930    :          \n",
      "Cell 18 (Normal)     :  128 x 8     :   508,747    :  100.0%  \n",
      "Cell 19 (Normal)     :  128 x 8     :   508,748    :  100.0%  \n",
      "Cell 20 (Normal)     :  128 x 8     :   508,749    :  100.0%  \n",
      " ↳ Classifier        :              :    81,930    :          \n",
      "===============================================================\n",
      "Total                :              :  3,427,813   :   25.1%  \n",
      "===============================================================\n",
      "\n",
      "\n",
      "(8.9921875, True)\n"
     ]
    }
   ],
   "source": [
    "print(sp_size_test(hypers['num_patterns']-1,e_c=.25,add_pattern=True,remove_prune=False,print_model=True,**hypers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sizing Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp Ratios: \n",
      "*1->2: 0.353 \n",
      " 2->3: 0.522 \n",
      " 3->4: 0.353 \n",
      " 4->5: 0.269 \n",
      " 5->6: 0.213\n"
     ]
    }
   ],
   "source": [
    "sizes = {}\n",
    "for n in range(1,hypers['num_patterns']):\n",
    "    sizes[n]=[]\n",
    "    remove_prune = False#(n==hypers['num_patterns']['final']-1)\n",
    "    bst=BST(.1,1.)\n",
    "    while bst.answer is None:\n",
    "        print(\"{}: {:.3f}\\r\".format(n,bst.pos),end=\"\")\n",
    "        size = sp_size_test(n,e_c=bst.pos,add_pattern=True,remove_prune=remove_prune,**hypers)\n",
    "        query = not (not size[1] and (size[0])<hypers['gpu_space'])\n",
    "        bst.query(query)\n",
    "    if bst.passes:\n",
    "        sizes[n]=max(bst.passes)\n",
    "\n",
    "if any([v for (k,v) in sizes.items() if v==1]):\n",
    "    start_size = [k for (k,v) in sizes.items() if v==1][-1]+1\n",
    "else:\n",
    "    start_size = 1\n",
    "print(\"Comp Ratios:\",*[\"\\n{}{}->{}: {:.3f}\".format(\" \" if k!=start_size else \"*\",k,k+1,v) for (k,v) in sizes.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: 22.00MiB\n",
      "0: 2.03GiB\n",
      "1: 3.89GiB\n",
      "2: 5.75GiB\n",
      "GP: 5.75GiB\n",
      "Classifier: 5.75GiB\n",
      "=========================== NETWORK ===========================\n",
      "=================== Dutchman Bristol Dailey ===================\n",
      "                     :     Dim      :    Params    :   Comp   \n",
      "Initializer          :              :     160      :          \n",
      "Cell 0  (Normal)     :   32 x 32    :    41,209    :  100.0%  \n",
      "Cell 1  (Normal)     :   32 x 32    :    41,210    :  100.0%  \n",
      "Cell 2  (Normal)     :   32 x 32    :    41,211    :  100.0%  \n",
      " ↳ Classifier        :              :   327,690    :          \n",
      "===============================================================\n",
      "Total                :              :   451,480    :  100.0%  \n",
      "===============================================================\n",
      "\n",
      "Est Size: 5.74GiB \n"
     ]
    }
   ],
   "source": [
    "def jn_print(x,end=\"\\n\"):\n",
    "    print(x,end=end)\n",
    "    with open(\"logs/jn_out.log\",\"a\") as f:\n",
    "        f.write(x+end)\n",
    "          \n",
    "# init model\n",
    "model = Net(dim=dim, \n",
    "            classes=hypers['classes'], \n",
    "            scale=hypers['scale'],\n",
    "            patterns=hypers['patterns'], \n",
    "            num_patterns=start_size,\n",
    "            nodes=hypers['nodes'],\n",
    "            drop_prob=hypers['drop_prob'],\n",
    "            lr_schedule=hypers['lr_schedule'])\n",
    "model.data = data\n",
    "size, overflow = size_test(model, data)\n",
    "print(model)\n",
    "print(\"Est Size: {}{:.2f}GiB {}\".format(\">\" if overflow else \"\", size, \"(overflow)\" if overflow else \"\")) \n",
    "if overflow:\n",
    "    del model\n",
    "    clean('Search init')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-68c79f1cf77a>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-68c79f1cf77a>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(model)rue\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wipe_output()\n",
    "search_start = time.time()\n",
    "\n",
    "# search loop\n",
    "for n in range(start_size,hypers['num_patterns']):\n",
    "    print(\"===\",n,\"===\")\n",
    "    print(model)\n",
    "    finish = False\n",
    "    comp_ratio = sizes.get(n,0)\n",
    "    aim = comp_ratio*.9 if comp_ratio>.35 else comp_ratio*.66\n",
    "    jn_print(\"=== {} Patterns. Target Comp: {:.2f}, Aim: {:.2f}\".format(n, comp_ratio,aim))\n",
    "\n",
    "    for tries in range(1,10):\n",
    "        # try initialization\n",
    "        epochs = (nas_schedule['learn_phase']*(tries==1))+nas_schedule['prune_phase']\n",
    "        comp_lambdas = {'transition': model.lr_scheduler.t+(nas_schedule['prune_phase']*(tries==1)),\n",
    "                        'lambdas': {k:v*tries for k,v in hypers['prune_rate'].items()}}\n",
    "        \n",
    "        #learn+prune\n",
    "        full_train(model, epochs, comp_lambdas=comp_lambdas, comp_ratio=aim, prune_interval=nas_schedule['prune_interval'])\n",
    "        clean(verbose=False)\n",
    "        hard_comp = model.genotype_compression()[1]\n",
    "        if hard_comp and hard_comp > sizes[n]:\n",
    "            jn_print(\"Try {}. Restarting pruning at pattern {}. Target comp: {:.2f}/{:.2f}, Actual: {:.3f}\".format(tries,n,comp_ratio,aim,hard_comp))\n",
    "        else:\n",
    "            finish = True\n",
    "            break\n",
    "\n",
    "    if finish:\n",
    "        if n != hypers['num_patterns']:\n",
    "            print(\"Adding next pattern:\",n+1)\n",
    "            model.add_pattern()\n",
    "    else: \n",
    "        print(\"No progress after 10 tries, aborting.\")\n",
    "        break\n",
    "\n",
    "clean(\"Search End\")\n",
    "print(\"Search Time:\",show_time(time.time()-search_start))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_train(model, epochs=model.lr_scheduler.remaining);\n",
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e_c, i_c = .25, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data, dim =load_data(hypers['batch_size'], hypers['dataset'])\n",
    "model = Net(dim=dim, \n",
    "            classes=hypers['classes'], \n",
    "            scale=hypers['scale'],\n",
    "            num_patterns=hypers['num_patterns'],\n",
    "            patterns=hypers['patterns'],\n",
    "            nodes=hypers['nodes'],\n",
    "            random_ops={'e_c':e_c,'i_c':i_c}, \n",
    "            drop_prob=hypers['drop_prob'],\n",
    "            lr_schedule=hypers['lr_schedule'],\n",
    "            prune=False)\n",
    "model.data = data\n",
    "model.save_genotype()\n",
    "print(model)\n",
    "print(size_test(model, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_train(model, hypers['lr_schedule']['T'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
