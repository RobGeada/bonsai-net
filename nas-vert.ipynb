{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from bonsai.data_loaders import load_data\n",
    "from bonsai.net import Net\n",
    "from bonsai.trainers import *\n",
    "from bonsai.helpers import *\n",
    "from bonsai.ops import commons, Zero\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00B'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_space = 8.5\n",
    "batch_size = 64\n",
    "patterns = [['r','n','na'],['r','n','na'],['r','n','na'],['r',',n','na'],['r','n','na'],['r','n','na'],['n','na']]\n",
    "hypers = {\n",
    "    'dataset':'CIFAR10',\n",
    "    'classes':10,\n",
    "    'scale':5,\n",
    "    'half':False,\n",
    "    'batch_size':batch_size,\n",
    "    'multiplier':1,\n",
    "    'patterns':patterns,\n",
    "    'num_patterns':{'init':1,'final':len(patterns)},\n",
    "    'nodes':4,\n",
    "    'lr_schedule':\n",
    "        {'lr_max': .01,\n",
    "         'T': 600},\n",
    "    'drop_prob':.25,\n",
    "}\n",
    "schedule = {'cycle_len':4,\n",
    "            'transition_after':2,\n",
    "            'n_cycles':4}\n",
    "sizes = {1:1,\n",
    "         2:.95,\n",
    "         3:.775,\n",
    "         4:.6,\n",
    "         5:.275,\n",
    "         6:.475}\n",
    "start_size=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_space = 8\n",
    "batch_size = 2048\n",
    "patterns = [['n','ra']]\n",
    "hypers = {\n",
    "    'dataset':'CIFAR10',\n",
    "    'classes':10,\n",
    "    'scale':1,\n",
    "    'half':False,\n",
    "    'batch_size':batch_size,\n",
    "    'multiplier':1,\n",
    "    'patterns':patterns,\n",
    "    'num_patterns':{'init':1,'final':3},\n",
    "    'nodes':1,\n",
    "    'lr_schedule':\n",
    "        {'lr_max': .01,\n",
    "         'T': 600},\n",
    "    'drop_prob':.25,\n",
    "}\n",
    "schedule = {'cycle_len':2,\n",
    "            'transition_after':1,\n",
    "            'n_cycles':2}\n",
    "sizes = {1:1.,\n",
    "         2:1,\n",
    "         3:1,\n",
    "         4:1,\n",
    "         5:1}\n",
    "start_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Height/Size Ratios\n",
    "Check how a test model scales under the search params to ensure we don't overfill GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.19921875, False)\n",
      "Cleaning at Edge Pruner Removal. Pre: 746.00MiB, Post: 678.00MiB\n",
      "(5.451171875, False)\n",
      "========================== NETWORK ==========================\n",
      "=================== Abyssinia Dhabi Cole ====================\n",
      "                     :     Dim      :   Params   :   Comp   \n",
      "Initializer          :              :    160     :          \n",
      "Cell 0  (Normal)     :   32 x 32    :   21121    :   47.3%  \n",
      "Cell 1  (Normal)     :   32 x 32    :   21122    :   47.3%  \n",
      "Cell 2  (Normal)     :   32 x 32    :   21123    :   47.3%  \n",
      " ↳ Aux Tower         :              :   327690   :          \n",
      "Cell 3  (Reduction)  :   64 x 16    :   70916    :   47.0%  \n",
      "Cell 4  (Normal)     :   64 x 16    :   62661    :   47.0%  \n",
      "Cell 5  (Normal)     :   64 x 16    :   62662    :   47.0%  \n",
      " ↳ Aux Tower         :              :   163850   :          \n",
      "Cell 6  (Reduction)  :  128 x 8     :   256519   :   47.3%  \n",
      "Cell 7  (Normal)     :  128 x 8     :   221320   :   46.4%  \n",
      "Cell 8  (Normal)     :  128 x 8     :   221321   :   46.4%  \n",
      " ↳ Aux Tower         :              :   81930    :          \n",
      "Cell 9  (Reduction)  :  256 x 4     :   840458   :   47.0%  \n",
      "Cell 10 (Normal)     :  256 x 4     :  1109259   :   47.1%  \n",
      "Cell 11 (Normal)     :  256 x 4     :  1109260   :   47.1%  \n",
      " ↳ Aux Tower         :              :   40970    :          \n",
      "Cell 12 (Reduction)  :  512 x 2     :  3244557   :   45.2%  \n",
      "Cell 13 (Normal)     :  512 x 2     :  3255310   :   42.9%  \n",
      "Cell 14 (Normal)     :  512 x 2     :  3255311   :   42.9%  \n",
      " ↳ Aux Tower         :              :   20490    :          \n",
      "Cell 15 (Reduction)  :  1024x 1     :  14903312  :   47.4%  \n",
      "Cell 16 (Normal)     :  1024x 1     :  12802065  :   42.9%  \n",
      "Cell 17 (Normal)     :  1024x 1     :  12802066  :   42.9%  \n",
      " ↳ Aux Tower         :              :   10250    :          \n",
      "Cell 18 (Normal)     :  1024x 1     :  29759563  :  100.0%  \n",
      "Cell 19 (Normal)     :  1024x 1     :  29759564  :  100.0%  \n",
      " ↳ Classifier        :              :   10250    :          \n",
      "=============================================================\n",
      "Total                :              : 114455080  :   49.5%  \n",
      "=============================================================\n",
      "\n",
      "\n",
      "(8.087890625, False)\n"
     ]
    }
   ],
   "source": [
    "#print(sp_size_test(hypers['num_patterns']['final']-1,e_c=.3,remove_prune=True,print_model=True,verbose=True,**hypers))\n",
    "print(sp_size_test(hypers['num_patterns']['final']-1,e_c=.475,add_pattern=True,remove_prune=True,print_model=True,**hypers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp Ratios: \n",
      "1->2: 1.000 \n",
      "2->3: 0.925 \n",
      "3->4: 0.775 \n",
      "4->5: 0.575 \n",
      "5->6: 0.275 \n",
      "6->7: 0.575\n"
     ]
    }
   ],
   "source": [
    "sizes = {}\n",
    "for n in range(hypers['num_patterns']['init'],hypers['num_patterns']['final']):\n",
    "    sizes[n]=[]\n",
    "    remove_prune = (n==hypers['num_patterns']['final']-1)\n",
    "    bst=BST(.2,1.)\n",
    "    while bst.answer is None:\n",
    "        print(\"{}: {:.3f}\\r\".format(n,bst.pos),end=\"\")\n",
    "        size = sp_size_test(n,e_c=bst.pos,add_pattern=True,remove_prune=remove_prune,**hypers)\n",
    "        query = not (not size[1] and (size[0])<gpu_space)\n",
    "        bst.query(query)\n",
    "    sizes[n]=max(bst.passes)\n",
    "\n",
    "if any([v for (k,v) in sizes.items() if v==1]):\n",
    "    start_size = [k for (k,v) in sizes.items() if v==1][-1]+1\n",
    "else:\n",
    "    start_size = hypers['num_patterns']['init']\n",
    "print(\"Comp Ratios:\",*[\"\\n{}->{}: {:.3f}\".format(k,k+1,v) for (k,v) in sizes.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: 26.00MiB\n",
      "0: 2.04GiB\n",
      "1: 3.89GiB\n",
      "2: 5.75GiB\n",
      "Tower 2: 5.75GiB\n",
      "3: 5.87GiB\n",
      "4: 6.42GiB\n",
      "5: 7.28GiB\n",
      "GP: 7.28GiB\n",
      "Classifier: 7.28GiB\n",
      "========================== NETWORK ==========================\n",
      "================= Lancelot Rushmore Alberto =================\n",
      "                     :     Dim      :   Params   :   Comp   \n",
      "Initializer          :              :    160     :          \n",
      "Cell 0  (Normal)     :   32 x 32    :   41209    :  100.0%  \n",
      "Cell 1  (Normal)     :   32 x 32    :   41210    :  100.0%  \n",
      "Cell 2  (Normal)     :   32 x 32    :   41211    :  100.0%  \n",
      " ↳ Aux Tower         :              :   327690   :          \n",
      "Cell 3  (Reduction)  :   64 x 16    :   139708   :  100.0%  \n",
      "Cell 4  (Normal)     :   64 x 16    :   139709   :  100.0%  \n",
      "Cell 5  (Normal)     :   64 x 16    :   139710   :  100.0%  \n",
      " ↳ Classifier        :              :   163850   :          \n",
      "=============================================================\n",
      "Total                :              :  1034457   :  100.0%  \n",
      "=============================================================\n",
      "\n",
      "Est Size: 7.28GiB \n"
     ]
    }
   ],
   "source": [
    "def jn_print(x,end=\"\\n\"):\n",
    "    print(x,end=end)\n",
    "    with open(\"logs/jn_out.log\",\"a\") as f:\n",
    "        f.write(x+end)\n",
    "          \n",
    "# init model\n",
    "data, dim = load_data(hypers['batch_size'], hypers['dataset'])\n",
    "model = Net(dim=dim, \n",
    "            classes=hypers['classes'], \n",
    "            scale=hypers['scale'],\n",
    "            patterns=hypers['patterns'], \n",
    "            num_patterns=start_size,\n",
    "            nodes=hypers['nodes'],\n",
    "            drop_prob=hypers['drop_prob'],\n",
    "            lr_schedule=hypers['lr_schedule'])\n",
    "model.data = data\n",
    "#model.save_genotype()\n",
    "size, overflow = size_test(model, data)\n",
    "print(model)\n",
    "print(\"Est Size: {}{:.2f}GiB {}\".format(\">\" if overflow else \"\", size, \"(overflow)\" if overflow else \"\")) \n",
    "if overflow:\n",
    "    del model\n",
    "    clean('Search init')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 2 ===\n",
      "=== 2 Patterns. Target Comp: 0.93, Aim: 0.83\n",
      "=== Training Lancelot Rushmore Alberto ===\n",
      "Starting at 2019-11-20 12:03:18.437522\n",
      "11/20/2019 12:03 PM\n",
      "Init: 50.00MiB\n",
      "0: 2.04GiB\n",
      "1: 3.90GiB\n",
      "2: 5.75GiB\n",
      "Tower 2: 5.75GiB\n",
      "3: 5.87GiB\n",
      "4: 6.42GiB\n",
      "5: 7.28GiB\n",
      "GP: 7.28GiB\n",
      "Classifier: 7.28GiB\n",
      "Train Epoch: 0   [28864 /50000  (58%)]\tLoss: 1.780, Losses [[]] Per Epoch: 6m,5s  , Alloc: 7.29GiB  \r"
     ]
    }
   ],
   "source": [
    "wipe_output()\n",
    "search_start = time.time()\n",
    "transition = schedule['cycle_len']*schedule['transition_after']\n",
    "rate = {'edge':.5,'input':.5}\n",
    "\n",
    "# search loop\n",
    "for n in range(start_size,hypers['num_patterns']['final']):\n",
    "    print(\"===\",n,\"===\")\n",
    "    finish = False\n",
    "    comp_ratio = sizes.get(n,0)\n",
    "    edge_prune = 1 if n<hypers['num_patterns']['final'] else 0\n",
    "    aim = comp_ratio*.9 if comp_ratio>.35 else comp_ratio*.66\n",
    "    jn_print(\"=== {} Patterns. Target Comp: {:.2f}, Aim: {:.2f}\".format(n, comp_ratio,aim))\n",
    "\n",
    "    for tries in range(1,10):\n",
    "        if tries == 1:\n",
    "            epochs = schedule['cycle_len']*schedule['n_cycles']\n",
    "            comp_lambdas = TransitionDict(\n",
    "                {model.lr_scheduler.t: None, \n",
    "                 model.lr_scheduler.t+transition: {'edge': rate['edge']*edge_prune*tries,\n",
    "                                                   'input': rate['input']*tries}})\n",
    "        else:\n",
    "            epochs = transition\n",
    "            comp_lambdas = TransitionDict(\n",
    "                {model.lr_scheduler.t: {'edge': rate['edge']*edge_prune*tries,\n",
    "                                        'input': rate['input']*tries}})\n",
    "\n",
    "        full_train(model, epochs, comp_lambdas=comp_lambdas, comp_ratio=aim, prune_interval=schedule['cycle_len'])\n",
    "        clean(verbose=False)\n",
    "        hard_comp = model.genotype_compression()[1]\n",
    "        if hard_comp and hard_comp > sizes[n]:\n",
    "            jn_print(\"Try {}. Restarting pruning at pattern {}. Target comp: {:.2f}/{:.2f}, Actual: {:.3f}\".format(tries,n,comp_ratio,aim,hard_comp))\n",
    "        else:\n",
    "            finish = True\n",
    "            break\n",
    "\n",
    "    if 1:#finish:\n",
    "        #model.save_genotype()\n",
    "        clean(\"Pre-add\")\n",
    "        if n == hypers['num_patterns']['final']-1:\n",
    "            print(\"\\tremoving pruners\")\n",
    "            s_c,h_c,i_c = model.genotype_compression()\n",
    "            model.remove_pruners(remove_input=True,remove_edge=True)\n",
    "        if n != hypers['num_patterns']['final']:\n",
    "            print(\"Adding next pattern:\",n+1)\n",
    "            model.add_pattern()\n",
    "    else: \n",
    "        print(\"No progress after 10 tries, aborting.\")\n",
    "        clean()\n",
    "        break\n",
    "\n",
    "clean(\"Search End\")\n",
    "#print(size_test(model,data))\n",
    "print(\"Search Time:\",show_time(time.time()-search_start))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.detail_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_train(model, epochs=model.lr_scheduler.remaining);\n",
    "clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_c,i_c=.25,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dim =load_data(hypers['batch_size'], hypers['dataset'])\n",
    "model = Net(dim=dim, \n",
    "            classes=hypers['classes'], \n",
    "            scale=hypers['scale'],\n",
    "            num_patterns=hypers['num_patterns']['final'],\n",
    "            patterns=hypers['patterns'],\n",
    "            nodes=hypers['nodes'],\n",
    "            random_ops={'e_c':e_c,'i_c':i_c}, \n",
    "            drop_prob=hypers['drop_prob'],\n",
    "            lr_schedule=hypers['lr_schedule'],\n",
    "            prune=False)\n",
    "model.data = data\n",
    "model.save_genotype()\n",
    "print(model)\n",
    "print(size_test(model,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train(model,hypers['lr_schedule']['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
