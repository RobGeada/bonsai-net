{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "\n",
    "search=True\n",
    "\n",
    "from bonsai.data_loaders import load_data\n",
    "from bonsai.net import Net\n",
    "from bonsai.trainers import *\n",
    "from bonsai.helpers import cell_cnx, show_time, namer, TransitionDict, prev_output, wipe_output, mem_stats\n",
    "from bonsai.ops import commons, Zero\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CIFAR10'\n",
    "classes = 10\n",
    "gpu_space = 8.4\n",
    "comp_ratio = 1/4\n",
    "hypers = {\n",
    "    'scale':{'init':2,'final':7},\n",
    "    'batch_size':{'init':256,'final':64},\n",
    "    'reductions':3,\n",
    "    'spacing':5,\n",
    "    'nodes':4,\n",
    "    'lr_schedule':\n",
    "        {'lr_min': 0,\n",
    "         'lr_max': 1e-2,\n",
    "         't_0': 600,\n",
    "         't_mult': 1},\n",
    "    'epochs':600,\n",
    "    'drop_prob':.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges per cell: 24.0\n",
      "===================== NETWORK =====================\n",
      "              Carlton McClure Banbury              \n",
      "Initializer         :                     20 params\n",
      "Cell 0  (Normal)    :  4  x 32 ,       2,017 params\n",
      "Cell 1  (Normal)    :  4  x 32 ,       2,018 params\n",
      "Cell 2  (Normal)    :  4  x 32 ,       2,019 params\n",
      "Cell 3  (Normal)    :  4  x 32 ,       2,020 params\n",
      "Cell 4  (Reduction) :  8  x 32 ,       4,957 params\n",
      " ↳ Aux Tower        :                 20,490 params\n",
      "Cell 5  (Normal)    :  8  x 16 ,       5,078 params\n",
      "Cell 6  (Normal)    :  8  x 16 ,       5,079 params\n",
      "Cell 7  (Normal)    :  8  x 16 ,       5,080 params\n",
      "Cell 8  (Normal)    :  8  x 16 ,       5,081 params\n",
      "Cell 9  (Reduction) :  16 x 16 ,      13,770 params\n",
      " ↳ Aux Tower        :                 10,250 params\n",
      "Cell 10 (Normal)    :  16 x 8  ,      14,403 params\n",
      "Cell 11 (Normal)    :  16 x 8  ,      14,404 params\n",
      "Cell 12 (Normal)    :  16 x 8  ,      14,405 params\n",
      "Cell 13 (Normal)    :  16 x 8  ,      14,406 params\n",
      "Cell 14 (Reduction) :  32 x 8  ,      43,047 params\n",
      " ↳ Aux Tower        :                  5,130 params\n",
      "Classifier          :                  5,130 params\n",
      "===================================================\n",
      "Total               :                188,804 params\n",
      "===================================================\n",
      "\n",
      "Est Size: 7.11GiB \n"
     ]
    }
   ],
   "source": [
    "if search:\n",
    "    if 'model' in globals().keys():\n",
    "        del model\n",
    "        clean(\"Search init\")\n",
    "           \n",
    "    # load date\n",
    "    batch_size= hypers['batch_size']['init']\n",
    "    data, data_shape = load_data(batch_size, dataset)\n",
    "    print(\"Edges per cell:\",cell_cnx(hypers['nodes']))\n",
    "    \n",
    "    # init model\n",
    "    model = Net(dim=data_shape, \n",
    "                classes=classes, \n",
    "                scale=hypers['scale']['init'],\n",
    "                reductions=hypers['reductions'], \n",
    "                spacing=hypers['spacing'],\n",
    "                nodes=hypers['nodes'],\n",
    "                auxiliary=True)\n",
    "    model.save_genotype()\n",
    "    size, overflow = size_test(model, data)\n",
    "    print(model)\n",
    "    print(\"Est Size: {}{:.2f}GiB {}\".format(\">\" if overflow else \"\", size, \"(overflow)\" if overflow else \"\")) \n",
    "    if overflow:\n",
    "        del model\n",
    "        clean('Search init')\n",
    "    \n",
    "    # search params\n",
    "    init_or_finish = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Carlton McClure Banbury ===\n",
      "0: 22.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.60GiB\n",
      "3: 2.37GiB\n",
      "4: 3.13GiB\n",
      "5: 3.54GiB\n",
      "6: 3.99GiB\n",
      "7: 4.44GiB\n",
      "8: 4.88GiB\n",
      "9: 5.33GiB\n",
      "10: 5.62GiB\n",
      "11: 5.93GiB\n",
      "12: 6.24GiB\n",
      "13: 6.56GiB\n",
      "14: 6.88GiB\n",
      "Train Epoch: 0   [15680 /50000  (100%)]\tLoss: 2.384, Losses [0: 1.54, 1: 1.47, 2: 1.52, 3: 1.48]Per Epoch: 3m,25s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 35.39%, 4m,41s\n",
      "Test  Corrects: Top-1: 43.48%, 14.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [15680 /50000  (100%)]\tLoss: 2.351, Losses [0: 1.56, 1: 1.46, 2: 1.5, 3: 1.45]Per Epoch: 3m,44s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 44.17%, 4m,40s\n",
      "Test  Corrects: Top-1: 44.88%, 14.52 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [15680 /50000  (100%)]\tLoss: 2.228, Losses [0: 1.52, 1: 1.47, 2: 1.35, 3: 1.36]Per Epoch: 3m,40s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 47.45%, 4m,37s\n",
      "Test  Corrects: Top-1: 49.06%, 14.23 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [15680 /50000  (100%)]\tLoss: 2.167, Losses [0: 1.48, 1: 1.35, 2: 1.36, 3: 1.33]Per Epoch: 3m,32s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 49.80%, 4m,36s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 188,804 -> 188,804\n",
      "Pre-prune Test  Corrects: Top-1: 51.74%, 14.12 s\n",
      "Post-prune Test  Corrects: Top-1: 51.74%, 14.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [15680 /50000  (100%)]\tLoss: 2.239, Losses [0: 1.57, 1: 1.46, 2: 1.36, 3: 1.36]Per Epoch: 3m,40s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 51.78%, 4m,40s\n",
      "Test  Corrects: Top-1: 52.08%, 14.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [15680 /50000  (100%)]\tLoss: 2.219, Losses [0: 1.6, 1: 1.44, 2: 1.31, 3: 1.35]Per Epoch: 3m,38s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 53.48%, 4m,38s\n",
      "Test  Corrects: Top-1: 51.80%, 14.74 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [15680 /50000  (100%)]\tLoss: 1.947, Losses [0: 1.37, 1: 1.25, 2: 1.21, 3: 1.18]Per Epoch: 3m,39s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 54.90%, 4m,40s\n",
      "Test  Corrects: Top-1: 54.07%, 14.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [15680 /50000  (100%)]\tLoss: 2.000, Losses [0: 1.38, 1: 1.31, 2: 1.27, 3: 1.21]Per Epoch: 3m,48s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 55.74%, 4m,38s\n",
      "\n",
      "Deadheaded 7 operations\n",
      "Param Delta: 188,804 -> 188,797\n",
      "Pre-prune Test  Corrects: Top-1: 57.00%, 14.27 s\n",
      "Post-prune Test  Corrects: Top-1: 56.99%, 14.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [15680 /50000  (100%)]\tComp Ratio: [E: 0.988, I: 7.400], Loss Comp: [C: 2.755, E: 0.429, I: 0.29], Losses [0: 1.61, 1: 1.33, 2: 1.25, 3: 1.2]Per Epoch: 5m,12s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 56.37%, Comp: 0.99, 7.40 6m,0s\n",
      "Train Loss Components: C: 2.755, E: 0.429, I: 0.29\n",
      "Test  Corrects: Top-1: 53.62%, 14.22 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [15680 /50000  (100%)]\tComp Ratio: [E: 0.977, I: 6.400], Loss Comp: [C: 2.900, E: 0.423, I: 0.24], Losses [0: 1.48, 1: 1.45, 2: 1.41, 3: 1.37]Per Epoch: 5m,5s  , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 54.07%, Comp: 0.98, 6.40 5m,57s\n",
      "Train Loss Components: C: 2.900, E: 0.423, I: 0.24\n",
      "Test  Corrects: Top-1: 50.54%, 13.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [15680 /50000  (100%)]\tComp Ratio: [E: 0.971, I: 5.133], Loss Comp: [C: 2.602, E: 0.420, I: 0.20], Losses [0: 1.38, 1: 1.33, 2: 1.17, 3: 1.21]Per Epoch: 4m,47s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 54.96%, Comp: 0.97, 5.13 5m,47s\n",
      "Train Loss Components: C: 2.602, E: 0.420, I: 0.20\n",
      "Test  Corrects: Top-1: 44.27%, 13.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [15680 /50000  (100%)]\tComp Ratio: [E: 0.946, I: 3.933], Loss Comp: [C: 2.583, E: 0.405, I: 0.15], Losses [0: 1.42, 1: 1.3, 2: 1.24, 3: 1.24]Per Epoch: 4m,42s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 56.01%, Comp: 0.95, 3.93 5m,45s\n",
      "Train Loss Components: C: 2.583, E: 0.405, I: 0.15\n",
      "\n",
      "Deadheaded 10 operations\n",
      "Param Delta: 188,797 -> 188,643\n",
      "Pre-prune Test  Corrects: Top-1: 46.26%, 13.77 s\n",
      "Post-prune Test  Corrects: Top-1: 46.26%, 13.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [15680 /50000  (100%)]\tComp Ratio: [E: 0.932, I: 3.467], Loss Comp: [C: 2.457, E: 0.397, I: 0.13], Losses [0: 1.34, 1: 1.23, 2: 1.14, 3: 1.19]Per Epoch: 4m,52s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 57.47%, Comp: 0.93, 3.47 5m,42s\n",
      "Train Loss Components: C: 2.457, E: 0.397, I: 0.13\n",
      "Test  Corrects: Top-1: 40.84%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [15680 /50000  (100%)]\tComp Ratio: [E: 0.917, I: 3.267], Loss Comp: [C: 2.683, E: 0.388, I: 0.12], Losses [0: 1.6, 1: 1.46, 2: 1.32, 3: 1.3]Per Epoch: 4m,31s , Alloc: 7.11GiB   \n",
      "Train Corrects: Top-1: 59.05%, Comp: 0.92, 3.27 5m,43s\n",
      "Train Loss Components: C: 2.683, E: 0.388, I: 0.12\n",
      "Test  Corrects: Top-1: 55.31%, 13.71 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [15680 /50000  (100%)]\tComp Ratio: [E: 0.901, I: 2.933], Loss Comp: [C: 2.383, E: 0.379, I: 0.10], Losses [0: 1.26, 1: 1.25, 2: 1.18, 3: 1.16]Per Epoch: 4m,44s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 60.37%, Comp: 0.90, 2.93 5m,42s\n",
      "Train Loss Components: C: 2.383, E: 0.379, I: 0.10\n",
      "Test  Corrects: Top-1: 54.44%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [15680 /50000  (100%)]\tComp Ratio: [E: 0.893, I: 3.133], Loss Comp: [C: 2.311, E: 0.374, I: 0.11], Losses [0: 1.32, 1: 1.18, 2: 1.12, 3: 1.1]Per Epoch: 4m,32s , Alloc: 7.11GiB  \n",
      "Train Corrects: Top-1: 61.24%, Comp: 0.89, 3.13 5m,44s\n",
      "Train Loss Components: C: 2.311, E: 0.374, I: 0.11\n",
      "\n",
      "Deadheaded 87 operations\n",
      "Param Delta: 188,643 -> 184,924\n",
      "Pre-prune Test  Corrects: Top-1: 53.66%, 13.82 s\n",
      "Post-prune Test  Corrects: Top-1: 53.66%, 13.09 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.248046875, Batch: 256\n",
      "Lowering batch size to 128 for scaling\n",
      "Cleaning at Prescale. Pre: 26.00MiB, Post: 10.00MiB\n",
      "\u001b[31mScaling from 2 to 3\u001b[0m\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 30.00MiB\n",
      "1: 770.00MiB\n",
      "2: 1.49GiB\n",
      "3: 2.20GiB\n",
      "4: 2.90GiB\n",
      "5: 3.31GiB\n",
      "6: 3.70GiB\n",
      "7: 4.07GiB\n",
      "8: 4.46GiB\n",
      "9: 4.87GiB\n",
      "10: 5.13GiB\n",
      "11: 5.38GiB\n",
      "12: 5.62GiB\n",
      "13: 5.80GiB\n",
      "14: 6.07GiB\n",
      "Train Epoch: 0   [31280 /50000  (100%)]\tLoss: 2.284, Losses [0: 1.57, 1: 1.43, 2: 1.39, 3: 1.41]Per Epoch: 6m,39s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 43.14%, 6m,57s\n",
      "Test  Corrects: Top-1: 50.60%, 24.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [31280 /50000  (100%)]\tLoss: 1.631, Losses [0: 1.1, 1: 1.03, 2: 1.0, 3: 1.0]Per Epoch: 6m,24s , Alloc: 6.25GiB    \n",
      "Train Corrects: Top-1: 55.33%, 6m,58s\n",
      "Test  Corrects: Top-1: 57.23%, 24.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [31280 /50000  (100%)]\tLoss: 1.772, Losses [0: 1.24, 1: 1.2, 2: 1.07, 3: 1.07]Per Epoch: 6m,34s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 61.07%, 6m,57s\n",
      "Test  Corrects: Top-1: 56.70%, 23.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [31280 /50000  (100%)]\tLoss: 1.642, Losses [0: 1.13, 1: 0.99, 2: 0.96, 3: 1.02]Per Epoch: 6m,46s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 65.00%, 6m,57s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 527,284 -> 527,284\n",
      "Pre-prune Test  Corrects: Top-1: 67.86%, 23.85 s\n",
      "Post-prune Test  Corrects: Top-1: 67.86%, 24.38 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [31280 /50000  (100%)]\tLoss: 1.540, Losses [0: 1.23, 1: 0.97, 2: 0.87, 3: 0.93]Per Epoch: 6m,51s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 68.19%, 6m,58s\n",
      "Test  Corrects: Top-1: 68.08%, 24.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [31280 /50000  (100%)]\tLoss: 1.885, Losses [0: 1.38, 1: 1.24, 2: 1.09, 3: 1.14]Per Epoch: 6m,20s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 71.08%, 6m,56s\n",
      "Test  Corrects: Top-1: 67.35%, 24.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [31280 /50000  (100%)]\tLoss: 1.393, Losses [0: 1.03, 1: 0.87, 2: 0.83, 3: 0.85]Per Epoch: 6m,24s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 72.79%, 6m,57s\n",
      "Test  Corrects: Top-1: 45.21%, 23.74 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [31280 /50000  (100%)]\tLoss: 1.228, Losses [0: 1.05, 1: 0.76, 2: 0.72, 3: 0.72]Per Epoch: 6m,29s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 74.43%, 6m,57s\n",
      "\n",
      "Deadheaded 96 operations\n",
      "Param Delta: 527,284 -> 520,820\n",
      "Pre-prune Test  Corrects: Top-1: 75.35%, 23.79 s\n",
      "Post-prune Test  Corrects: Top-1: 75.35%, 22.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [31280 /50000  (100%)]\tComp Ratio: [E: 0.799, I: 3.067], Loss Comp: [C: 1.389, E: 0.321, I: 0.11], Losses [0: 0.86, 1: 0.61, 2: 0.58, 3: 0.55]Per Epoch: 8m,9s  , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 75.38%, Comp: 0.80, 3.07 9m,1s\n",
      "Train Loss Components: C: 1.389, E: 0.321, I: 0.11\n",
      "Test  Corrects: Top-1: 75.04%, 22.66 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [31280 /50000  (100%)]\tComp Ratio: [E: 0.651, I: 2.400], Loss Comp: [C: 1.882, E: 0.235, I: 0.09], Losses [0: 1.22, 1: 0.93, 2: 0.86, 3: 0.95]Per Epoch: 8m,41s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 69.56%, Comp: 0.65, 2.40 9m,3s\n",
      "Train Loss Components: C: 1.882, E: 0.235, I: 0.09\n",
      "Test  Corrects: Top-1: 59.28%, 22.60 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [31280 /50000  (100%)]\tComp Ratio: [E: 0.581, I: 2.133], Loss Comp: [C: 1.898, E: 0.198, I: 0.08], Losses [0: 1.25, 1: 1.03, 2: 0.88, 3: 0.99]Per Epoch: 8m,33s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 70.53%, Comp: 0.58, 2.13 9m,4s\n",
      "Train Loss Components: C: 1.898, E: 0.198, I: 0.08\n",
      "Test  Corrects: Top-1: 58.78%, 22.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [31280 /50000  (100%)]\tComp Ratio: [E: 0.543, I: 2.133], Loss Comp: [C: 1.580, E: 0.174, I: 0.08], Losses [0: 1.01, 1: 0.84, 2: 0.72, 3: 0.81]Per Epoch: 8m,26s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 72.30%, Comp: 0.54, 2.13 9m,4s\n",
      "Train Loss Components: C: 1.580, E: 0.174, I: 0.08\n",
      "\n",
      "Deadheaded 24 operations\n",
      "Param Delta: 520,820 -> 519,188\n",
      "Pre-prune Test  Corrects: Top-1: 62.90%, 22.33 s\n",
      "Post-prune Test  Corrects: Top-1: 62.90%, 22.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [31280 /50000  (100%)]\tComp Ratio: [E: 0.552, I: 2.067], Loss Comp: [C: 2.018, E: 0.181, I: 0.08], Losses [0: 1.27, 1: 1.17, 2: 0.98, 3: 1.07]Per Epoch: 8m,23s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 73.75%, Comp: 0.55, 2.07 8m,54s\n",
      "Train Loss Components: C: 2.018, E: 0.181, I: 0.08\n",
      "Test  Corrects: Top-1: 69.94%, 22.28 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [31280 /50000  (100%)]\tComp Ratio: [E: 0.538, I: 2.000], Loss Comp: [C: 1.534, E: 0.173, I: 0.08], Losses [0: 0.9, 1: 0.74, 2: 0.73, 3: 0.81]Per Epoch: 8m,19s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 75.32%, Comp: 0.54, 2.00 8m,54s\n",
      "Train Loss Components: C: 1.534, E: 0.173, I: 0.08\n",
      "Test  Corrects: Top-1: 69.20%, 22.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [31280 /50000  (100%)]\tComp Ratio: [E: 0.518, I: 2.000], Loss Comp: [C: 1.185, E: 0.161, I: 0.08], Losses [0: 1.05, 1: 0.63, 2: 0.52, 3: 0.51]Per Epoch: 8m,37s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 76.93%, Comp: 0.52, 2.00 8m,54s\n",
      "Train Loss Components: C: 1.185, E: 0.161, I: 0.08\n",
      "Test  Corrects: Top-1: 70.40%, 22.10 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [31280 /50000  (100%)]\tComp Ratio: [E: 0.529, I: 2.133], Loss Comp: [C: 1.235, E: 0.167, I: 0.08], Losses [0: 0.87, 1: 0.61, 2: 0.58, 3: 0.58]Per Epoch: 8m,10s , Alloc: 6.25GiB  \n",
      "Train Corrects: Top-1: 78.12%, Comp: 0.53, 2.13 8m,54s\n",
      "Train Loss Components: C: 1.235, E: 0.167, I: 0.08\n",
      "\n",
      "Deadheaded 205 operations\n",
      "Param Delta: 519,188 -> 451,543\n",
      "Pre-prune Test  Corrects: Top-1: 73.33%, 22.05 s\n",
      "Post-prune Test  Corrects: Top-1: 73.33%, 17.62 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.525390625, Batch: 128\n",
      "Lowering batch size to 64 for scaling\n",
      "Cleaning at Prescale. Pre: 38.00MiB, Post: 22.00MiB\n",
      "\u001b[31mScaling from 3 to 4\u001b[0m\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 42.00MiB\n",
      "1: 682.00MiB\n",
      "2: 1.19GiB\n",
      "3: 1.72GiB\n",
      "4: 2.33GiB\n",
      "5: 2.68GiB\n",
      "6: 2.95GiB\n",
      "7: 3.17GiB\n",
      "8: 3.44GiB\n",
      "9: 3.69GiB\n",
      "10: 3.88GiB\n",
      "11: 4.01GiB\n",
      "12: 4.13GiB\n",
      "13: 4.21GiB\n",
      "14: 4.40GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.500, Losses [0: 1.5, 1: 1.16, 2: 1.04, 3: 1.76]Per Epoch: 8m,33s , Alloc: 4.54GiB  \n",
      "Train Corrects: Top-1: 45.00%, 8m,53s\n",
      "Test  Corrects: Top-1: 51.70%, 32.14 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.793, Losses [0: 1.39, 1: 0.93, 2: 0.89, 3: 1.15]Per Epoch: 9m,6s  , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 60.36%, 8m,55s\n",
      "Test  Corrects: Top-1: 63.03%, 31.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 0.908, Losses [0: 1.04, 1: 0.52, 2: 0.49, 3: 0.5]Per Epoch: 8m,21s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 67.87%, 8m,56s\n",
      "Test  Corrects: Top-1: 68.67%, 32.16 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.223, Losses [0: 0.79, 1: 0.52, 2: 0.51, 3: 0.86]Per Epoch: 8m,45s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 71.60%, 8m,57s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 1,441,615 -> 1,441,615\n",
      "Pre-prune Test  Corrects: Top-1: 73.58%, 32.02 s\n",
      "Post-prune Test  Corrects: Top-1: 73.58%, 32.66 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.311, Losses [0: 1.3, 1: 0.89, 2: 0.66, 3: 0.74]Per Epoch: 9m,0s  , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 75.13%, 8m,59s\n",
      "Test  Corrects: Top-1: 78.76%, 32.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.730, Losses [0: 0.86, 1: 0.46, 2: 0.41, 3: 0.38]Per Epoch: 8m,32s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 78.42%, 8m,57s\n",
      "Test  Corrects: Top-1: 80.02%, 31.98 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.064, Losses [0: 0.84, 1: 0.7, 2: 0.54, 3: 0.65]Per Epoch: 8m,33s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 80.70%, 8m,57s\n",
      "Test  Corrects: Top-1: 82.37%, 32.02 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.739, Losses [0: 0.7, 1: 0.47, 2: 0.42, 3: 0.42]Per Epoch: 9m,9s  , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 82.35%, 8m,56s\n",
      "\n",
      "Deadheaded 42 operations\n",
      "Param Delta: 1,441,615 -> 1,407,909\n",
      "Pre-prune Test  Corrects: Top-1: 83.86%, 32.01 s\n",
      "Post-prune Test  Corrects: Top-1: 83.86%, 30.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.518, I: 2.200], Loss Comp: [C: 1.022, E: 0.161, I: 0.08], Losses [0: 0.85, 1: 0.56, 2: 0.43, 3: 0.41]Per Epoch: 10m,56s, Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 83.19%, Comp: 0.52, 2.20 12m,1s\n",
      "Train Loss Components: C: 1.976, E: 0.161, I: 0.08\n",
      "Test  Corrects: Top-1: 82.51%, 30.58 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.481, I: 1.867], Loss Comp: [C: 2.326, E: 0.139, I: 0.07], Losses [0: 1.77, 1: 1.39, 2: 1.04, 3: 1.27]Per Epoch: 12m,7s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 72.12%, Comp: 0.48, 1.87 12m,1s\n",
      "Train Loss Components: C: 9.252, E: 0.138, I: 0.07\n",
      "Test  Corrects: Top-1: 54.18%, 31.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.473, I: 1.933], Loss Comp: [C: 1.802, E: 0.135, I: 0.08], Losses [0: 1.42, 1: 1.1, 2: 0.81, 3: 0.92]Per Epoch: 11m,18s, Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 68.34%, Comp: 0.47, 1.93 12m,2s\n",
      "Train Loss Components: C: 0.967, E: 0.133, I: 0.08\n",
      "Test  Corrects: Top-1: 71.85%, 30.74 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.460, I: 2.000], Loss Comp: [C: 1.802, E: 0.132, I: 0.08], Losses [0: 1.17, 1: 0.91, 2: 0.72, 3: 1.03]Per Epoch: 11m,35s, Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 76.37%, Comp: 0.46, 2.00 12m,1s\n",
      "Train Loss Components: C: 1.684, E: 0.132, I: 0.08\n",
      "\n",
      "Deadheaded 6 operations\n",
      "Param Delta: 1,407,909 -> 1,407,519\n",
      "Pre-prune Test  Corrects: Top-1: 74.65%, 30.35 s\n",
      "Post-prune Test  Corrects: Top-1: 74.65%, 30.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.455, I: 1.800], Loss Comp: [C: 1.297, E: 0.126, I: 0.07], Losses [0: 1.27, 1: 0.69, 2: 0.55, 3: 0.59]Per Epoch: 11m,26s, Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 78.74%, Comp: 0.45, 1.73 11m,56s\n",
      "Train Loss Components: C: 1.337, E: 0.126, I: 0.07\n",
      "Test  Corrects: Top-1: 74.08%, 30.55 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.456, I: 1.933], Loss Comp: [C: 1.217, E: 0.128, I: 0.08], Losses [0: 1.4, 1: 0.65, 2: 0.51, 3: 0.5]Per Epoch: 11m,45s, Alloc: 4.92GiB   \n",
      "Train Corrects: Top-1: 80.77%, Comp: 0.46, 1.93 11m,57s\n",
      "Train Loss Components: C: 1.142, E: 0.127, I: 0.08\n",
      "Test  Corrects: Top-1: 80.78%, 30.66 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.450, I: 1.733], Loss Comp: [C: 1.235, E: 0.123, I: 0.07], Losses [0: 1.17, 1: 0.74, 2: 0.56, 3: 0.54]Per Epoch: 11m,23s, Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 82.86%, Comp: 0.45, 1.73 11m,57s\n",
      "Train Loss Components: C: 0.540, E: 0.125, I: 0.07\n",
      "Test  Corrects: Top-1: 82.07%, 30.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.450, I: 1.800], Loss Comp: [C: 0.748, E: 0.123, I: 0.07], Losses [0: 0.75, 1: 0.41, 2: 0.28, 3: 0.26]Per Epoch: 12m,9s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 84.18%, Comp: 0.45, 1.80 11m,56s\n",
      "Train Loss Components: C: 1.538, E: 0.124, I: 0.07\n",
      "\n",
      "Deadheaded 46 operations\n",
      "Param Delta: 1,407,519 -> 1,319,505\n",
      "Pre-prune Test  Corrects: Top-1: 78.27%, 30.39 s\n",
      "Post-prune Test  Corrects: Top-1: 78.27%, 28.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 3.9453125, Batch: 64\n",
      "Cleaning at Prescale. Pre: 26.00MiB, Post: 26.00MiB\n",
      "\u001b[31mScaling from 4 to 5\u001b[0m\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 46.00MiB\n",
      "1: 1.48GiB\n",
      "2: 2.73GiB\n",
      "3: 3.82GiB\n",
      "4: 5.01GiB\n",
      "5: 5.11GiB\n",
      "6: 5.13GiB\n",
      "7: 5.51GiB\n",
      "8: 5.94GiB\n",
      "9: 6.35GiB\n",
      "10: 6.74GiB\n",
      "11: 6.97GiB\n",
      "12: 7.16GiB\n",
      "13: 7.34GiB\n",
      "14: 7.64GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 8.644, Losses [0: 2.66, 1: 1.89, 2: 2.41, 3: 7.25]Per Epoch: 8m,16s , Alloc: 7.92GiB  \n",
      "Train Corrects: Top-1: 37.36%, 8m,27s\n",
      "Test  Corrects: Top-1: 49.52%, 28.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 4.095, Losses [0: 3.59, 1: 2.22, 2: 1.79, 3: 2.58]Per Epoch: 7m,53s , Alloc: 8.61GiB   \n",
      "Train Corrects: Top-1: 45.47%, 8m,26s\n",
      "Test  Corrects: Top-1: 39.58%, 27.79 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 4.535, Losses [0: 2.71, 1: 1.71, 2: 1.43, 3: 3.36]Per Epoch: 8m,17s , Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 48.25%, 8m,28s\n",
      "Test  Corrects: Top-1: 54.26%, 27.67 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 3.109, Losses [0: 2.0, 1: 1.36, 2: 0.99, 3: 2.24]Per Epoch: 8m,4s  , Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 53.53%, 8m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,592,246 -> 4,592,246\n",
      "Pre-prune Test  Corrects: Top-1: 56.81%, 28.26 s\n",
      "Post-prune Test  Corrects: Top-1: 56.81%, 28.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.591, Losses [0: 1.82, 1: 1.27, 2: 1.03, 3: 1.77]Per Epoch: 8m,5s  , Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 61.92%, 8m,28s\n",
      "Test  Corrects: Top-1: 65.64%, 27.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.553, Losses [0: 1.32, 1: 1.07, 2: 0.81, 3: 0.91]Per Epoch: 8m,6s  , Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 67.69%, 8m,29s\n",
      "Test  Corrects: Top-1: 67.22%, 27.77 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.393, Losses [0: 1.2, 1: 0.83, 2: 0.63, 3: 0.86]Per Epoch: 8m,45s , Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 71.81%, 8m,28s\n",
      "Test  Corrects: Top-1: 74.55%, 27.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.854, Losses [0: 0.72, 1: 0.59, 2: 0.45, 3: 0.5]Per Epoch: 8m,0s  , Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 75.28%, 8m,28s\n",
      "\n",
      "Deadheaded 42 operations\n",
      "Param Delta: 4,592,246 -> 4,329,868\n",
      "Pre-prune Test  Corrects: Top-1: 75.75%, 28.19 s\n",
      "Post-prune Test  Corrects: Top-1: 75.75%, 26.62 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.431, I: 1.667], Loss Comp: [C: 1.138, E: 0.113, I: 0.07], Losses [0: 0.8, 1: 0.75, 2: 0.55, 3: 0.53]Per Epoch: 10m,35s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 77.07%, Comp: 0.43, 1.67 10m,56s\n",
      "Train Loss Components: C: 0.902, E: 0.114, I: 0.07\n",
      "Test  Corrects: Top-1: 78.63%, 26.94 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.414, I: 1.667], Loss Comp: [C: 2.922, E: 0.104, I: 0.07], Losses [0: 1.51, 1: 1.13, 2: 0.91, 3: 2.04]Per Epoch: 10m,55s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 63.53%, Comp: 0.42, 1.67 10m,58s\n",
      "Train Loss Components: C: 1.488, E: 0.104, I: 0.07\n",
      "Test  Corrects: Top-1: 66.51%, 26.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.411, I: 1.600], Loss Comp: [C: 1.996, E: 0.099, I: 0.07], Losses [0: 2.08, 1: 1.29, 2: 0.63, 3: 1.03]Per Epoch: 10m,50s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 65.77%, Comp: 0.41, 1.60 10m,59s\n",
      "Train Loss Components: C: 3.877, E: 0.099, I: 0.07\n",
      "Test  Corrects: Top-1: 67.72%, 26.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.399, I: 1.600], Loss Comp: [C: 2.006, E: 0.095, I: 0.07], Losses [0: 1.49, 1: 1.06, 2: 0.74, 3: 1.18]Per Epoch: 10m,47s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 69.09%, Comp: 0.40, 1.67 10m,58s\n",
      "Train Loss Components: C: 2.229, E: 0.095, I: 0.07\n",
      "\n",
      "Deadheaded 3 operations\n",
      "Param Delta: 4,329,868 -> 4,157,481\n",
      "Pre-prune Test  Corrects: Top-1: 72.62%, 26.97 s\n",
      "Post-prune Test  Corrects: Top-1: 72.62%, 26.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.398, I: 1.667], Loss Comp: [C: 1.276, E: 0.093, I: 0.07], Losses [0: 1.06, 1: 0.94, 2: 0.49, 3: 0.61]Per Epoch: 10m,49s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 72.56%, Comp: 0.40, 1.67 10m,53s\n",
      "Train Loss Components: C: 2.474, E: 0.093, I: 0.07\n",
      "Test  Corrects: Top-1: 74.17%, 26.70 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.396, I: 1.667], Loss Comp: [C: 1.373, E: 0.093, I: 0.07], Losses [0: 0.97, 1: 0.75, 2: 0.56, 3: 0.75]Per Epoch: 10m,49s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 76.48%, Comp: 0.40, 1.67 10m,56s\n",
      "Train Loss Components: C: 1.774, E: 0.092, I: 0.07\n",
      "Test  Corrects: Top-1: 77.59%, 26.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.390, I: 1.667], Loss Comp: [C: 1.270, E: 0.090, I: 0.07], Losses [0: 1.04, 1: 0.7, 2: 0.57, 3: 0.65]Per Epoch: 10m,36s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 79.37%, Comp: 0.39, 1.67 10m,55s\n",
      "Train Loss Components: C: 1.509, E: 0.091, I: 0.07\n",
      "Test  Corrects: Top-1: 76.68%, 26.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.387, I: 1.600], Loss Comp: [C: 1.355, E: 0.088, I: 0.07], Losses [0: 0.81, 1: 0.84, 2: 0.65, 3: 0.74]Per Epoch: 10m,21s, Alloc: 8.61GiB  \n",
      "Train Corrects: Top-1: 81.11%, Comp: 0.39, 1.60 10m,55s\n",
      "Train Loss Components: C: 0.606, E: 0.089, I: 0.07\n",
      "\n",
      "Deadheaded 20 operations\n",
      "Param Delta: 4,157,481 -> 3,940,501\n",
      "Pre-prune Test  Corrects: Top-1: 81.82%, 26.43 s\n",
      "Post-prune Test  Corrects: Top-1: 81.82%, 25.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.224609375, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.1875\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 1.35GiB\n",
      "2: 2.50GiB\n",
      "3: 3.57GiB\n",
      "4: 4.74GiB\n",
      "5: 4.82GiB\n",
      "6: 4.82GiB\n",
      "7: 5.15GiB\n",
      "8: 5.56GiB\n",
      "9: 5.89GiB\n",
      "10: 6.24GiB\n",
      "11: 6.41GiB\n",
      "12: 6.57GiB\n",
      "13: 6.76GiB\n",
      "14: 7.01GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.757, Losses [0: 1.97, 1: 1.43, 2: 0.78, 3: 0.92]Per Epoch: 7m,19s , Alloc: 7.27GiB  \n",
      "Train Corrects: Top-1: 70.64%, 7m,40s\n",
      "Test  Corrects: Top-1: 74.23%, 25.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.562, Losses [0: 1.98, 1: 1.14, 2: 0.7, 3: 1.8]Per Epoch: 7m,18s , Alloc: 7.89GiB   \n",
      "Train Corrects: Top-1: 70.46%, 7m,42s\n",
      "Test  Corrects: Top-1: 60.38%, 25.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 5.244, Losses [0: 2.08, 1: 1.43, 2: 1.22, 3: 4.3]Per Epoch: 7m,29s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 68.31%, 7m,42s\n",
      "Test  Corrects: Top-1: 62.32%, 25.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 3.510, Losses [0: 2.17, 1: 1.13, 2: 0.86, 3: 2.68]Per Epoch: 7m,39s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 62.27%, 7m,41s\n",
      "\n",
      "Deadheaded 3 operations\n",
      "Param Delta: 3,940,501 -> 3,937,746\n",
      "Pre-prune Test  Corrects: Top-1: 69.10%, 25.27 s\n",
      "Post-prune Test  Corrects: Top-1: 69.10%, 25.38 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.701, Losses [0: 2.55, 1: 1.58, 2: 0.76, 3: 1.72]Per Epoch: 8m,11s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 71.39%, 7m,39s\n",
      "Test  Corrects: Top-1: 74.84%, 25.11 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.849, Losses [0: 1.75, 1: 1.22, 2: 0.62, 3: 1.13]Per Epoch: 7m,19s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 76.43%, 7m,43s\n",
      "Test  Corrects: Top-1: 77.24%, 26.64 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.212, Losses [0: 1.3, 1: 0.8, 2: 0.49, 3: 0.69]Per Epoch: 7m,34s , Alloc: 7.89GiB   \n",
      "Train Corrects: Top-1: 79.16%, 7m,49s\n",
      "Test  Corrects: Top-1: 82.42%, 26.00 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.818, Losses [0: 0.68, 1: 0.77, 2: 0.39, 3: 0.45]Per Epoch: 7m,33s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 81.80%, 7m,39s\n",
      "\n",
      "Deadheaded 17 operations\n",
      "Param Delta: 3,937,746 -> 3,885,921\n",
      "Pre-prune Test  Corrects: Top-1: 83.45%, 25.06 s\n",
      "Post-prune Test  Corrects: Top-1: 83.45%, 24.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.387, I: 1.533], Loss Comp: [C: 1.389, E: 0.242, I: 0.13], Losses [0: 0.91, 1: 0.75, 2: 0.56, 3: 0.57]Per Epoch: 9m,37s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 83.37%, Comp: 0.39, 1.53 10m,1s\n",
      "Train Loss Components: C: 0.900, E: 0.244, I: 0.13\n",
      "Test  Corrects: Top-1: 84.28%, 24.68 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.374, I: 1.600], Loss Comp: [C: 3.419, E: 0.228, I: 0.14], Losses [0: 2.0, 1: 1.17, 2: 0.61, 3: 2.3]Per Epoch: 10m,5s , Alloc: 7.89GiB   \n",
      "Train Corrects: Top-1: 73.60%, Comp: 0.38, 1.60 10m,2s\n",
      "Train Loss Components: C: 3.286, E: 0.231, I: 0.14\n",
      "Test  Corrects: Top-1: 75.58%, 24.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.360, I: 1.600], Loss Comp: [C: 2.580, E: 0.214, I: 0.14], Losses [0: 2.21, 1: 1.4, 2: 0.74, 3: 1.36]Per Epoch: 9m,55s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 74.62%, Comp: 0.36, 1.60 10m,2s\n",
      "Train Loss Components: C: 1.770, E: 0.214, I: 0.14\n",
      "Test  Corrects: Top-1: 78.25%, 24.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.362, I: 1.467], Loss Comp: [C: 3.011, E: 0.215, I: 0.12], Losses [0: 1.62, 1: 1.06, 2: 0.77, 3: 1.98]Per Epoch: 9m,57s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 75.45%, Comp: 0.36, 1.40 10m,2s\n",
      "Train Loss Components: C: 2.835, E: 0.216, I: 0.12\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 3,885,921 -> 3,880,415\n",
      "Pre-prune Test  Corrects: Top-1: 76.30%, 24.52 s\n",
      "Post-prune Test  Corrects: Top-1: 76.30%, 24.10 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.360, I: 1.467], Loss Comp: [C: 1.607, E: 0.214, I: 0.12], Losses [0: 2.03, 1: 1.07, 2: 0.44, 3: 0.56]Per Epoch: 9m,35s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 78.20%, Comp: 0.36, 1.47 9m,56s\n",
      "Train Loss Components: C: 2.762, E: 0.214, I: 0.12\n",
      "Test  Corrects: Top-1: 78.22%, 24.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.351, I: 1.467], Loss Comp: [C: 1.719, E: 0.202, I: 0.12], Losses [0: 1.17, 1: 0.91, 2: 0.65, 3: 0.85]Per Epoch: 9m,50s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 81.73%, Comp: 0.35, 1.47 9m,57s\n",
      "Train Loss Components: C: 1.502, E: 0.204, I: 0.12\n",
      "Test  Corrects: Top-1: 80.81%, 24.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.351, I: 1.533], Loss Comp: [C: 1.065, E: 0.206, I: 0.12], Losses [0: 0.75, 1: 0.57, 2: 0.36, 3: 0.4]Per Epoch: 9m,43s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 84.02%, Comp: 0.35, 1.53 9m,58s\n",
      "Train Loss Components: C: 1.413, E: 0.203, I: 0.12\n",
      "Test  Corrects: Top-1: 83.28%, 24.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.348, I: 1.533], Loss Comp: [C: 1.217, E: 0.200, I: 0.12], Losses [0: 0.82, 1: 0.64, 2: 0.49, 3: 0.5]Per Epoch: 9m,50s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 85.56%, Comp: 0.35, 1.53 9m,58s\n",
      "Train Loss Components: C: 0.470, E: 0.200, I: 0.12\n",
      "\n",
      "Deadheaded 20 operations\n",
      "Param Delta: 3,880,415 -> 3,687,115\n",
      "Pre-prune Test  Corrects: Top-1: 83.80%, 24.32 s\n",
      "Post-prune Test  Corrects: Top-1: 83.80%, 23.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.341796875, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.140625\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 1.21GiB\n",
      "2: 2.10GiB\n",
      "3: 3.09GiB\n",
      "4: 4.12GiB\n",
      "5: 4.20GiB\n",
      "6: 4.26GiB\n",
      "7: 4.55GiB\n",
      "8: 4.87GiB\n",
      "9: 5.13GiB\n",
      "10: 5.40GiB\n",
      "11: 5.59GiB\n",
      "12: 5.75GiB\n",
      "13: 5.88GiB\n",
      "14: 6.15GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.128, Losses [0: 2.56, 1: 1.03, 2: 0.59, 3: 1.29]Per Epoch: 6m,57s , Alloc: 6.38GiB  \n",
      "Train Corrects: Top-1: 76.39%, 6m,50s\n",
      "Test  Corrects: Top-1: 70.99%, 23.26 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.503, Losses [0: 1.58, 1: 0.8, 2: 0.5, 3: 0.93]Per Epoch: 6m,45s , Alloc: 6.93GiB   \n",
      "Train Corrects: Top-1: 74.37%, 6m,51s\n",
      "Test  Corrects: Top-1: 76.97%, 23.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.273, Losses [0: 2.03, 1: 0.97, 2: 0.4, 3: 0.59]Per Epoch: 6m,51s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 77.13%, 6m,52s\n",
      "Test  Corrects: Top-1: 73.17%, 23.49 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.220, Losses [0: 1.24, 1: 0.82, 2: 0.57, 3: 0.69]Per Epoch: 6m,34s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 80.05%, 6m,52s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 3,687,115 -> 3,677,514\n",
      "Pre-prune Test  Corrects: Top-1: 83.14%, 23.63 s\n",
      "Post-prune Test  Corrects: Top-1: 83.14%, 23.64 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.586, Losses [0: 1.51, 1: 1.14, 2: 0.72, 3: 0.91]Per Epoch: 6m,38s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 81.02%, 6m,50s\n",
      "Test  Corrects: Top-1: 83.32%, 23.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.222, Losses [0: 1.37, 1: 0.89, 2: 0.54, 3: 0.66]Per Epoch: 7m,12s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 83.59%, 6m,51s\n",
      "Test  Corrects: Top-1: 84.93%, 23.00 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.701, Losses [0: 0.63, 1: 0.43, 2: 0.38, 3: 0.41]Per Epoch: 6m,59s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 85.58%, 6m,50s\n",
      "Test  Corrects: Top-1: 87.07%, 22.80 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.789, Losses [0: 1.03, 1: 0.68, 2: 0.39, 3: 0.37]Per Epoch: 6m,36s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 87.26%, 6m,51s\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 3,677,514 -> 3,677,320\n",
      "Pre-prune Test  Corrects: Top-1: 87.60%, 22.99 s\n",
      "Post-prune Test  Corrects: Top-1: 87.60%, 22.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.358, I: 1.533], Loss Comp: [C: 1.388, E: 0.398, I: 0.19], Losses [0: 1.04, 1: 0.73, 2: 0.42, 3: 0.36]Per Epoch: 9m,17s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 87.81%, Comp: 0.36, 1.53 9m,26s\n",
      "Train Loss Components: C: 0.931, E: 0.398, I: 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Corrects: Top-1: 87.17%, 22.95 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.342, I: 1.533], Loss Comp: [C: 2.076, E: 0.372, I: 0.19], Losses [0: 1.62, 1: 0.96, 2: 0.62, 3: 0.88]Per Epoch: 9m,23s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 81.24%, Comp: 0.34, 1.53 9m,27s\n",
      "Train Loss Components: C: 4.062, E: 0.369, I: 0.19\n",
      "Test  Corrects: Top-1: 76.51%, 23.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.336, I: 1.333], Loss Comp: [C: 1.579, E: 0.359, I: 0.17], Losses [0: 1.89, 1: 1.11, 2: 0.39, 3: 0.37]Per Epoch: 9m,3s  , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 78.60%, Comp: 0.33, 1.33 9m,27s\n",
      "Train Loss Components: C: 1.293, E: 0.357, I: 0.17\n",
      "Test  Corrects: Top-1: 78.85%, 22.97 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.330, I: 1.400], Loss Comp: [C: 2.958, E: 0.350, I: 0.17], Losses [0: 3.09, 1: 1.73, 2: 0.99, 3: 1.27]Per Epoch: 9m,2s  , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 76.64%, Comp: 0.33, 1.40 9m,26s\n",
      "Train Loss Components: C: 2.340, E: 0.350, I: 0.17\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 3,677,320 -> 3,641,735\n",
      "Pre-prune Test  Corrects: Top-1: 74.82%, 23.34 s\n",
      "Post-prune Test  Corrects: Top-1: 74.82%, 23.01 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.326, I: 1.400], Loss Comp: [C: 1.758, E: 0.348, I: 0.17], Losses [0: 1.34, 1: 1.0, 2: 0.44, 3: 0.68]Per Epoch: 9m,12s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 79.94%, Comp: 0.33, 1.40 9m,22s\n",
      "Train Loss Components: C: 1.613, E: 0.348, I: 0.17\n",
      "Test  Corrects: Top-1: 81.98%, 22.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.317, I: 1.467], Loss Comp: [C: 1.407, E: 0.331, I: 0.17], Losses [0: 1.19, 1: 0.74, 2: 0.43, 3: 0.43]Per Epoch: 9m,16s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 82.90%, Comp: 0.32, 1.47 9m,24s\n",
      "Train Loss Components: C: 2.239, E: 0.333, I: 0.17\n",
      "Test  Corrects: Top-1: 82.70%, 23.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.317, I: 1.333], Loss Comp: [C: 1.327, E: 0.332, I: 0.17], Losses [0: 1.0, 1: 0.57, 2: 0.38, 3: 0.44]Per Epoch: 9m,34s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 85.45%, Comp: 0.32, 1.33 9m,23s\n",
      "Train Loss Components: C: 1.472, E: 0.330, I: 0.17\n",
      "Test  Corrects: Top-1: 82.90%, 22.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.315, I: 1.467], Loss Comp: [C: 1.290, E: 0.330, I: 0.17], Losses [0: 0.8, 1: 0.62, 2: 0.39, 3: 0.42]Per Epoch: 9m,29s , Alloc: 6.93GiB  \n",
      "Train Corrects: Top-1: 86.75%, Comp: 0.32, 1.47 9m,23s\n",
      "Train Loss Components: C: 1.221, E: 0.330, I: 0.17\n",
      "\n",
      "Deadheaded 26 operations\n",
      "Param Delta: 3,641,735 -> 3,343,277\n",
      "Pre-prune Test  Corrects: Top-1: 86.39%, 22.83 s\n",
      "Post-prune Test  Corrects: Top-1: 86.39%, 21.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.806640625, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.10546875\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 1.05GiB\n",
      "2: 1.94GiB\n",
      "3: 2.93GiB\n",
      "4: 3.85GiB\n",
      "5: 3.93GiB\n",
      "6: 3.97GiB\n",
      "7: 4.24GiB\n",
      "8: 4.47GiB\n",
      "9: 4.69GiB\n",
      "10: 4.96GiB\n",
      "11: 5.10GiB\n",
      "12: 5.25GiB\n",
      "13: 5.39GiB\n",
      "14: 5.62GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.823, Losses [0: 2.01, 1: 1.54, 2: 1.01, 3: 1.91]Per Epoch: 5m,50s , Alloc: 5.84GiB  \n",
      "Train Corrects: Top-1: 77.47%, 6m,17s\n",
      "Test  Corrects: Top-1: 68.31%, 21.87 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.382, Losses [0: 1.7, 1: 0.92, 2: 0.55, 3: 0.75]Per Epoch: 5m,49s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 75.41%, 6m,18s\n",
      "Test  Corrects: Top-1: 80.28%, 21.60 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.796, Losses [0: 1.8, 1: 1.5, 2: 0.9, 3: 1.96]Per Epoch: 5m,48s , Alloc: 6.32GiB    \n",
      "Train Corrects: Top-1: 75.86%, 6m,20s\n",
      "Test  Corrects: Top-1: 77.71%, 21.98 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.110, Losses [0: 1.25, 1: 0.79, 2: 0.84, 3: 1.53]Per Epoch: 6m,12s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 73.68%, 6m,19s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 3,343,277 -> 3,343,276\n",
      "Pre-prune Test  Corrects: Top-1: 79.29%, 21.34 s\n",
      "Post-prune Test  Corrects: Top-1: 79.29%, 21.28 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.184, Losses [0: 1.33, 1: 0.98, 2: 0.45, 3: 0.63]Per Epoch: 6m,11s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 79.16%, 6m,18s\n",
      "Test  Corrects: Top-1: 83.82%, 21.60 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.733, Losses [0: 0.75, 1: 0.59, 2: 0.38, 3: 0.39]Per Epoch: 5m,59s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 83.26%, 6m,17s\n",
      "Test  Corrects: Top-1: 85.60%, 21.74 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.677, Losses [0: 0.9, 1: 0.56, 2: 0.33, 3: 0.32]Per Epoch: 6m,43s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 85.71%, 6m,19s\n",
      "Test  Corrects: Top-1: 85.73%, 21.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.203, Losses [0: 1.23, 1: 0.84, 2: 0.6, 3: 0.67]Per Epoch: 5m,59s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 87.13%, 6m,19s\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 3,343,276 -> 3,340,522\n",
      "Pre-prune Test  Corrects: Top-1: 87.36%, 21.42 s\n",
      "Post-prune Test  Corrects: Top-1: 87.36%, 21.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.323, I: 1.400], Loss Comp: [C: 1.367, E: 0.535, I: 0.23], Losses [0: 0.76, 1: 0.53, 2: 0.26, 3: 0.29]Per Epoch: 8m,35s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 87.39%, Comp: 0.32, 1.40 8m,43s\n",
      "Train Loss Components: C: 1.700, E: 0.535, I: 0.23\n",
      "Test  Corrects: Top-1: 87.08%, 21.54 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.313, I: 1.467], Loss Comp: [C: 3.031, E: 0.503, I: 0.23], Losses [0: 2.48, 1: 1.31, 2: 0.94, 3: 1.35]Per Epoch: 8m,51s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 82.02%, Comp: 0.31, 1.47 8m,44s\n",
      "Train Loss Components: C: 3.231, E: 0.503, I: 0.23\n",
      "Test  Corrects: Top-1: 76.13%, 21.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.308, I: 1.467], Loss Comp: [C: 2.180, E: 0.504, I: 0.23], Losses [0: 1.67, 1: 0.82, 2: 0.58, 3: 0.83]Per Epoch: 8m,6s  , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 79.64%, Comp: 0.31, 1.47 8m,45s\n",
      "Train Loss Components: C: 1.761, E: 0.510, I: 0.23\n",
      "Test  Corrects: Top-1: 77.50%, 21.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.307, I: 1.400], Loss Comp: [C: 2.435, E: 0.501, I: 0.23], Losses [0: 2.08, 1: 1.04, 2: 0.67, 3: 0.95]Per Epoch: 8m,15s , Alloc: 6.32GiB   \n",
      "Train Corrects: Top-1: 78.10%, Comp: 0.31, 1.40 8m,46s\n",
      "Train Loss Components: C: 2.685, E: 0.496, I: 0.23\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,340,522 -> 3,340,522\n",
      "Pre-prune Test  Corrects: Top-1: 74.77%, 21.34 s\n",
      "Post-prune Test  Corrects: Top-1: 74.77%, 21.28 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.310, I: 1.400], Loss Comp: [C: 1.494, E: 0.504, I: 0.23], Losses [0: 1.0, 1: 0.57, 2: 0.34, 3: 0.38]Per Epoch: 8m,59s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 80.32%, Comp: 0.31, 1.33 8m,45s\n",
      "Train Loss Components: C: 8.170, E: 0.504, I: 0.22\n",
      "Test  Corrects: Top-1: 84.53%, 21.09 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.296, I: 1.267], Loss Comp: [C: 1.545, E: 0.472, I: 0.22], Losses [0: 0.92, 1: 0.77, 2: 0.39, 3: 0.44]Per Epoch: 8m,44s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 84.13%, Comp: 0.30, 1.27 8m,46s\n",
      "Train Loss Components: C: 2.399, E: 0.472, I: 0.22\n",
      "Test  Corrects: Top-1: 84.54%, 21.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.301, I: 1.333], Loss Comp: [C: 1.484, E: 0.489, I: 0.22], Losses [0: 0.91, 1: 0.79, 2: 0.32, 3: 0.37]Per Epoch: 8m,27s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 85.89%, Comp: 0.30, 1.33 8m,43s\n",
      "Train Loss Components: C: 3.572, E: 0.489, I: 0.22\n",
      "Test  Corrects: Top-1: 84.60%, 21.01 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.292, I: 1.400], Loss Comp: [C: 1.276, E: 0.465, I: 0.23], Losses [0: 0.77, 1: 0.57, 2: 0.28, 3: 0.26]Per Epoch: 8m,30s , Alloc: 6.32GiB  \n",
      "Train Corrects: Top-1: 87.21%, Comp: 0.29, 1.40 8m,46s\n",
      "Train Loss Components: C: 1.451, E: 0.463, I: 0.23\n",
      "\n",
      "Deadheaded 16 operations\n",
      "Param Delta: 3,340,522 -> 3,102,426\n",
      "Pre-prune Test  Corrects: Top-1: 86.83%, 21.38 s\n",
      "Post-prune Test  Corrects: Top-1: 86.83%, 20.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.4296875, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.0791015625\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 1018.00MiB\n",
      "2: 1.81GiB\n",
      "3: 2.79GiB\n",
      "4: 3.58GiB\n",
      "5: 3.65GiB\n",
      "6: 3.71GiB\n",
      "7: 3.95GiB\n",
      "8: 4.14GiB\n",
      "9: 4.36GiB\n",
      "10: 4.61GiB\n",
      "11: 4.74GiB\n",
      "12: 4.88GiB\n",
      "13: 5.02GiB\n",
      "14: 5.24GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.168, Losses [0: 1.82, 1: 0.77, 2: 0.43, 3: 0.56]Per Epoch: 5m,47s , Alloc: 5.46GiB  \n",
      "Train Corrects: Top-1: 77.94%, 5m,54s\n",
      "Test  Corrects: Top-1: 79.53%, 20.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.078, Losses [0: 1.23, 1: 0.6, 2: 0.39, 3: 0.63]Per Epoch: 5m,46s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 79.28%, 5m,57s\n",
      "Test  Corrects: Top-1: 82.34%, 20.63 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 0.843, Losses [0: 1.37, 1: 0.57, 2: 0.27, 3: 0.4]Per Epoch: 5m,50s , Alloc: 5.92GiB   \n",
      "Train Corrects: Top-1: 80.04%, 5m,57s\n",
      "Test  Corrects: Top-1: 80.68%, 20.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 0.637, Losses [0: 1.01, 1: 0.48, 2: 0.23, 3: 0.29]Per Epoch: 6m,2s  , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 83.49%, 5m,56s\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 3,102,426 -> 3,102,424\n",
      "Pre-prune Test  Corrects: Top-1: 85.02%, 20.32 s\n",
      "Post-prune Test  Corrects: Top-1: 85.02%, 20.10 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.658, Losses [0: 0.84, 1: 0.56, 2: 0.3, 3: 0.32]Per Epoch: 5m,36s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 85.20%, 5m,55s\n",
      "Test  Corrects: Top-1: 86.16%, 20.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.725, Losses [0: 1.0, 1: 0.6, 2: 0.35, 3: 0.34]Per Epoch: 5m,42s , Alloc: 5.92GiB   \n",
      "Train Corrects: Top-1: 86.66%, 5m,56s\n",
      "Test  Corrects: Top-1: 87.84%, 20.51 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.800, Losses [0: 0.8, 1: 0.56, 2: 0.43, 3: 0.44]Per Epoch: 5m,25s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 88.34%, 5m,55s\n",
      "Test  Corrects: Top-1: 87.44%, 20.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.572, Losses [0: 0.76, 1: 0.44, 2: 0.26, 3: 0.28]Per Epoch: 5m,30s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 89.74%, 5m,56s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,102,424 -> 3,102,424\n",
      "Pre-prune Test  Corrects: Top-1: 88.61%, 20.58 s\n",
      "Post-prune Test  Corrects: Top-1: 88.61%, 20.76 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.304, I: 1.333], Loss Comp: [C: 1.543, E: 0.683, I: 0.28], Losses [0: 0.76, 1: 0.54, 2: 0.28, 3: 0.26]Per Epoch: 7m,54s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 90.06%, Comp: 0.31, 1.33 8m,21s\n",
      "Train Loss Components: C: 1.301, E: 0.694, I: 0.28\n",
      "Test  Corrects: Top-1: 88.74%, 20.22 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.294, I: 1.400], Loss Comp: [C: 1.633, E: 0.655, I: 0.28], Losses [0: 1.02, 1: 0.55, 2: 0.3, 3: 0.32]Per Epoch: 8m,2s  , Alloc: 5.92GiB   \n",
      "Train Corrects: Top-1: 82.26%, Comp: 0.29, 1.40 8m,20s\n",
      "Train Loss Components: C: 7.795, E: 0.655, I: 0.28\n",
      "Test  Corrects: Top-1: 77.72%, 20.20 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.296, I: 1.333], Loss Comp: [C: 5.134, E: 0.664, I: 0.28], Losses [0: 3.46, 1: 2.34, 2: 1.28, 3: 2.78]Per Epoch: 8m,1s  , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 75.11%, Comp: 0.30, 1.33 8m,21s\n",
      "Train Loss Components: C: 4.755, E: 0.664, I: 0.28\n",
      "Test  Corrects: Top-1: 26.21%, 20.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.293, I: 1.333], Loss Comp: [C: 3.308, E: 0.653, I: 0.28], Losses [0: 2.28, 1: 1.24, 2: 0.84, 3: 1.5]Per Epoch: 8m,28s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 64.54%, Comp: 0.29, 1.33 8m,21s\n",
      "Train Loss Components: C: 2.936, E: 0.652, I: 0.28\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,102,424 -> 3,102,424\n",
      "Pre-prune Test  Corrects: Top-1: 68.35%, 20.91 s\n",
      "Post-prune Test  Corrects: Top-1: 68.35%, 20.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.290, I: 1.267], Loss Comp: [C: 2.033, E: 0.649, I: 0.27], Losses [0: 1.52, 1: 0.79, 2: 0.43, 3: 0.56]Per Epoch: 8m,34s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 76.32%, Comp: 0.29, 1.27 8m,20s\n",
      "Train Loss Components: C: 2.514, E: 0.649, I: 0.27\n",
      "Test  Corrects: Top-1: 80.04%, 20.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.282, I: 1.267], Loss Comp: [C: 1.665, E: 0.622, I: 0.27], Losses [0: 0.96, 1: 0.71, 2: 0.36, 3: 0.36]Per Epoch: 7m,46s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 80.86%, Comp: 0.28, 1.27 8m,20s\n",
      "Train Loss Components: C: 3.197, E: 0.614, I: 0.27\n",
      "Test  Corrects: Top-1: 79.74%, 20.22 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.281, I: 1.267], Loss Comp: [C: 1.629, E: 0.617, I: 0.27], Losses [0: 1.03, 1: 0.76, 2: 0.32, 3: 0.32]Per Epoch: 7m,58s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 84.00%, Comp: 0.28, 1.27 8m,21s\n",
      "Train Loss Components: C: 1.890, E: 0.617, I: 0.27\n",
      "Test  Corrects: Top-1: 81.04%, 20.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.276, I: 1.267], Loss Comp: [C: 1.353, E: 0.603, I: 0.27], Losses [0: 0.79, 1: 0.59, 2: 0.21, 3: 0.16]Per Epoch: 8m,15s , Alloc: 5.92GiB  \n",
      "Train Corrects: Top-1: 85.85%, Comp: 0.28, 1.27 8m,20s\n",
      "Train Loss Components: C: 1.948, E: 0.603, I: 0.27\n",
      "\n",
      "Deadheaded 13 operations\n",
      "Param Delta: 3,102,424 -> 2,996,075\n",
      "Pre-prune Test  Corrects: Top-1: 85.55%, 20.16 s\n",
      "Post-prune Test  Corrects: Top-1: 85.55%, 19.78 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.20703125, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.059326171875\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 938.00MiB\n",
      "2: 1.73GiB\n",
      "3: 2.72GiB\n",
      "4: 3.50GiB\n",
      "5: 3.56GiB\n",
      "6: 3.56GiB\n",
      "7: 3.80GiB\n",
      "8: 3.99GiB\n",
      "9: 4.21GiB\n",
      "10: 4.44GiB\n",
      "11: 4.56GiB\n",
      "12: 4.68GiB\n",
      "13: 4.81GiB\n",
      "14: 5.02GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.659, Losses [0: 1.36, 1: 0.81, 2: 0.45, 3: 1.13]Per Epoch: 5m,23s , Alloc: 5.24GiB  \n",
      "Train Corrects: Top-1: 79.39%, 5m,39s\n",
      "Test  Corrects: Top-1: 78.49%, 19.80 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.088, Losses [0: 1.77, 1: 0.64, 2: 0.45, 3: 0.52]Per Epoch: 5m,42s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 77.73%, 5m,40s\n",
      "Test  Corrects: Top-1: 82.50%, 19.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.233, Losses [0: 1.34, 1: 0.88, 2: 0.52, 3: 0.69]Per Epoch: 5m,39s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 79.68%, 5m,41s\n",
      "Test  Corrects: Top-1: 82.98%, 19.64 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.622, Losses [0: 1.54, 1: 1.05, 2: 0.63, 3: 0.98]Per Epoch: 5m,21s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 80.66%, 5m,40s\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 2,996,075 -> 2,995,945\n",
      "Pre-prune Test  Corrects: Top-1: 83.21%, 19.56 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-prune Test  Corrects: Top-1: 83.21%, 19.65 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.962, Losses [0: 1.21, 1: 0.68, 2: 0.43, 3: 0.5]Per Epoch: 5m,24s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 83.34%, 5m,39s\n",
      "Test  Corrects: Top-1: 85.07%, 19.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.865, Losses [0: 1.36, 1: 0.61, 2: 0.34, 3: 0.4]Per Epoch: 5m,34s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 85.98%, 5m,39s\n",
      "Test  Corrects: Top-1: 86.23%, 19.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.616, Losses [0: 0.88, 1: 0.58, 2: 0.29, 3: 0.27]Per Epoch: 5m,16s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 87.80%, 5m,40s\n",
      "Test  Corrects: Top-1: 88.03%, 19.58 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.593, Losses [0: 0.75, 1: 0.48, 2: 0.32, 3: 0.28]Per Epoch: 5m,43s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 89.01%, 5m,39s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,995,945 -> 2,995,945\n",
      "Pre-prune Test  Corrects: Top-1: 86.32%, 19.58 s\n",
      "Post-prune Test  Corrects: Top-1: 86.32%, 19.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.288, I: 1.267], Loss Comp: [C: 1.756, E: 0.828, I: 0.33], Losses [0: 0.95, 1: 0.54, 2: 0.24, 3: 0.25]Per Epoch: 7m,34s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 89.35%, Comp: 0.29, 1.27 8m,2s\n",
      "Train Loss Components: C: 1.797, E: 0.834, I: 0.33\n",
      "Test  Corrects: Top-1: 87.82%, 19.50 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.283, I: 1.267], Loss Comp: [C: 2.324, E: 0.816, I: 0.33], Losses [0: 1.72, 1: 1.07, 2: 0.43, 3: 0.54]Per Epoch: 7m,56s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 81.88%, Comp: 0.28, 1.27 8m,2s\n",
      "Train Loss Components: C: 11.435, E: 0.809, I: 0.33\n",
      "Test  Corrects: Top-1: 83.15%, 19.99 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.279, I: 1.200], Loss Comp: [C: 2.455, E: 0.793, I: 0.33], Losses [0: 2.26, 1: 0.95, 2: 0.38, 3: 0.62]Per Epoch: 7m,47s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 79.91%, Comp: 0.28, 1.20 8m,2s\n",
      "Train Loss Components: C: 2.722, E: 0.793, I: 0.33\n",
      "Test  Corrects: Top-1: 82.68%, 19.66 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.281, I: 1.267], Loss Comp: [C: 2.720, E: 0.807, I: 0.33], Losses [0: 1.84, 1: 0.61, 2: 0.46, 3: 1.0]Per Epoch: 7m,56s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 81.76%, Comp: 0.28, 1.27 8m,2s\n",
      "Train Loss Components: C: 1.737, E: 0.818, I: 0.33\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,995,945 -> 2,995,945\n",
      "Pre-prune Test  Corrects: Top-1: 72.72%, 19.67 s\n",
      "Post-prune Test  Corrects: Top-1: 72.72%, 19.52 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.277, I: 1.200], Loss Comp: [C: 1.860, E: 0.798, I: 0.33], Losses [0: 0.71, 1: 0.66, 2: 0.37, 3: 0.39]Per Epoch: 7m,35s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 83.17%, Comp: 0.28, 1.20 8m,2s\n",
      "Train Loss Components: C: 2.387, E: 0.795, I: 0.33\n",
      "Test  Corrects: Top-1: 84.91%, 19.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.273, I: 1.133], Loss Comp: [C: 1.923, E: 0.782, I: 0.13], Losses [0: 1.44, 1: 0.67, 2: 0.44, 3: 0.5]Per Epoch: 7m,57s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 86.31%, Comp: 0.27, 1.13 8m,3s\n",
      "Train Loss Components: C: 1.687, E: 0.786, I: 0.13\n",
      "Test  Corrects: Top-1: 85.21%, 19.78 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.269, I: 1.133], Loss Comp: [C: 1.689, E: 0.766, I: 0.13], Losses [0: 1.09, 1: 0.56, 2: 0.38, 3: 0.39]Per Epoch: 7m,32s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 87.50%, Comp: 0.27, 1.13 8m,2s\n",
      "Train Loss Components: C: 1.527, E: 0.776, I: 0.13\n",
      "Test  Corrects: Top-1: 87.44%, 19.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.271, I: 1.133], Loss Comp: [C: 1.323, E: 0.779, I: 0.13], Losses [0: 0.63, 1: 0.35, 2: 0.21, 3: 0.18]Per Epoch: 8m,25s , Alloc: 5.66GiB  \n",
      "Train Corrects: Top-1: 88.99%, Comp: 0.27, 1.13 8m,2s\n",
      "Train Loss Components: C: 1.281, E: 0.783, I: 0.13\n",
      "\n",
      "Deadheaded 8 operations\n",
      "Param Delta: 2,995,945 -> 2,917,473\n",
      "Pre-prune Test  Corrects: Top-1: 88.71%, 19.56 s\n",
      "Post-prune Test  Corrects: Top-1: 88.71%, 19.12 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.037109375, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.04449462890625\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 938.00MiB\n",
      "2: 1.67GiB\n",
      "3: 2.64GiB\n",
      "4: 3.40GiB\n",
      "5: 3.47GiB\n",
      "6: 3.49GiB\n",
      "7: 3.70GiB\n",
      "8: 3.92GiB\n",
      "9: 4.11GiB\n",
      "10: 4.33GiB\n",
      "11: 4.44GiB\n",
      "12: 4.56GiB\n",
      "13: 4.70GiB\n",
      "14: 4.85GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.147, Losses [0: 2.57, 1: 1.32, 2: 0.77, 3: 1.21]Per Epoch: 5m,4s  , Alloc: 5.07GiB  \n",
      "Train Corrects: Top-1: 83.94%, 5m,29s\n",
      "Test  Corrects: Top-1: 83.99%, 18.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.966, Losses [0: 1.55, 1: 1.07, 2: 0.65, 3: 1.31]Per Epoch: 5m,15s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 79.16%, 5m,31s\n",
      "Test  Corrects: Top-1: 81.75%, 19.39 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.091, Losses [0: 1.45, 1: 0.84, 2: 0.39, 3: 0.55]Per Epoch: 5m,32s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 80.80%, 5m,32s\n",
      "Test  Corrects: Top-1: 84.49%, 19.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.105, Losses [0: 1.55, 1: 1.0, 2: 0.38, 3: 0.52]Per Epoch: 5m,24s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 82.64%, 5m,31s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,917,473 -> 2,881,888\n",
      "Pre-prune Test  Corrects: Top-1: 76.02%, 19.14 s\n",
      "Post-prune Test  Corrects: Top-1: 76.02%, 19.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.634, Losses [0: 0.93, 1: 0.5, 2: 0.29, 3: 0.29]Per Epoch: 5m,19s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 84.66%, 5m,31s\n",
      "Test  Corrects: Top-1: 86.09%, 19.52 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.799, Losses [0: 1.08, 1: 0.67, 2: 0.3, 3: 0.39]Per Epoch: 5m,24s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 87.21%, 5m,29s\n",
      "Test  Corrects: Top-1: 87.47%, 19.01 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.073, Losses [0: 1.25, 1: 0.63, 2: 0.49, 3: 0.6]Per Epoch: 5m,36s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 88.98%, 5m,31s\n",
      "Test  Corrects: Top-1: 88.72%, 19.13 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.439, Losses [0: 0.67, 1: 0.43, 2: 0.19, 3: 0.18]Per Epoch: 5m,31s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 90.17%, 5m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,881,888 -> 2,881,888\n",
      "Pre-prune Test  Corrects: Top-1: 89.78%, 19.38 s\n",
      "Post-prune Test  Corrects: Top-1: 89.78%, 19.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.280, I: 1.133], Loss Comp: [C: 1.657, E: 0.996, I: 0.15], Losses [0: 0.72, 1: 0.43, 2: 0.24, 3: 0.24]Per Epoch: 8m,0s  , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 90.36%, Comp: 0.28, 1.13 7m,50s\n",
      "Train Loss Components: C: 1.901, E: 0.981, I: 0.15\n",
      "Test  Corrects: Top-1: 74.78%, 19.17 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.271, I: 1.200], Loss Comp: [C: 2.420, E: 0.960, I: 0.38], Losses [0: 1.31, 1: 0.56, 2: 0.3, 3: 0.65]Per Epoch: 7m,43s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 82.06%, Comp: 0.27, 1.13 7m,52s\n",
      "Train Loss Components: C: 5.077, E: 0.960, I: 0.15\n",
      "Test  Corrects: Top-1: 78.47%, 19.12 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.267, I: 1.133], Loss Comp: [C: 2.232, E: 0.934, I: 0.15], Losses [0: 1.84, 1: 0.94, 2: 0.45, 3: 0.5]Per Epoch: 7m,39s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 82.66%, Comp: 0.27, 1.13 7m,51s\n",
      "Train Loss Components: C: 4.259, E: 0.934, I: 0.15\n",
      "Test  Corrects: Top-1: 84.12%, 19.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.264, I: 1.133], Loss Comp: [C: 1.651, E: 0.922, I: 0.15], Losses [0: 0.86, 1: 0.6, 2: 0.22, 3: 0.25]Per Epoch: 7m,28s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 83.24%, Comp: 0.26, 1.13 7m,51s\n",
      "Train Loss Components: C: 1.574, E: 0.922, I: 0.15\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,881,888 -> 2,881,887\n",
      "Pre-prune Test  Corrects: Top-1: 85.35%, 19.11 s\n",
      "Post-prune Test  Corrects: Top-1: 85.35%, 19.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.265, I: 1.200], Loss Comp: [C: 2.222, E: 0.929, I: 0.38], Losses [0: 1.42, 1: 0.8, 2: 0.36, 3: 0.4]Per Epoch: 7m,37s , Alloc: 5.48GiB   \n",
      "Train Corrects: Top-1: 84.92%, Comp: 0.27, 1.20 7m,50s\n",
      "Train Loss Components: C: 4.307, E: 0.929, I: 0.38\n",
      "Test  Corrects: Top-1: 85.13%, 18.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.262, I: 1.200], Loss Comp: [C: 2.904, E: 0.911, I: 0.38], Losses [0: 1.05, 1: 0.8, 2: 0.47, 3: 1.15]Per Epoch: 7m,20s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 87.52%, Comp: 0.26, 1.20 7m,50s\n",
      "Train Loss Components: C: 3.284, E: 0.905, I: 0.38\n",
      "Test  Corrects: Top-1: 86.63%, 19.26 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.261, I: 1.200], Loss Comp: [C: 1.680, E: 0.915, I: 0.38], Losses [0: 0.61, 1: 0.29, 2: 0.17, 3: 0.17]Per Epoch: 8m,8s  , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 89.17%, Comp: 0.26, 1.20 7m,52s\n",
      "Train Loss Components: C: 1.903, E: 0.903, I: 0.38\n",
      "Test  Corrects: Top-1: 88.74%, 18.99 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.261, I: 1.200], Loss Comp: [C: 2.025, E: 0.914, I: 0.38], Losses [0: 0.64, 1: 0.51, 2: 0.34, 3: 0.43]Per Epoch: 7m,47s , Alloc: 5.48GiB  \n",
      "Train Corrects: Top-1: 90.50%, Comp: 0.26, 1.20 7m,52s\n",
      "Train Loss Components: C: 1.878, E: 0.920, I: 0.38\n",
      "\n",
      "Deadheaded 11 operations\n",
      "Param Delta: 2,881,887 -> 2,634,036\n",
      "Pre-prune Test  Corrects: Top-1: 89.05%, 19.16 s\n",
      "Post-prune Test  Corrects: Top-1: 89.05%, 18.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.888671875, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.0333709716796875\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 938.00MiB\n",
      "2: 1.65GiB\n",
      "3: 2.62GiB\n",
      "4: 3.31GiB\n",
      "5: 3.38GiB\n",
      "6: 3.38GiB\n",
      "7: 3.62GiB\n",
      "8: 3.81GiB\n",
      "9: 4.03GiB\n",
      "10: 4.21GiB\n",
      "11: 4.34GiB\n",
      "12: 4.44GiB\n",
      "13: 4.56GiB\n",
      "14: 4.69GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.198, Losses [0: 1.71, 1: 0.92, 2: 0.4, 3: 0.59]Per Epoch: 5m,6s  , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 85.68%, 5m,16s\n",
      "Test  Corrects: Top-1: 83.10%, 18.50 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 0.686, Losses [0: 1.17, 1: 0.53, 2: 0.28, 3: 0.29]Per Epoch: 5m,6s  , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 81.33%, 5m,17s\n",
      "Test  Corrects: Top-1: 86.01%, 18.62 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.314, Losses [0: 2.1, 1: 0.73, 2: 0.46, 3: 0.66]Per Epoch: 5m,3s  , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 81.25%, 5m,18s\n",
      "Test  Corrects: Top-1: 82.88%, 18.51 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.088, Losses [0: 1.27, 1: 0.81, 2: 0.44, 3: 0.58]Per Epoch: 5m,5s  , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 82.19%, 5m,16s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,634,036 -> 2,634,036\n",
      "Pre-prune Test  Corrects: Top-1: 84.92%, 18.41 s\n",
      "Post-prune Test  Corrects: Top-1: 84.92%, 18.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.844, Losses [0: 1.17, 1: 0.68, 2: 0.34, 3: 0.41]Per Epoch: 5m,22s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 85.46%, 5m,17s\n",
      "Test  Corrects: Top-1: 87.44%, 18.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.623, Losses [0: 1.03, 1: 0.63, 2: 0.26, 3: 0.24]Per Epoch: 4m,47s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 88.29%, 5m,16s\n",
      "Test  Corrects: Top-1: 88.04%, 18.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.888, Losses [0: 1.03, 1: 0.7, 2: 0.4, 3: 0.46]Per Epoch: 5m,29s , Alloc: 5.31GiB   \n",
      "Train Corrects: Top-1: 89.86%, 5m,17s\n",
      "Test  Corrects: Top-1: 89.75%, 18.58 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.430, Losses [0: 0.52, 1: 0.29, 2: 0.2, 3: 0.23]Per Epoch: 5m,10s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 91.00%, 5m,17s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,634,036 -> 2,634,036\n",
      "Pre-prune Test  Corrects: Top-1: 90.11%, 18.54 s\n",
      "Post-prune Test  Corrects: Top-1: 90.11%, 18.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.261, I: 1.200], Loss Comp: [C: 2.057, E: 1.097, I: 0.43], Losses [0: 0.56, 1: 0.43, 2: 0.24, 3: 0.28]Per Epoch: 7m,21s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 91.37%, Comp: 0.26, 1.20 7m,36s\n",
      "Train Loss Components: C: 2.119, E: 1.097, I: 0.43\n",
      "Test  Corrects: Top-1: 89.11%, 18.42 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.261, I: 1.200], Loss Comp: [C: 2.594, E: 1.092, I: 0.43], Losses [0: 1.36, 1: 0.85, 2: 0.4, 3: 0.55]Per Epoch: 7m,15s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 81.84%, Comp: 0.26, 1.20 7m,36s\n",
      "Train Loss Components: C: 2.047, E: 1.088, I: 0.43\n",
      "Test  Corrects: Top-1: 85.95%, 18.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.249, I: 1.200], Loss Comp: [C: 2.641, E: 1.051, I: 0.43], Losses [0: 1.26, 1: 0.89, 2: 0.4, 3: 0.65]Per Epoch: 7m,20s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 82.61%, Comp: 0.25, 1.20 7m,35s\n",
      "Train Loss Components: C: 3.647, E: 1.051, I: 0.43\n",
      "Test  Corrects: Top-1: 81.95%, 18.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.251, I: 1.200], Loss Comp: [C: 2.549, E: 1.054, I: 0.43], Losses [0: 1.31, 1: 0.71, 2: 0.41, 3: 0.57]Per Epoch: 7m,26s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 83.21%, Comp: 0.25, 1.20 7m,36s\n",
      "Train Loss Components: C: 2.774, E: 1.062, I: 0.43\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,634,036 -> 2,634,036\n",
      "Pre-prune Test  Corrects: Top-1: 76.95%, 18.56 s\n",
      "Post-prune Test  Corrects: Top-1: 76.95%, 18.74 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.254, I: 1.200], Loss Comp: [C: 2.381, E: 1.081, I: 0.43], Losses [0: 1.52, 1: 0.83, 2: 0.3, 3: 0.34]Per Epoch: 8m,1s  , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 84.76%, Comp: 0.25, 1.20 7m,37s\n",
      "Train Loss Components: C: 2.421, E: 1.081, I: 0.43\n",
      "Test  Corrects: Top-1: 82.99%, 18.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.245, I: 1.200], Loss Comp: [C: 2.200, E: 1.037, I: 0.43], Losses [0: 1.04, 1: 0.8, 2: 0.28, 3: 0.3]Per Epoch: 8m,3s  , Alloc: 5.31GiB   \n",
      "Train Corrects: Top-1: 87.08%, Comp: 0.25, 1.20 7m,36s\n",
      "Train Loss Components: C: 1.979, E: 1.038, I: 0.43\n",
      "Test  Corrects: Top-1: 85.84%, 18.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.246, I: 1.200], Loss Comp: [C: 1.922, E: 1.045, I: 0.43], Losses [0: 0.63, 1: 0.4, 2: 0.21, 3: 0.2]Per Epoch: 7m,15s , Alloc: 5.31GiB   \n",
      "Train Corrects: Top-1: 89.25%, Comp: 0.25, 1.20 7m,36s\n",
      "Train Loss Components: C: 2.253, E: 1.036, I: 0.43\n",
      "Test  Corrects: Top-1: 75.18%, 18.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.244, I: 1.200], Loss Comp: [C: 2.190, E: 1.029, I: 0.43], Losses [0: 0.87, 1: 0.52, 2: 0.34, 3: 0.38]Per Epoch: 7m,26s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 90.61%, Comp: 0.24, 1.20 7m,36s\n",
      "Train Loss Components: C: 1.809, E: 1.027, I: 0.43\n",
      "\n",
      "Deadheaded 9 operations\n",
      "Param Delta: 2,634,036 -> 2,560,875\n",
      "Pre-prune Test  Corrects: Top-1: 89.59%, 18.41 s\n",
      "Post-prune Test  Corrects: Top-1: 89.58%, 17.80 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.791015625, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.025028228759765625\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 938.00MiB\n",
      "2: 1.65GiB\n",
      "3: 2.62GiB\n",
      "4: 3.31GiB\n",
      "5: 3.38GiB\n",
      "6: 3.38GiB\n",
      "7: 3.56GiB\n",
      "8: 3.78GiB\n",
      "9: 3.97GiB\n",
      "10: 4.15GiB\n",
      "11: 4.28GiB\n",
      "12: 4.38GiB\n",
      "13: 4.50GiB\n",
      "14: 4.62GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.312, Losses [0: 1.81, 1: 0.93, 2: 0.53, 3: 0.66]Per Epoch: 5m,1s  , Alloc: 4.82GiB  \n",
      "Train Corrects: Top-1: 86.47%, 5m,9s\n",
      "Test  Corrects: Top-1: 84.68%, 17.99 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.226, Losses [0: 1.71, 1: 0.71, 2: 0.5, 3: 0.64]Per Epoch: 5m,3s  , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 82.56%, 5m,8s\n",
      "Test  Corrects: Top-1: 84.82%, 18.12 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 0.924, Losses [0: 1.03, 1: 0.44, 2: 0.35, 3: 0.56]Per Epoch: 4m,43s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 84.05%, 5m,11s\n",
      "Test  Corrects: Top-1: 84.55%, 18.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.105, Losses [0: 1.11, 1: 0.74, 2: 0.36, 3: 0.66]Per Epoch: 5m,4s  , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 84.81%, 5m,10s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,560,875 -> 2,560,875\n",
      "Pre-prune Test  Corrects: Top-1: 74.38%, 18.07 s\n",
      "Post-prune Test  Corrects: Top-1: 74.38%, 18.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.759, Losses [0: 1.06, 1: 0.68, 2: 0.31, 3: 0.35]Per Epoch: 5m,15s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 85.20%, 5m,10s\n",
      "Test  Corrects: Top-1: 87.16%, 17.99 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.686, Losses [0: 0.75, 1: 0.63, 2: 0.35, 3: 0.34]Per Epoch: 4m,39s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 87.34%, 5m,10s\n",
      "Test  Corrects: Top-1: 86.49%, 18.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.627, Losses [0: 0.78, 1: 0.51, 2: 0.32, 3: 0.3]Per Epoch: 5m,12s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 88.95%, 5m,10s\n",
      "Test  Corrects: Top-1: 87.98%, 18.14 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.316, Losses [0: 0.65, 1: 0.27, 2: 0.13, 3: 0.11]Per Epoch: 4m,58s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 91.00%, 5m,10s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,560,875 -> 2,560,875\n",
      "Pre-prune Test  Corrects: Top-1: 89.88%, 17.81 s\n",
      "Post-prune Test  Corrects: Top-1: 89.88%, 17.90 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.254, I: 1.200], Loss Comp: [C: 2.297, E: 1.244, I: 0.49], Losses [0: 0.91, 1: 0.51, 2: 0.23, 3: 0.23]Per Epoch: 6m,49s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 91.43%, Comp: 0.25, 1.20 7m,26s\n",
      "Train Loss Components: C: 2.034, E: 1.244, I: 0.49\n",
      "Test  Corrects: Top-1: 89.58%, 17.88 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.251, I: 1.200], Loss Comp: [C: 2.809, E: 1.231, I: 0.49], Losses [0: 1.38, 1: 0.59, 2: 0.39, 3: 0.62]Per Epoch: 7m,19s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 81.84%, Comp: 0.25, 1.20 7m,25s\n",
      "Train Loss Components: C: 7.755, E: 1.222, I: 0.49\n",
      "Test  Corrects: Top-1: 31.02%, 17.79 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.244, I: 1.200], Loss Comp: [C: 3.371, E: 1.194, I: 0.49], Losses [0: 2.14, 1: 1.11, 2: 0.47, 3: 0.94]Per Epoch: 7m,19s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 71.52%, Comp: 0.25, 1.20 7m,26s\n",
      "Train Loss Components: C: 2.951, E: 1.209, I: 0.49\n",
      "Test  Corrects: Top-1: 80.37%, 17.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.239, I: 1.200], Loss Comp: [C: 2.696, E: 1.179, I: 0.49], Losses [0: 1.24, 1: 0.67, 2: 0.41, 3: 0.56]Per Epoch: 7m,41s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 80.02%, Comp: 0.24, 1.20 7m,26s\n",
      "Train Loss Components: C: 4.498, E: 1.179, I: 0.49\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,560,875 -> 2,560,875\n",
      "Pre-prune Test  Corrects: Top-1: 82.24%, 17.98 s\n",
      "Post-prune Test  Corrects: Top-1: 82.24%, 18.24 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.245, I: 1.133], Loss Comp: [C: 2.377, E: 1.211, I: 0.45], Losses [0: 0.91, 1: 0.66, 2: 0.27, 3: 0.34]Per Epoch: 7m,12s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 83.66%, Comp: 0.24, 1.13 7m,28s\n",
      "Train Loss Components: C: 1.998, E: 1.202, I: 0.45\n",
      "Test  Corrects: Top-1: 86.76%, 18.01 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.238, I: 1.133], Loss Comp: [C: 2.618, E: 1.168, I: 0.45], Losses [0: 1.02, 1: 0.69, 2: 0.48, 3: 0.56]Per Epoch: 6m,59s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 86.57%, Comp: 0.24, 1.13 7m,25s\n",
      "Train Loss Components: C: 2.796, E: 1.168, I: 0.45\n",
      "Test  Corrects: Top-1: 86.43%, 18.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.233, I: 1.133], Loss Comp: [C: 2.564, E: 1.143, I: 0.45], Losses [0: 0.93, 1: 0.48, 2: 0.29, 3: 0.63]Per Epoch: 7m,32s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 88.39%, Comp: 0.23, 1.13 7m,27s\n",
      "Train Loss Components: C: 2.449, E: 1.151, I: 0.45\n",
      "Test  Corrects: Top-1: 86.77%, 17.97 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.237, I: 1.200], Loss Comp: [C: 1.848, E: 1.169, I: 0.49], Losses [0: 0.38, 1: 0.18, 2: 0.08, 3: 0.06]Per Epoch: 7m,16s , Alloc: 5.20GiB  \n",
      "Train Corrects: Top-1: 89.84%, Comp: 0.24, 1.20 7m,25s\n",
      "Train Loss Components: C: 2.177, E: 1.168, I: 0.49\n",
      "\n",
      "Deadheaded 11 operations\n",
      "Param Delta: 2,560,875 -> 2,437,600\n",
      "Pre-prune Test  Corrects: Top-1: 87.63%, 17.90 s\n",
      "Post-prune Test  Corrects: Top-1: 87.63%, 17.12 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.580078125, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.01877117156982422\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 878.00MiB\n",
      "2: 1.57GiB\n",
      "3: 2.49GiB\n",
      "4: 3.17GiB\n",
      "5: 3.25GiB\n",
      "6: 3.25GiB\n",
      "7: 3.41GiB\n",
      "8: 3.60GiB\n",
      "9: 3.82GiB\n",
      "10: 3.99GiB\n",
      "11: 4.09GiB\n",
      "12: 4.17GiB\n",
      "13: 4.29GiB\n",
      "14: 4.40GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.475, Losses [0: 2.0, 1: 1.03, 2: 0.51, 3: 0.77]Per Epoch: 4m,45s , Alloc: 4.61GiB  \n",
      "Train Corrects: Top-1: 84.20%, 4m,55s\n",
      "Test  Corrects: Top-1: 84.04%, 17.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.053, Losses [0: 1.61, 1: 0.79, 2: 0.36, 3: 0.5]Per Epoch: 4m,58s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 84.14%, 4m,55s\n",
      "Test  Corrects: Top-1: 79.88%, 17.51 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.060, Losses [0: 1.36, 1: 0.75, 2: 0.47, 3: 0.54]Per Epoch: 4m,50s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 84.37%, 4m,56s\n",
      "Test  Corrects: Top-1: 86.65%, 17.19 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.692, Losses [0: 1.1, 1: 0.69, 2: 0.47, 3: 1.24]Per Epoch: 4m,32s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 83.71%, 4m,56s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,437,600 -> 2,300,895\n",
      "Pre-prune Test  Corrects: Top-1: 83.46%, 17.22 s\n",
      "Post-prune Test  Corrects: Top-1: 83.46%, 17.08 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.566, Losses [0: 0.78, 1: 0.51, 2: 0.24, 3: 0.26]Per Epoch: 5m,2s  , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 86.43%, 4m,55s\n",
      "Test  Corrects: Top-1: 88.20%, 17.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.836, Losses [0: 0.79, 1: 0.51, 2: 0.43, 3: 0.49]Per Epoch: 5m,10s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 89.20%, 4m,55s\n",
      "Test  Corrects: Top-1: 89.02%, 17.26 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.205, Losses [0: 1.2, 1: 0.65, 2: 0.39, 3: 0.76]Per Epoch: 4m,46s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 90.57%, 4m,54s\n",
      "Test  Corrects: Top-1: 90.07%, 17.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.400, Losses [0: 0.7, 1: 0.53, 2: 0.16, 3: 0.12]Per Epoch: 4m,56s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 92.00%, 4m,55s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,300,895 -> 2,300,895\n",
      "Pre-prune Test  Corrects: Top-1: 90.32%, 17.57 s\n",
      "Post-prune Test  Corrects: Top-1: 90.32%, 17.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.237, I: 1.133], Loss Comp: [C: 2.076, E: 1.323, I: 0.50], Losses [0: 0.42, 1: 0.28, 2: 0.09, 3: 0.09]Per Epoch: 7m,5s  , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 92.21%, Comp: 0.23, 1.13 7m,9s\n",
      "Train Loss Components: C: 2.140, E: 1.305, I: 0.50\n",
      "Test  Corrects: Top-1: 87.89%, 17.29 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.235, I: 1.133], Loss Comp: [C: 2.714, E: 1.326, I: 0.50], Losses [0: 1.16, 1: 0.75, 2: 0.29, 3: 0.44]Per Epoch: 6m,52s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 85.28%, Comp: 0.23, 1.13 7m,7s\n",
      "Train Loss Components: C: 2.867, E: 1.326, I: 0.50\n",
      "Test  Corrects: Top-1: 84.90%, 17.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.227, I: 1.133], Loss Comp: [C: 2.639, E: 1.280, I: 0.50], Losses [0: 1.33, 1: 0.73, 2: 0.33, 3: 0.38]Per Epoch: 6m,58s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 82.53%, Comp: 0.23, 1.13 7m,10s\n",
      "Train Loss Components: C: 2.882, E: 1.280, I: 0.50\n",
      "Test  Corrects: Top-1: 84.16%, 17.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.232, I: 1.133], Loss Comp: [C: 2.517, E: 1.306, I: 0.50], Losses [0: 0.78, 1: 0.46, 2: 0.26, 3: 0.41]Per Epoch: 7m,9s  , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 84.49%, Comp: 0.23, 1.13 7m,9s\n",
      "Train Loss Components: C: 3.420, E: 1.306, I: 0.50\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,300,895 -> 2,291,294\n",
      "Pre-prune Test  Corrects: Top-1: 66.61%, 17.14 s\n",
      "Post-prune Test  Corrects: Top-1: 66.61%, 17.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.229, I: 1.133], Loss Comp: [C: 2.255, E: 1.296, I: 0.50], Losses [0: 0.76, 1: 0.43, 2: 0.18, 3: 0.18]Per Epoch: 6m,58s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 87.43%, Comp: 0.23, 1.13 7m,9s\n",
      "Train Loss Components: C: 1.997, E: 1.296, I: 0.50\n",
      "Test  Corrects: Top-1: 88.47%, 17.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.225, I: 1.133], Loss Comp: [C: 2.341, E: 1.264, I: 0.50], Losses [0: 0.8, 1: 0.32, 2: 0.25, 3: 0.3]Per Epoch: 6m,31s , Alloc: 4.96GiB   \n",
      "Train Corrects: Top-1: 89.18%, Comp: 0.23, 1.13 7m,8s\n",
      "Train Loss Components: C: 3.126, E: 1.263, I: 0.50\n",
      "Test  Corrects: Top-1: 88.38%, 17.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.218, I: 1.133], Loss Comp: [C: 2.325, E: 1.224, I: 0.50], Losses [0: 0.77, 1: 0.63, 2: 0.25, 3: 0.27]Per Epoch: 6m,56s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 90.51%, Comp: 0.22, 1.13 7m,8s\n",
      "Train Loss Components: C: 2.182, E: 1.224, I: 0.50\n",
      "Test  Corrects: Top-1: 87.30%, 17.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.218, I: 1.133], Loss Comp: [C: 2.676, E: 1.229, I: 0.50], Losses [0: 1.03, 1: 0.77, 2: 0.45, 3: 0.49]Per Epoch: 7m,12s , Alloc: 4.96GiB  \n",
      "Train Corrects: Top-1: 91.45%, Comp: 0.22, 1.13 7m,6s\n",
      "Train Loss Components: C: 2.442, E: 1.218, I: 0.50\n",
      "\n",
      "Deadheaded 9 operations\n",
      "Param Delta: 2,291,294 -> 2,190,037\n",
      "Pre-prune Test  Corrects: Top-1: 76.98%, 17.37 s\n",
      "Post-prune Test  Corrects: Top-1: 76.98%, 16.62 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.416015625, Batch: 64\n",
      "Restarting pruning at scale level 5, new comp ratio: 0.014078378677368164\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 62.00MiB\n",
      "1: 878.00MiB\n",
      "2: 1.57GiB\n",
      "3: 2.49GiB\n",
      "4: 3.17GiB\n",
      "5: 3.25GiB\n",
      "6: 3.25GiB\n",
      "7: 3.35GiB\n",
      "8: 3.51GiB\n",
      "9: 3.68GiB\n",
      "10: 3.84GiB\n",
      "11: 3.94GiB\n",
      "12: 4.03GiB\n",
      "13: 4.13GiB\n",
      "14: 4.25GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 0.954, Losses [0: 1.51, 1: 0.71, 2: 0.36, 3: 0.44]Per Epoch: 4m,33s , Alloc: 4.45GiB  \n",
      "Train Corrects: Top-1: 87.81%, 4m,41s\n",
      "Test  Corrects: Top-1: 87.24%, 16.90 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 0.832, Losses [0: 1.3, 1: 0.61, 2: 0.34, 3: 0.38]Per Epoch: 4m,46s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 85.97%, 4m,43s\n",
      "Test  Corrects: Top-1: 86.89%, 16.60 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 0.669, Losses [0: 1.09, 1: 0.48, 2: 0.27, 3: 0.3]Per Epoch: 4m,33s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 87.13%, 4m,43s\n",
      "Test  Corrects: Top-1: 88.66%, 16.67 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 0.953, Losses [0: 1.34, 1: 0.82, 2: 0.38, 3: 0.45]Per Epoch: 4m,35s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 89.21%, 4m,44s\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 2,190,037 -> 2,189,907\n",
      "Pre-prune Test  Corrects: Top-1: 85.87%, 16.68 s\n",
      "Post-prune Test  Corrects: Top-1: 85.87%, 16.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.443, Losses [0: 0.89, 1: 0.44, 2: 0.13, 3: 0.15]Per Epoch: 4m,33s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 88.71%, 4m,42s\n",
      "Test  Corrects: Top-1: 89.21%, 16.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.646, Losses [0: 0.79, 1: 0.51, 2: 0.32, 3: 0.32]Per Epoch: 4m,29s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 90.89%, 4m,40s\n",
      "Test  Corrects: Top-1: 90.19%, 16.64 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.595, Losses [0: 0.81, 1: 0.57, 2: 0.26, 3: 0.27]Per Epoch: 4m,24s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 92.48%, 4m,41s\n",
      "Test  Corrects: Top-1: 91.23%, 16.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.295, Losses [0: 0.43, 1: 0.37, 2: 0.11, 3: 0.11]Per Epoch: 4m,13s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 93.63%, 4m,41s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,189,907 -> 2,189,907\n",
      "Pre-prune Test  Corrects: Top-1: 91.58%, 16.93 s\n",
      "Post-prune Test  Corrects: Top-1: 91.58%, 16.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.226, I: 1.133], Loss Comp: [C: 2.515, E: 1.436, I: 0.55], Losses [0: 0.67, 1: 0.41, 2: 0.27, 3: 0.26]Per Epoch: 6m,55s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 93.53%, Comp: 0.23, 1.13 6m,51s\n",
      "Train Loss Components: C: 3.183, E: 1.424, I: 0.55\n",
      "Test  Corrects: Top-1: 87.54%, 16.79 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.224, I: 1.133], Loss Comp: [C: 2.705, E: 1.430, I: 0.55], Losses [0: 1.41, 1: 0.55, 2: 0.25, 3: 0.28]Per Epoch: 6m,37s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 87.67%, Comp: 0.22, 1.13 6m,52s\n",
      "Train Loss Components: C: 2.826, E: 1.417, I: 0.55\n",
      "Test  Corrects: Top-1: 87.20%, 16.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.220, I: 1.133], Loss Comp: [C: 2.967, E: 1.409, I: 0.55], Losses [0: 1.26, 1: 0.65, 2: 0.4, 3: 0.54]Per Epoch: 6m,15s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 81.22%, Comp: 0.22, 1.13 6m,53s\n",
      "Train Loss Components: C: 3.003, E: 1.409, I: 0.55\n",
      "Test  Corrects: Top-1: 85.20%, 16.98 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.218, I: 1.133], Loss Comp: [C: 2.717, E: 1.393, I: 0.55], Losses [0: 1.4, 1: 0.61, 2: 0.24, 3: 0.32]Per Epoch: 6m,47s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 84.56%, Comp: 0.22, 1.13 6m,51s\n",
      "Train Loss Components: C: 3.720, E: 1.393, I: 0.55\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,189,907 -> 2,189,907\n",
      "Pre-prune Test  Corrects: Top-1: 85.97%, 16.53 s\n",
      "Post-prune Test  Corrects: Top-1: 85.97%, 16.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.213, I: 1.133], Loss Comp: [C: 3.419, E: 1.350, I: 0.55], Losses [0: 1.89, 1: 1.23, 2: 0.63, 3: 0.76]Per Epoch: 6m,50s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 87.72%, Comp: 0.21, 1.13 6m,53s\n",
      "Train Loss Components: C: 2.807, E: 1.358, I: 0.55\n",
      "Test  Corrects: Top-1: 86.00%, 16.77 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.212, I: 1.133], Loss Comp: [C: 2.682, E: 1.351, I: 0.55], Losses [0: 0.84, 1: 0.57, 2: 0.34, 3: 0.43]Per Epoch: 6m,50s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 89.85%, Comp: 0.21, 1.13 6m,53s\n",
      "Train Loss Components: C: 2.775, E: 1.352, I: 0.55\n",
      "Test  Corrects: Top-1: 87.72%, 16.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.210, I: 1.133], Loss Comp: [C: 2.433, E: 1.337, I: 0.55], Losses [0: 0.6, 1: 0.34, 2: 0.27, 3: 0.3]Per Epoch: 6m,46s , Alloc: 4.76GiB   \n",
      "Train Corrects: Top-1: 91.36%, Comp: 0.21, 1.13 6m,53s\n",
      "Train Loss Components: C: 1.969, E: 1.349, I: 0.55\n",
      "Test  Corrects: Top-1: 88.51%, 16.58 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.210, I: 1.133], Loss Comp: [C: 2.173, E: 1.348, I: 0.55], Losses [0: 0.55, 1: 0.29, 2: 0.12, 3: 0.08]Per Epoch: 6m,45s , Alloc: 4.76GiB  \n",
      "Train Corrects: Top-1: 92.37%, Comp: 0.21, 1.13 6m,52s\n",
      "Train Loss Components: C: 2.229, E: 1.335, I: 0.55\n",
      "\n",
      "Deadheaded 9 operations\n",
      "Param Delta: 2,189,907 -> 2,128,330\n",
      "Pre-prune Test  Corrects: Top-1: 89.68%, 16.31 s\n",
      "Post-prune Test  Corrects: Top-1: 89.68%, 16.03 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.1796875, Batch: 64\n",
      "Cleaning at Prescale. Pre: 42.00MiB, Post: 42.00MiB\n",
      "\u001b[31mScaling from 5 to 6\u001b[0m\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 1.34GiB\n",
      "2: 2.50GiB\n",
      "3: 3.87GiB\n",
      "4: 4.87GiB\n",
      "5: 5.78GiB\n",
      "6: 6.15GiB\n",
      "7: 6.63GiB\n",
      "8: 6.96GiB\n",
      "9: 7.38GiB\n",
      "10: 7.46GiB\n",
      "11: 7.46GiB\n",
      "12: 7.56GiB\n",
      "13: 7.75GiB\n",
      "14: 7.97GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 15.756, Losses [0: 7.15, 1: 5.13, 2: 3.09, 3: 12.68]Per Epoch: 5m,36s , Alloc: 8.41GiB  \n",
      "Train Corrects: Top-1: 27.40%, 5m,39s\n",
      "Test  Corrects: Top-1: 33.45%, 19.61 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 10.650, Losses [0: 11.28, 1: 3.86, 2: 2.44, 3: 7.13]Per Epoch: 5m,25s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 34.30%, 5m,40s\n",
      "Test  Corrects: Top-1: 23.80%, 19.62 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 8.775, Losses [0: 7.27, 1: 3.37, 2: 1.96, 3: 6.25]Per Epoch: 5m,30s , Alloc: 8.67GiB   \n",
      "Train Corrects: Top-1: 39.12%, 5m,39s\n",
      "Test  Corrects: Top-1: 43.74%, 19.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 8.429, Losses [0: 7.31, 1: 3.62, 2: 2.17, 3: 5.81]Per Epoch: 5m,37s , Alloc: 8.67GiB   \n",
      "Train Corrects: Top-1: 44.74%, 5m,41s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,557,721 -> 7,557,721\n",
      "Pre-prune Test  Corrects: Top-1: 45.28%, 19.56 s\n",
      "Post-prune Test  Corrects: Top-1: 45.28%, 19.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.848, Losses [0: 2.57, 1: 1.81, 2: 0.84, 3: 1.8]Per Epoch: 5m,28s , Alloc: 8.67GiB    \n",
      "Train Corrects: Top-1: 49.71%, 5m,40s\n",
      "Test  Corrects: Top-1: 52.75%, 19.62 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 2.798, Losses [0: 2.68, 1: 1.98, 2: 1.11, 3: 1.64]Per Epoch: 5m,28s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 55.10%, 5m,40s\n",
      "Test  Corrects: Top-1: 61.27%, 19.60 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 3.997, Losses [0: 1.91, 1: 1.42, 2: 1.34, 3: 3.06]Per Epoch: 5m,36s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 60.50%, 5m,40s\n",
      "Test  Corrects: Top-1: 65.93%, 19.63 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.760, Losses [0: 1.42, 1: 1.2, 2: 0.83, 3: 1.07]Per Epoch: 5m,33s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 65.27%, 5m,40s\n",
      "\n",
      "Deadheaded 5 operations\n",
      "Param Delta: 7,557,721 -> 7,557,204\n",
      "Pre-prune Test  Corrects: Top-1: 70.49%, 19.61 s\n",
      "Post-prune Test  Corrects: Top-1: 70.49%, 19.53 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.214, I: 1.067], Loss Comp: [C: 1.390, E: 0.123, I: 0.01], Losses [0: 1.18, 1: 1.11, 2: 0.72, 3: 0.66]Per Epoch: 7m,25s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 68.30%, Comp: 0.21, 1.07 7m,25s\n",
      "Train Loss Components: C: 1.771, E: 0.123, I: 0.01\n",
      "Test  Corrects: Top-1: 72.32%, 19.46 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.206, I: 1.067], Loss Comp: [C: 7.839, E: 0.117, I: 0.01], Losses [0: 4.41, 1: 2.84, 2: 1.71, 3: 5.92]Per Epoch: 7m,12s , Alloc: 8.67GiB   \n",
      "Train Corrects: Top-1: 48.09%, Comp: 0.21, 1.07 7m,25s\n",
      "Train Loss Components: C: 13.302, E: 0.117, I: 0.01\n",
      "Test  Corrects: Top-1: 50.99%, 19.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.208, I: 1.000], Loss Comp: [C: 10.393, E: 0.119, I: 0.00], Losses [0: 4.1, 1: 2.68, 2: 1.63, 3: 8.59]Per Epoch: 7m,3s  , Alloc: 8.67GiB   \n",
      "Train Corrects: Top-1: 51.84%, Comp: 0.21, 1.00 7m,25s\n",
      "Train Loss Components: C: 5.452, E: 0.119, I: 0.00\n",
      "Test  Corrects: Top-1: 51.92%, 19.49 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 6.464, E: 0.118, I: 0.01], Losses [0: 4.48, 1: 2.71, 2: 1.48, 3: 4.6]Per Epoch: 7m,25s , Alloc: 8.67GiB    \n",
      "Train Corrects: Top-1: 54.62%, Comp: 0.21, 1.07 7m,25s\n",
      "Train Loss Components: C: 7.048, E: 0.118, I: 0.01\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,557,204 -> 7,557,204\n",
      "Pre-prune Test  Corrects: Top-1: 56.80%, 19.45 s\n",
      "Post-prune Test  Corrects: Top-1: 56.80%, 19.52 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.208, I: 1.067], Loss Comp: [C: 4.752, E: 0.119, I: 0.01], Losses [0: 2.74, 1: 2.53, 2: 1.38, 3: 3.3]Per Epoch: 7m,18s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 59.69%, Comp: 0.21, 1.07 7m,24s\n",
      "Train Loss Components: C: 5.136, E: 0.119, I: 0.01\n",
      "Test  Corrects: Top-1: 63.27%, 19.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 3.705, E: 0.118, I: 0.01], Losses [0: 2.73, 1: 2.03, 2: 0.91, 3: 2.45]Per Epoch: 7m,37s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 64.04%, Comp: 0.21, 1.07 7m,24s\n",
      "Train Loss Components: C: 2.799, E: 0.118, I: 0.01\n",
      "Test  Corrects: Top-1: 68.59%, 19.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 1.727, E: 0.118, I: 0.01], Losses [0: 1.37, 1: 0.9, 2: 0.59, 3: 1.03]Per Epoch: 7m,17s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 68.44%, Comp: 0.21, 1.07 7m,25s\n",
      "Train Loss Components: C: 3.555, E: 0.118, I: 0.01\n",
      "Test  Corrects: Top-1: 72.81%, 19.51 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 1.305, E: 0.118, I: 0.01], Losses [0: 1.29, 1: 0.85, 2: 0.56, 3: 0.64]Per Epoch: 7m,20s , Alloc: 8.67GiB  \n",
      "Train Corrects: Top-1: 71.99%, Comp: 0.21, 1.07 7m,25s\n",
      "Train Loss Components: C: 1.770, E: 0.118, I: 0.01\n",
      "\n",
      "Deadheaded 5 operations\n",
      "Param Delta: 7,557,204 -> 7,537,615\n",
      "Pre-prune Test  Corrects: Top-1: 75.41%, 19.48 s\n",
      "Post-prune Test  Corrects: Top-1: 75.41%, 18.97 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.8046875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.010558784008026123\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.23GiB\n",
      "2: 2.39GiB\n",
      "3: 3.62GiB\n",
      "4: 4.45GiB\n",
      "5: 5.30GiB\n",
      "6: 5.67GiB\n",
      "7: 6.16GiB\n",
      "8: 6.48GiB\n",
      "9: 6.90GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: 6.98GiB\n",
      "11: 6.98GiB\n",
      "12: 7.08GiB\n",
      "13: 7.29GiB\n",
      "14: 7.51GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 5.180, Losses [0: 3.69, 1: 2.02, 2: 1.15, 3: 3.81]Per Epoch: 5m,28s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 59.03%, 5m,28s\n",
      "Test  Corrects: Top-1: 58.48%, 18.99 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 5.345, Losses [0: 5.14, 1: 1.95, 2: 1.19, 3: 3.69]Per Epoch: 5m,17s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 60.32%, 5m,27s\n",
      "Test  Corrects: Top-1: 65.70%, 18.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 4.020, Losses [0: 3.82, 1: 1.46, 2: 0.75, 3: 2.81]Per Epoch: 5m,20s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 62.43%, 5m,28s\n",
      "Test  Corrects: Top-1: 61.27%, 19.00 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 5.562, Losses [0: 4.01, 1: 2.42, 2: 1.19, 3: 4.04]Per Epoch: 5m,13s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 65.34%, 5m,28s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 7,537,615 -> 7,537,486\n",
      "Pre-prune Test  Corrects: Top-1: 66.08%, 18.96 s\n",
      "Post-prune Test  Corrects: Top-1: 66.08%, 18.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 4.404, Losses [0: 2.03, 1: 0.85, 2: 1.23, 3: 3.58]Per Epoch: 5m,9s  , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 68.87%, 5m,27s\n",
      "Test  Corrects: Top-1: 72.98%, 18.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.411, Losses [0: 1.45, 1: 1.29, 2: 0.5, 3: 0.76]Per Epoch: 5m,13s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 72.27%, 5m,27s\n",
      "Test  Corrects: Top-1: 74.12%, 18.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 2.117, Losses [0: 1.94, 1: 1.16, 2: 0.64, 3: 1.37]Per Epoch: 5m,18s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 75.71%, 5m,27s\n",
      "Test  Corrects: Top-1: 76.65%, 18.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.777, Losses [0: 1.6, 1: 1.03, 2: 0.76, 3: 1.1]Per Epoch: 5m,21s , Alloc: 8.16GiB   \n",
      "Train Corrects: Top-1: 78.00%, 5m,27s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,537,486 -> 7,537,486\n",
      "Pre-prune Test  Corrects: Top-1: 79.55%, 18.92 s\n",
      "Post-prune Test  Corrects: Top-1: 79.55%, 18.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 1.336, E: 0.240, I: 0.01], Losses [0: 1.16, 1: 0.75, 2: 0.53, 3: 0.6]Per Epoch: 6m,53s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 79.96%, Comp: 0.21, 1.07 7m,9s\n",
      "Train Loss Components: C: 1.677, E: 0.240, I: 0.01\n",
      "Test  Corrects: Top-1: 80.08%, 18.88 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.000], Loss Comp: [C: 6.641, E: 0.240, I: 0.00], Losses [0: 4.51, 1: 3.13, 2: 1.09, 3: 4.65]Per Epoch: 6m,47s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 65.85%, Comp: 0.21, 1.00 7m,9s\n",
      "Train Loss Components: C: 4.939, E: 0.240, I: 0.00\n",
      "Test  Corrects: Top-1: 67.08%, 18.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.206, I: 1.067], Loss Comp: [C: 3.813, E: 0.238, I: 0.01], Losses [0: 2.84, 1: 2.54, 2: 0.68, 3: 2.35]Per Epoch: 6m,49s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 67.27%, Comp: 0.21, 1.07 7m,9s\n",
      "Train Loss Components: C: 1.180, E: 0.238, I: 0.01\n",
      "Test  Corrects: Top-1: 69.91%, 18.87 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 3.330, E: 0.240, I: 0.01], Losses [0: 1.88, 1: 0.82, 2: 0.7, 3: 2.4]Per Epoch: 6m,56s , Alloc: 8.16GiB   \n",
      "Train Corrects: Top-1: 70.42%, Comp: 0.21, 1.07 7m,10s\n",
      "Train Loss Components: C: 4.685, E: 0.240, I: 0.01\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,537,486 -> 7,537,486\n",
      "Pre-prune Test  Corrects: Top-1: 68.94%, 18.90 s\n",
      "Post-prune Test  Corrects: Top-1: 68.94%, 18.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 3.169, E: 0.240, I: 0.01], Losses [0: 1.8, 1: 1.25, 2: 0.75, 3: 2.16]Per Epoch: 6m,53s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 73.31%, Comp: 0.21, 1.07 7m,9s\n",
      "Train Loss Components: C: 2.658, E: 0.240, I: 0.01\n",
      "Test  Corrects: Top-1: 73.15%, 18.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.206, I: 1.067], Loss Comp: [C: 2.754, E: 0.238, I: 0.01], Losses [0: 3.02, 1: 1.03, 2: 0.75, 3: 1.54]Per Epoch: 7m,2s  , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 76.57%, Comp: 0.21, 1.00 7m,9s\n",
      "Train Loss Components: C: 1.626, E: 0.238, I: 0.00\n",
      "Test  Corrects: Top-1: 76.71%, 18.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 2.154, E: 0.240, I: 0.01], Losses [0: 1.75, 1: 1.13, 2: 0.58, 3: 1.21]Per Epoch: 7m,0s  , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 79.73%, Comp: 0.21, 1.07 7m,8s\n",
      "Train Loss Components: C: 1.692, E: 0.240, I: 0.01\n",
      "Test  Corrects: Top-1: 80.98%, 18.88 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.207, I: 1.067], Loss Comp: [C: 1.186, E: 0.240, I: 0.01], Losses [0: 0.78, 1: 0.55, 2: 0.43, 3: 0.58]Per Epoch: 6m,46s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 82.06%, Comp: 0.21, 1.07 7m,9s\n",
      "Train Loss Components: C: 1.504, E: 0.240, I: 0.01\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,537,486 -> 7,537,486\n",
      "Pre-prune Test  Corrects: Top-1: 83.06%, 18.89 s\n",
      "Post-prune Test  Corrects: Top-1: 83.06%, 18.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.8046875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.007919088006019592\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.23GiB\n",
      "2: 2.39GiB\n",
      "3: 3.61GiB\n",
      "4: 4.45GiB\n",
      "5: 5.30GiB\n",
      "6: 5.67GiB\n",
      "7: 6.16GiB\n",
      "8: 6.48GiB\n",
      "9: 6.90GiB\n",
      "10: 6.98GiB\n",
      "11: 6.98GiB\n",
      "12: 7.08GiB\n",
      "13: 7.29GiB\n",
      "14: 7.51GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 4.648, Losses [0: 3.58, 1: 1.71, 2: 0.91, 3: 3.41]Per Epoch: 5m,14s , Alloc: 7.89GiB  \n",
      "Train Corrects: Top-1: 71.62%, 5m,27s\n",
      "Test  Corrects: Top-1: 73.11%, 18.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 4.393, Losses [0: 4.31, 1: 1.97, 2: 1.02, 3: 2.93]Per Epoch: 5m,24s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 71.56%, 5m,28s\n",
      "Test  Corrects: Top-1: 77.54%, 18.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 5.096, Losses [0: 3.43, 1: 1.73, 2: 0.87, 3: 3.89]Per Epoch: 5m,15s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 71.52%, 5m,27s\n",
      "Test  Corrects: Top-1: 69.80%, 18.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 3.328, Losses [0: 3.66, 1: 1.81, 2: 0.75, 3: 2.08]Per Epoch: 5m,17s , Alloc: 8.16GiB   \n",
      "Train Corrects: Top-1: 70.68%, 5m,27s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,537,486 -> 7,537,486\n",
      "Pre-prune Test  Corrects: Top-1: 73.82%, 18.94 s\n",
      "Post-prune Test  Corrects: Top-1: 73.82%, 18.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.191, Losses [0: 2.37, 1: 1.33, 2: 0.67, 3: 1.32]Per Epoch: 5m,24s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 75.56%, 5m,27s\n",
      "Test  Corrects: Top-1: 80.38%, 18.90 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 2.906, Losses [0: 2.15, 1: 1.21, 2: 0.86, 3: 2.06]Per Epoch: 5m,12s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 79.10%, 5m,27s\n",
      "Test  Corrects: Top-1: 79.59%, 18.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.137, Losses [0: 1.28, 1: 0.71, 2: 0.38, 3: 0.66]Per Epoch: 5m,17s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 81.44%, 5m,27s\n",
      "Test  Corrects: Top-1: 81.85%, 18.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.020, Losses [0: 0.94, 1: 0.62, 2: 0.62, 3: 0.58]Per Epoch: 5m,17s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 83.46%, 5m,27s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,537,486 -> 7,537,486\n",
      "Pre-prune Test  Corrects: Top-1: 84.10%, 18.87 s\n",
      "Post-prune Test  Corrects: Top-1: 84.10%, 18.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.206, I: 1.067], Loss Comp: [C: 1.339, E: 0.361, I: 0.02], Losses [0: 0.98, 1: 0.46, 2: 0.46, 3: 0.58]Per Epoch: 6m,50s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 84.41%, Comp: 0.21, 1.07 7m,9s\n",
      "Train Loss Components: C: 1.490, E: 0.361, I: 0.02\n",
      "Test  Corrects: Top-1: 85.20%, 18.88 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.206, I: 1.067], Loss Comp: [C: 2.095, E: 0.363, I: 0.02], Losses [0: 2.27, 1: 0.82, 2: 0.42, 3: 1.01]Per Epoch: 6m,50s , Alloc: 8.16GiB   \n",
      "Train Corrects: Top-1: 69.41%, Comp: 0.21, 1.07 7m,8s\n",
      "Train Loss Components: C: 7.284, E: 0.363, I: 0.02\n",
      "Test  Corrects: Top-1: 57.60%, 18.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.201, I: 1.067], Loss Comp: [C: 2.927, E: 0.355, I: 0.02], Losses [0: 3.13, 1: 1.93, 2: 0.62, 3: 1.42]Per Epoch: 6m,59s , Alloc: 8.16GiB   \n",
      "Train Corrects: Top-1: 71.98%, Comp: 0.20, 1.07 7m,8s\n",
      "Train Loss Components: C: 3.430, E: 0.355, I: 0.02\n",
      "Test  Corrects: Top-1: 10.00%, 18.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.204, I: 1.067], Loss Comp: [C: 2.255, E: 0.357, I: 0.02], Losses [0: 1.79, 1: 0.89, 2: 0.46, 3: 1.25]Per Epoch: 7m,11s , Alloc: 8.16GiB   \n",
      "Train Corrects: Top-1: 74.88%, Comp: 0.20, 1.07 7m,10s\n",
      "Train Loss Components: C: 2.964, E: 0.357, I: 0.02\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,537,486 -> 7,537,486\n",
      "Pre-prune Test  Corrects: Top-1: 10.01%, 18.91 s\n",
      "Post-prune Test  Corrects: Top-1: 10.01%, 18.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.201, I: 1.067], Loss Comp: [C: 3.891, E: 0.353, I: 0.02], Losses [0: 2.13, 1: 1.03, 2: 0.81, 3: 2.72]Per Epoch: 6m,41s , Alloc: 8.16GiB   \n",
      "Train Corrects: Top-1: 77.27%, Comp: 0.20, 1.07 7m,8s\n",
      "Train Loss Components: C: 2.180, E: 0.353, I: 0.02\n",
      "Test  Corrects: Top-1: 10.00%, 18.90 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.202, I: 1.067], Loss Comp: [C: 1.774, E: 0.355, I: 0.02], Losses [0: 1.44, 1: 0.86, 2: 0.49, 3: 0.84]Per Epoch: 6m,50s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 79.63%, Comp: 0.20, 1.07 7m,16s\n",
      "Train Loss Components: C: 1.609, E: 0.355, I: 0.02\n",
      "Test  Corrects: Top-1: 16.93%, 18.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.202, I: 1.000], Loss Comp: [C: 1.750, E: 0.355, I: 0.00], Losses [0: 1.5, 1: 0.87, 2: 0.46, 3: 0.83]Per Epoch: 6m,52s , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 82.06%, Comp: 0.20, 1.07 7m,9s\n",
      "Train Loss Components: C: 1.977, E: 0.355, I: 0.02\n",
      "Test  Corrects: Top-1: 78.69%, 18.90 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.204, I: 1.067], Loss Comp: [C: 1.805, E: 0.357, I: 0.02], Losses [0: 0.79, 1: 0.67, 2: 0.57, 3: 1.02]Per Epoch: 7m,6s  , Alloc: 8.16GiB  \n",
      "Train Corrects: Top-1: 84.24%, Comp: 0.20, 1.07 7m,10s\n",
      "Train Loss Components: C: 3.610, E: 0.357, I: 0.02\n",
      "\n",
      "Deadheaded 3 operations\n",
      "Param Delta: 7,537,486 -> 7,491,915\n",
      "Pre-prune Test  Corrects: Top-1: 83.72%, 18.92 s\n",
      "Post-prune Test  Corrects: Top-1: 10.00%, 18.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.609375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.005939316004514694\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.23GiB\n",
      "2: 2.27GiB\n",
      "3: 3.48GiB\n",
      "4: 4.33GiB\n",
      "5: 5.18GiB\n",
      "6: 5.54GiB\n",
      "7: 5.93GiB\n",
      "8: 6.28GiB\n",
      "9: 6.68GiB\n",
      "10: 6.77GiB\n",
      "11: 6.77GiB\n",
      "12: 6.88GiB\n",
      "13: 7.10GiB\n",
      "14: 7.31GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 6.925, Losses [0: 4.05, 1: 2.1, 2: 1.34, 3: 5.43]Per Epoch: 5m,8s  , Alloc: 7.70GiB    \n",
      "Train Corrects: Top-1: 72.23%, 5m,19s\n",
      "Test  Corrects: Top-1: 66.86%, 18.60 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.918, Losses [0: 4.39, 1: 1.65, 2: 0.68, 3: 1.57]Per Epoch: 4m,59s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 70.49%, 5m,19s\n",
      "Test  Corrects: Top-1: 77.37%, 18.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.878, Losses [0: 2.81, 1: 1.29, 2: 0.6, 3: 0.94]Per Epoch: 5m,7s  , Alloc: 7.96GiB   \n",
      "Train Corrects: Top-1: 73.83%, 5m,19s\n",
      "Test  Corrects: Top-1: 76.05%, 18.61 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.784, Losses [0: 2.29, 1: 0.94, 2: 0.56, 3: 1.03]Per Epoch: 5m,14s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 74.63%, 5m,19s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,491,915 -> 7,491,915\n",
      "Pre-prune Test  Corrects: Top-1: 80.50%, 18.57 s\n",
      "Post-prune Test  Corrects: Top-1: 80.50%, 18.55 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.979, Losses [0: 2.29, 1: 1.37, 2: 0.64, 3: 1.12]Per Epoch: 5m,2s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 75.81%, 5m,19s\n",
      "Test  Corrects: Top-1: 80.54%, 18.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.250, Losses [0: 1.45, 1: 0.76, 2: 0.49, 3: 0.71]Per Epoch: 5m,5s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 78.53%, 5m,19s\n",
      "Test  Corrects: Top-1: 78.79%, 18.53 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.028, Losses [0: 1.25, 1: 0.66, 2: 0.46, 3: 0.55]Per Epoch: 5m,7s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 82.60%, 5m,20s\n",
      "Test  Corrects: Top-1: 84.36%, 18.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.841, Losses [0: 1.21, 1: 0.65, 2: 0.38, 3: 0.39]Per Epoch: 5m,16s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 84.64%, 5m,19s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,491,915 -> 7,491,915\n",
      "Pre-prune Test  Corrects: Top-1: 85.75%, 18.55 s\n",
      "Post-prune Test  Corrects: Top-1: 85.75%, 18.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.202, I: 1.067], Loss Comp: [C: 1.216, E: 0.479, I: 0.03], Losses [0: 0.58, 1: 0.45, 2: 0.42, 3: 0.42]Per Epoch: 6m,40s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 85.24%, Comp: 0.20, 1.07 7m,0s\n",
      "Train Loss Components: C: 0.978, E: 0.479, I: 0.03\n",
      "Test  Corrects: Top-1: 66.06%, 18.55 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.204, I: 1.067], Loss Comp: [C: 3.722, E: 0.481, I: 0.03], Losses [0: 2.86, 1: 2.15, 2: 0.97, 3: 2.02]Per Epoch: 7m,5s  , Alloc: 7.96GiB   \n",
      "Train Corrects: Top-1: 68.52%, Comp: 0.20, 1.07 7m,1s\n",
      "Train Loss Components: C: 10.533, E: 0.481, I: 0.03\n",
      "Test  Corrects: Top-1: 55.02%, 18.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.202, I: 1.067], Loss Comp: [C: 4.580, E: 0.477, I: 0.03], Losses [0: 4.82, 1: 2.5, 2: 0.8, 3: 2.45]Per Epoch: 6m,51s , Alloc: 7.96GiB     \n",
      "Train Corrects: Top-1: 64.28%, Comp: 0.20, 1.07 7m,1s\n",
      "Train Loss Components: C: 2.846, E: 0.477, I: 0.03\n",
      "Test  Corrects: Top-1: 73.68%, 18.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.204, I: 1.067], Loss Comp: [C: 2.891, E: 0.481, I: 0.03], Losses [0: 3.14, 1: 1.52, 2: 0.62, 3: 1.33]Per Epoch: 6m,52s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 72.02%, Comp: 0.20, 1.07 7m,1s\n",
      "Train Loss Components: C: 2.553, E: 0.477, I: 0.03\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,491,915 -> 7,491,915\n",
      "Pre-prune Test  Corrects: Top-1: 71.06%, 18.52 s\n",
      "Post-prune Test  Corrects: Top-1: 71.06%, 18.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.201, I: 1.067], Loss Comp: [C: 1.679, E: 0.475, I: 0.03], Losses [0: 1.56, 1: 1.31, 2: 0.44, 3: 0.52]Per Epoch: 6m,33s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 75.48%, Comp: 0.20, 1.07 7m,0s\n",
      "Train Loss Components: C: 2.720, E: 0.479, I: 0.03\n",
      "Test  Corrects: Top-1: 79.87%, 18.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.201, I: 1.067], Loss Comp: [C: 1.945, E: 0.476, I: 0.03], Losses [0: 1.88, 1: 1.17, 2: 0.57, 3: 0.72]Per Epoch: 6m,58s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 78.73%, Comp: 0.20, 1.07 7m,0s\n",
      "Train Loss Components: C: 2.180, E: 0.472, I: 0.03\n",
      "Test  Corrects: Top-1: 59.31%, 18.50 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.201, I: 1.067], Loss Comp: [C: 1.975, E: 0.476, I: 0.03], Losses [0: 1.73, 1: 1.03, 2: 0.6, 3: 0.8]Per Epoch: 6m,55s , Alloc: 7.96GiB   \n",
      "Train Corrects: Top-1: 81.72%, Comp: 0.20, 1.07 7m,0s\n",
      "Train Loss Components: C: 2.951, E: 0.474, I: 0.03\n",
      "Test  Corrects: Top-1: 84.48%, 18.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.200, I: 1.067], Loss Comp: [C: 1.287, E: 0.472, I: 0.03], Losses [0: 0.84, 1: 0.51, 2: 0.53, 3: 0.41]Per Epoch: 7m,15s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 83.51%, Comp: 0.20, 1.07 7m,0s\n",
      "Train Loss Components: C: 1.935, E: 0.476, I: 0.03\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 7,491,915 -> 7,491,402\n",
      "Pre-prune Test  Corrects: Top-1: 84.38%, 18.54 s\n",
      "Post-prune Test  Corrects: Top-1: 84.38%, 18.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.60546875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.004454487003386021\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.23GiB\n",
      "2: 2.27GiB\n",
      "3: 3.48GiB\n",
      "4: 4.33GiB\n",
      "5: 5.18GiB\n",
      "6: 5.54GiB\n",
      "7: 5.93GiB\n",
      "8: 6.28GiB\n",
      "9: 6.68GiB\n",
      "10: 6.77GiB\n",
      "11: 6.77GiB\n",
      "12: 6.88GiB\n",
      "13: 7.08GiB\n",
      "14: 7.29GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 5.062, Losses [0: 3.2, 1: 1.4, 2: 1.07, 3: 3.93]Per Epoch: 5m,15s , Alloc: 7.69GiB     \n",
      "Train Corrects: Top-1: 72.91%, 5m,18s\n",
      "Test  Corrects: Top-1: 54.05%, 18.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.070, Losses [0: 2.12, 1: 1.3, 2: 0.65, 3: 1.26]Per Epoch: 5m,12s , Alloc: 7.96GiB    \n",
      "Train Corrects: Top-1: 70.19%, 5m,19s\n",
      "Test  Corrects: Top-1: 78.11%, 18.50 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.899, Losses [0: 3.63, 1: 1.5, 2: 0.95, 3: 1.68]Per Epoch: 5m,15s , Alloc: 7.96GiB    \n",
      "Train Corrects: Top-1: 71.97%, 5m,19s\n",
      "Test  Corrects: Top-1: 79.21%, 18.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.395, Losses [0: 2.84, 1: 1.45, 2: 0.78, 3: 1.38]Per Epoch: 5m,5s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 74.87%, 5m,18s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 7,491,402 -> 7,491,273\n",
      "Pre-prune Test  Corrects: Top-1: 78.88%, 18.52 s\n",
      "Post-prune Test  Corrects: Top-1: 78.88%, 18.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.991, Losses [0: 3.06, 1: 1.28, 2: 0.85, 3: 0.95]Per Epoch: 5m,6s  , Alloc: 7.96GiB   \n",
      "Train Corrects: Top-1: 75.21%, 5m,18s\n",
      "Test  Corrects: Top-1: 79.00%, 18.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.057, Losses [0: 1.41, 1: 0.47, 2: 0.43, 3: 0.6]Per Epoch: 5m,3s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 79.49%, 5m,18s\n",
      "Test  Corrects: Top-1: 82.96%, 18.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.684, Losses [0: 1.15, 1: 0.53, 2: 0.3, 3: 0.29]Per Epoch: 5m,7s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 82.58%, 5m,18s\n",
      "Test  Corrects: Top-1: 84.82%, 18.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.847, Losses [0: 1.1, 1: 0.72, 2: 0.42, 3: 0.4]Per Epoch: 5m,4s  , Alloc: 7.96GiB   \n",
      "Train Corrects: Top-1: 84.08%, 5m,18s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 7,491,273 -> 7,481,672\n",
      "Pre-prune Test  Corrects: Top-1: 85.70%, 18.47 s\n",
      "Post-prune Test  Corrects: Top-1: 85.70%, 18.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.200, I: 1.067], Loss Comp: [C: 2.079, E: 0.595, I: 0.03], Losses [0: 1.27, 1: 0.72, 2: 0.56, 3: 0.94]Per Epoch: 6m,43s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 84.63%, Comp: 0.20, 1.07 6m,55s\n",
      "Train Loss Components: C: 1.640, E: 0.595, I: 0.03\n",
      "Test  Corrects: Top-1: 86.03%, 18.22 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.200, I: 1.067], Loss Comp: [C: 3.353, E: 0.595, I: 0.03], Losses [0: 4.11, 1: 1.65, 2: 0.58, 3: 1.46]Per Epoch: 6m,39s , Alloc: 7.96GiB   \n",
      "Train Corrects: Top-1: 71.49%, Comp: 0.20, 1.07 6m,55s\n",
      "Train Loss Components: C: 1.868, E: 0.595, I: 0.03\n",
      "Test  Corrects: Top-1: 63.24%, 18.20 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.199, I: 1.067], Loss Comp: [C: 9.752, E: 0.593, I: 0.03], Losses [0: 3.1, 1: 2.67, 2: 1.72, 3: 7.63]Per Epoch: 7m,7s  , Alloc: 7.96GiB    \n",
      "Train Corrects: Top-1: 72.27%, Comp: 0.20, 1.07 6m,55s\n",
      "Train Loss Components: C: 12.253, E: 0.593, I: 0.03\n",
      "Test  Corrects: Top-1: 60.57%, 18.20 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.199, I: 1.067], Loss Comp: [C: 2.559, E: 0.593, I: 0.03], Losses [0: 3.15, 1: 2.04, 2: 0.64, 3: 0.77]Per Epoch: 6m,31s , Alloc: 7.96GiB   \n",
      "Train Corrects: Top-1: 71.86%, Comp: 0.20, 1.07 6m,56s\n",
      "Train Loss Components: C: 2.691, E: 0.593, I: 0.03\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,481,672 -> 7,481,672\n",
      "Pre-prune Test  Corrects: Top-1: 80.50%, 18.20 s\n",
      "Post-prune Test  Corrects: Top-1: 80.50%, 18.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.199, I: 1.067], Loss Comp: [C: 1.668, E: 0.593, I: 0.03], Losses [0: 1.19, 1: 0.62, 2: 0.45, 3: 0.59]Per Epoch: 7m,0s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 78.69%, Comp: 0.20, 1.07 6m,54s\n",
      "Train Loss Components: C: 4.244, E: 0.593, I: 0.03\n",
      "Test  Corrects: Top-1: 82.06%, 18.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.199, I: 1.067], Loss Comp: [C: 1.992, E: 0.593, I: 0.03], Losses [0: 2.19, 1: 1.03, 2: 0.45, 3: 0.63]Per Epoch: 6m,38s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 80.92%, Comp: 0.20, 1.07 6m,56s\n",
      "Train Loss Components: C: 1.517, E: 0.593, I: 0.03\n",
      "Test  Corrects: Top-1: 83.88%, 18.19 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.198, I: 1.067], Loss Comp: [C: 1.526, E: 0.591, I: 0.03], Losses [0: 1.26, 1: 0.87, 2: 0.39, 3: 0.4]Per Epoch: 6m,43s , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 82.80%, Comp: 0.20, 1.07 6m,55s\n",
      "Train Loss Components: C: 2.367, E: 0.591, I: 0.03\n",
      "Test  Corrects: Top-1: 84.49%, 18.20 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.198, I: 1.067], Loss Comp: [C: 1.358, E: 0.591, I: 0.03], Losses [0: 0.84, 1: 0.42, 2: 0.38, 3: 0.41]Per Epoch: 7m,2s  , Alloc: 7.96GiB  \n",
      "Train Corrects: Top-1: 84.64%, Comp: 0.20, 1.07 6m,55s\n",
      "Train Loss Components: C: 1.168, E: 0.591, I: 0.03\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 7,481,672 -> 7,481,159\n",
      "Pre-prune Test  Corrects: Top-1: 86.06%, 18.20 s\n",
      "Post-prune Test  Corrects: Top-1: 86.06%, 18.19 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.49609375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.0033408652525395155\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.23GiB\n",
      "2: 2.16GiB\n",
      "3: 3.31GiB\n",
      "4: 4.22GiB\n",
      "5: 5.07GiB\n",
      "6: 5.43GiB\n",
      "7: 5.82GiB\n",
      "8: 6.17GiB\n",
      "9: 6.57GiB\n",
      "10: 6.66GiB\n",
      "11: 6.66GiB\n",
      "12: 6.77GiB\n",
      "13: 6.97GiB\n",
      "14: 7.18GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.651, Losses [0: 2.21, 1: 1.35, 2: 0.5, 3: 0.84]Per Epoch: 5m,4s  , Alloc: 7.58GiB    \n",
      "Train Corrects: Top-1: 75.79%, 5m,13s\n",
      "Test  Corrects: Top-1: 78.30%, 18.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 13.793, Losses [0: 2.12, 1: 1.23, 2: 0.62, 3: 13.0]Per Epoch: 5m,8s  , Alloc: 7.85GiB  \n",
      "Train Corrects: Top-1: 72.88%, 5m,13s\n",
      "Test  Corrects: Top-1: 77.97%, 18.19 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 3.041, Losses [0: 4.85, 1: 1.79, 2: 0.74, 3: 1.57]Per Epoch: 5m,7s  , Alloc: 7.85GiB   \n",
      "Train Corrects: Top-1: 71.11%, 5m,13s\n",
      "Test  Corrects: Top-1: 75.56%, 18.20 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.546, Losses [0: 2.31, 1: 1.18, 2: 0.57, 3: 0.73]Per Epoch: 5m,2s  , Alloc: 7.85GiB   \n",
      "Train Corrects: Top-1: 74.85%, 5m,13s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,481,159 -> 7,481,159\n",
      "Pre-prune Test  Corrects: Top-1: 76.77%, 18.23 s\n",
      "Post-prune Test  Corrects: Top-1: 76.77%, 18.23 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.956, Losses [0: 2.84, 1: 1.22, 2: 0.62, 3: 1.02]Per Epoch: 5m,9s  , Alloc: 7.85GiB   \n",
      "Train Corrects: Top-1: 76.11%, 5m,13s\n",
      "Test  Corrects: Top-1: 79.76%, 18.19 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.294, Losses [0: 2.38, 1: 1.11, 2: 0.42, 3: 0.51]Per Epoch: 5m,0s  , Alloc: 7.85GiB  \n",
      "Train Corrects: Top-1: 80.03%, 5m,13s\n",
      "Test  Corrects: Top-1: 82.45%, 18.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.041, Losses [0: 1.36, 1: 0.64, 2: 0.48, 3: 0.55]Per Epoch: 5m,3s  , Alloc: 7.85GiB  \n",
      "Train Corrects: Top-1: 83.25%, 5m,13s\n",
      "Test  Corrects: Top-1: 85.00%, 18.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.882, Losses [0: 1.02, 1: 0.6, 2: 0.45, 3: 0.47]Per Epoch: 5m,9s  , Alloc: 7.85GiB  \n",
      "Train Corrects: Top-1: 84.50%, 5m,13s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,481,159 -> 7,481,159\n",
      "Pre-prune Test  Corrects: Top-1: 86.27%, 18.20 s\n",
      "Post-prune Test  Corrects: Top-1: 86.27%, 18.20 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.198, I: 1.067], Loss Comp: [C: 1.160, E: 0.713, I: 0.04], Losses [0: 0.33, 1: 0.36, 2: 0.26, 3: 0.22]Per Epoch: 6m,38s , Alloc: 7.85GiB  \n",
      "Train Corrects: Top-1: 85.42%, Comp: 0.20, 1.07 6m,53s\n",
      "Train Loss Components: C: 1.472, E: 0.713, I: 0.04\n",
      "Test  Corrects: Top-1: 86.34%, 18.15 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.198, I: 1.067], Loss Comp: [C: 1.746, E: 0.712, I: 0.04], Losses [0: 1.8, 1: 0.71, 2: 0.38, 3: 0.41]Per Epoch: 7m,7s  , Alloc: 7.85GiB   \n",
      "Train Corrects: Top-1: 76.88%, Comp: 0.20, 1.00 6m,54s\n",
      "Train Loss Components: C: 1.370, E: 0.712, I: 0.00\n",
      "Test  Corrects: Top-1: 69.20%, 18.19 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.193, I: 1.067], Loss Comp: [C: 2.611, E: 0.700, I: 0.04], Losses [0: 2.49, 1: 1.35, 2: 0.63, 3: 0.98]Per Epoch: 6m,45s , Alloc: 7.85GiB   \n",
      "Train Corrects: Top-1: 73.01%, Comp: 0.19, 1.07 6m,54s\n",
      "Train Loss Components: C: 4.328, E: 0.700, I: 0.04\n",
      "Test  Corrects: Top-1: 79.05%, 18.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.189, I: 1.067], Loss Comp: [C: 2.130, E: 0.684, I: 0.04], Losses [0: 2.43, 1: 1.14, 2: 0.55, 3: 0.58]Per Epoch: 6m,30s , Alloc: 7.85GiB   \n",
      "Train Corrects: Top-1: 75.13%, Comp: 0.19, 1.07 6m,54s\n",
      "Train Loss Components: C: 8.052, E: 0.674, I: 0.04\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,481,159 -> 7,481,159\n",
      "Pre-prune Test  Corrects: Top-1: 63.44%, 18.20 s\n",
      "Post-prune Test  Corrects: Top-1: 63.44%, 18.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.192, I: 1.067], Loss Comp: [C: 3.147, E: 0.693, I: 0.04], Losses [0: 3.09, 1: 1.62, 2: 0.83, 3: 1.31]Per Epoch: 6m,46s , Alloc: 7.85GiB   \n",
      "Train Corrects: Top-1: 77.64%, Comp: 0.19, 1.07 6m,54s\n",
      "Train Loss Components: C: 13.805, E: 0.693, I: 0.04\n",
      "Test  Corrects: Top-1: 75.87%, 18.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.190, I: 1.067], Loss Comp: [C: 1.781, E: 0.690, I: 0.04], Losses [0: 1.55, 1: 0.78, 2: 0.43, 3: 0.5]Per Epoch: 6m,36s , Alloc: 7.85GiB  \n",
      "Train Corrects: Top-1: 79.99%, Comp: 0.19, 1.07 6m,53s\n",
      "Train Loss Components: C: 1.472, E: 0.690, I: 0.04\n",
      "Test  Corrects: Top-1: 83.92%, 18.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.190, I: 1.067], Loss Comp: [C: 1.632, E: 0.690, I: 0.04], Losses [0: 1.24, 1: 0.77, 2: 0.4, 3: 0.42]Per Epoch: 7m,9s  , Alloc: 7.85GiB    \n",
      "Train Corrects: Top-1: 83.04%, Comp: 0.19, 1.07 6m,54s\n",
      "Train Loss Components: C: 1.523, E: 0.690, I: 0.04\n",
      "Test  Corrects: Top-1: 85.70%, 18.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.192, I: 1.067], Loss Comp: [C: 1.613, E: 0.696, I: 0.04], Losses [0: 1.14, 1: 0.7, 2: 0.42, 3: 0.43]Per Epoch: 6m,47s , Alloc: 7.85GiB  \n",
      "Train Corrects: Top-1: 84.75%, Comp: 0.19, 1.07 6m,54s\n",
      "Train Loss Components: C: 1.958, E: 0.696, I: 0.04\n",
      "\n",
      "Deadheaded 5 operations\n",
      "Param Delta: 7,481,159 -> 7,288,258\n",
      "Pre-prune Test  Corrects: Top-1: 86.04%, 18.20 s\n",
      "Post-prune Test  Corrects: Top-1: 86.05%, 17.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.17578125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.0025056489394046366\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.08GiB\n",
      "4: 3.98GiB\n",
      "5: 4.83GiB\n",
      "6: 5.20GiB\n",
      "7: 5.51GiB\n",
      "8: 5.84GiB\n",
      "9: 6.26GiB\n",
      "10: 6.34GiB\n",
      "11: 6.34GiB\n",
      "12: 6.47GiB\n",
      "13: 6.65GiB\n",
      "14: 6.86GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.373, Losses [0: 4.33, 1: 2.12, 2: 0.83, 3: 0.92]Per Epoch: 4m,47s , Alloc: 7.26GiB  \n",
      "Train Corrects: Top-1: 77.02%, 5m,2s\n",
      "Test  Corrects: Top-1: 80.03%, 17.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.473, Losses [0: 4.23, 1: 1.31, 2: 0.66, 3: 1.23]Per Epoch: 4m,54s , Alloc: 7.52GiB   \n",
      "Train Corrects: Top-1: 71.08%, 5m,1s\n",
      "Test  Corrects: Top-1: 69.47%, 17.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 8.605, Losses [0: 3.68, 1: 2.0, 2: 1.53, 3: 7.16]Per Epoch: 4m,55s , Alloc: 7.52GiB    \n",
      "Train Corrects: Top-1: 64.84%, 5m,1s\n",
      "Test  Corrects: Top-1: 70.52%, 17.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.638, Losses [0: 3.17, 1: 1.6, 2: 0.6, 3: 0.56]Per Epoch: 4m,53s , Alloc: 7.52GiB    \n",
      "Train Corrects: Top-1: 71.24%, 5m,2s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,288,258 -> 7,288,258\n",
      "Pre-prune Test  Corrects: Top-1: 78.40%, 17.57 s\n",
      "Post-prune Test  Corrects: Top-1: 78.40%, 17.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.386, Losses [0: 3.46, 1: 1.82, 2: 0.83, 3: 1.16]Per Epoch: 4m,48s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 77.11%, 5m,2s\n",
      "Test  Corrects: Top-1: 81.38%, 17.55 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.897, Losses [0: 1.1, 1: 0.74, 2: 0.45, 3: 0.44]Per Epoch: 4m,42s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 80.75%, 5m,2s\n",
      "Test  Corrects: Top-1: 83.57%, 17.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.048, Losses [0: 1.26, 1: 0.65, 2: 0.5, 3: 0.57]Per Epoch: 4m,42s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 82.80%, 5m,2s\n",
      "Test  Corrects: Top-1: 81.39%, 17.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.989, Losses [0: 1.21, 1: 0.67, 2: 0.52, 3: 0.51]Per Epoch: 4m,57s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 84.58%, 5m,1s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,288,258 -> 7,288,258\n",
      "Pre-prune Test  Corrects: Top-1: 85.88%, 17.55 s\n",
      "Post-prune Test  Corrects: Top-1: 85.88%, 17.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.193, I: 1.067], Loss Comp: [C: 2.177, E: 0.819, I: 0.05], Losses [0: 1.16, 1: 0.87, 2: 0.57, 3: 0.79]Per Epoch: 7m,4s  , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 85.26%, Comp: 0.19, 1.07 6m,40s\n",
      "Train Loss Components: C: 3.409, E: 0.819, I: 0.05\n",
      "Test  Corrects: Top-1: 86.10%, 17.51 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.190, I: 1.067], Loss Comp: [C: 2.755, E: 0.812, I: 0.05], Losses [0: 2.12, 1: 1.09, 2: 0.69, 3: 1.12]Per Epoch: 6m,34s , Alloc: 7.52GiB   \n",
      "Train Corrects: Top-1: 75.31%, Comp: 0.19, 1.07 6m,42s\n",
      "Train Loss Components: C: 3.416, E: 0.812, I: 0.05\n",
      "Test  Corrects: Top-1: 78.51%, 17.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.192, I: 1.067], Loss Comp: [C: 4.393, E: 0.813, I: 0.05], Losses [0: 2.66, 1: 1.84, 2: 0.72, 3: 2.49]Per Epoch: 6m,29s , Alloc: 7.52GiB   \n",
      "Train Corrects: Top-1: 64.84%, Comp: 0.19, 1.07 6m,41s\n",
      "Train Loss Components: C: 3.413, E: 0.809, I: 0.05\n",
      "Test  Corrects: Top-1: 58.37%, 17.55 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.189, I: 1.067], Loss Comp: [C: 5.354, E: 0.803, I: 0.05], Losses [0: 4.16, 1: 2.8, 2: 0.69, 3: 2.97]Per Epoch: 6m,32s , Alloc: 7.52GiB    \n",
      "Train Corrects: Top-1: 66.49%, Comp: 0.19, 1.07 6m,40s\n",
      "Train Loss Components: C: 6.712, E: 0.803, I: 0.05\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,288,258 -> 7,288,258\n",
      "Pre-prune Test  Corrects: Top-1: 61.44%, 17.56 s\n",
      "Post-prune Test  Corrects: Top-1: 61.44%, 17.57 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.189, I: 1.067], Loss Comp: [C: 3.136, E: 0.804, I: 0.05], Losses [0: 2.67, 1: 1.36, 2: 0.68, 3: 1.34]Per Epoch: 6m,25s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 69.82%, Comp: 0.19, 1.07 6m,41s\n",
      "Train Loss Components: C: 15.836, E: 0.804, I: 0.05\n",
      "Test  Corrects: Top-1: 10.00%, 17.58 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.189, I: 1.067], Loss Comp: [C: 2.534, E: 0.804, I: 0.05], Losses [0: 2.65, 1: 1.44, 2: 0.66, 3: 0.73]Per Epoch: 6m,40s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 77.00%, Comp: 0.19, 1.07 6m,41s\n",
      "Train Loss Components: C: 3.203, E: 0.804, I: 0.05\n",
      "Test  Corrects: Top-1: 10.00%, 17.55 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.188, I: 1.067], Loss Comp: [C: 1.907, E: 0.801, I: 0.05], Losses [0: 1.41, 1: 0.88, 2: 0.51, 3: 0.5]Per Epoch: 6m,35s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 80.17%, Comp: 0.19, 1.07 6m,42s\n",
      "Train Loss Components: C: 4.331, E: 0.801, I: 0.05\n",
      "Test  Corrects: Top-1: 82.84%, 17.56 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.188, I: 1.067], Loss Comp: [C: 2.048, E: 0.801, I: 0.05], Losses [0: 1.63, 1: 0.96, 2: 0.56, 3: 0.57]Per Epoch: 6m,33s , Alloc: 7.52GiB  \n",
      "Train Corrects: Top-1: 82.17%, Comp: 0.19, 1.07 6m,41s\n",
      "Train Loss Components: C: 1.618, E: 0.801, I: 0.05\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 7,288,258 -> 7,287,488\n",
      "Pre-prune Test  Corrects: Top-1: 72.93%, 17.52 s\n",
      "Post-prune Test  Corrects: Top-1: 10.00%, 17.54 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.13671875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.0018792367045534775\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.08GiB\n",
      "4: 3.98GiB\n",
      "5: 4.83GiB\n",
      "6: 5.20GiB\n",
      "7: 5.51GiB\n",
      "8: 5.84GiB\n",
      "9: 6.24GiB\n",
      "10: 6.33GiB\n",
      "11: 6.33GiB\n",
      "12: 6.46GiB\n",
      "13: 6.64GiB\n",
      "14: 6.84GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.349, Losses [0: 2.42, 1: 1.54, 2: 0.69, 3: 1.42]Per Epoch: 4m,47s , Alloc: 7.24GiB   \n",
      "Train Corrects: Top-1: 73.83%, 5m,0s\n",
      "Test  Corrects: Top-1: 44.33%, 17.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.016, Losses [0: 3.52, 1: 1.54, 2: 0.6, 3: 0.88]Per Epoch: 4m,55s , Alloc: 7.49GiB   \n",
      "Train Corrects: Top-1: 73.73%, 5m,0s\n",
      "Test  Corrects: Top-1: 81.34%, 17.52 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.103, Losses [0: 2.76, 1: 1.63, 2: 0.59, 3: 1.11]Per Epoch: 4m,47s , Alloc: 7.49GiB   \n",
      "Train Corrects: Top-1: 69.60%, 4m,59s\n",
      "Test  Corrects: Top-1: 59.76%, 17.52 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.855, Losses [0: 2.11, 1: 1.31, 2: 0.55, 3: 1.06]Per Epoch: 4m,46s , Alloc: 7.49GiB   \n",
      "Train Corrects: Top-1: 73.31%, 4m,59s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 7,287,488 -> 7,150,271\n",
      "Pre-prune Test  Corrects: Top-1: 76.42%, 17.49 s\n",
      "Post-prune Test  Corrects: Top-1: 76.42%, 17.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.608, Losses [0: 1.42, 1: 0.63, 2: 0.48, 3: 1.1]Per Epoch: 4m,55s , Alloc: 7.49GiB    \n",
      "Train Corrects: Top-1: 76.92%, 4m,58s\n",
      "Test  Corrects: Top-1: 81.58%, 17.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.877, Losses [0: 1.28, 1: 0.69, 2: 0.35, 3: 0.41]Per Epoch: 4m,44s , Alloc: 7.49GiB  \n",
      "Train Corrects: Top-1: 80.31%, 4m,58s\n",
      "Test  Corrects: Top-1: 74.99%, 17.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.945, Losses [0: 1.68, 1: 0.66, 2: 0.4, 3: 0.4]Per Epoch: 4m,50s , Alloc: 7.49GiB   \n",
      "Train Corrects: Top-1: 83.25%, 4m,57s\n",
      "Test  Corrects: Top-1: 84.32%, 17.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.247, Losses [0: 1.6, 1: 0.8, 2: 0.56, 3: 0.65]Per Epoch: 4m,45s , Alloc: 7.49GiB   \n",
      "Train Corrects: Top-1: 84.44%, 4m,58s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,150,271 -> 7,150,271\n",
      "Pre-prune Test  Corrects: Top-1: 85.73%, 17.46 s\n",
      "Post-prune Test  Corrects: Top-1: 85.73%, 17.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.189, I: 1.067], Loss Comp: [C: 1.965, E: 0.926, I: 0.05], Losses [0: 1.5, 1: 0.72, 2: 0.46, 3: 0.45]Per Epoch: 6m,34s , Alloc: 7.49GiB  \n",
      "Train Corrects: Top-1: 85.26%, Comp: 0.19, 1.07 6m,37s\n",
      "Train Loss Components: C: 1.911, E: 0.909, I: 0.05\n",
      "Test  Corrects: Top-1: 83.05%, 17.40 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.187, I: 1.067], Loss Comp: [C: 3.124, E: 0.911, I: 0.05], Losses [0: 2.79, 1: 1.12, 2: 0.43, 3: 1.29]Per Epoch: 6m,28s , Alloc: 7.49GiB   \n",
      "Train Corrects: Top-1: 75.14%, Comp: 0.19, 1.07 6m,38s\n",
      "Train Loss Components: C: 17.999, E: 0.911, I: 0.05\n",
      "Test  Corrects: Top-1: 79.12%, 17.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.187, I: 1.067], Loss Comp: [C: 3.069, E: 0.911, I: 0.05], Losses [0: 3.65, 1: 1.29, 2: 0.6, 3: 1.0]Per Epoch: 6m,29s , Alloc: 7.49GiB     \n",
      "Train Corrects: Top-1: 75.40%, Comp: 0.19, 1.07 6m,36s\n",
      "Train Loss Components: C: 2.429, E: 0.911, I: 0.05\n",
      "Test  Corrects: Top-1: 79.15%, 17.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.186, I: 1.067], Loss Comp: [C: 2.608, E: 0.904, I: 0.05], Losses [0: 3.42, 1: 1.35, 2: 0.48, 3: 0.6]Per Epoch: 6m,31s , Alloc: 7.49GiB    \n",
      "Train Corrects: Top-1: 76.73%, Comp: 0.19, 1.07 6m,36s\n",
      "Train Loss Components: C: 5.689, E: 0.911, I: 0.05\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,150,271 -> 7,150,271\n",
      "Pre-prune Test  Corrects: Top-1: 80.92%, 17.46 s\n",
      "Post-prune Test  Corrects: Top-1: 80.92%, 17.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.187, I: 1.067], Loss Comp: [C: 2.471, E: 0.911, I: 0.05], Losses [0: 1.87, 1: 0.76, 2: 0.49, 3: 0.88]Per Epoch: 6m,31s , Alloc: 7.49GiB  \n",
      "Train Corrects: Top-1: 79.55%, Comp: 0.19, 1.07 6m,36s\n",
      "Train Loss Components: C: 3.152, E: 0.911, I: 0.05\n",
      "Test  Corrects: Top-1: 84.22%, 17.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.183, I: 1.067], Loss Comp: [C: 2.349, E: 0.897, I: 0.05], Losses [0: 1.75, 1: 1.01, 2: 0.69, 3: 0.71]Per Epoch: 6m,31s , Alloc: 7.49GiB   \n",
      "Train Corrects: Top-1: 82.80%, Comp: 0.18, 1.07 6m,38s\n",
      "Train Loss Components: C: 1.992, E: 0.897, I: 0.05\n",
      "Test  Corrects: Top-1: 84.17%, 17.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.186, I: 1.067], Loss Comp: [C: 2.115, E: 0.902, I: 0.05], Losses [0: 2.07, 1: 0.66, 2: 0.58, 3: 0.5]Per Epoch: 6m,20s , Alloc: 7.49GiB  \n",
      "Train Corrects: Top-1: 84.24%, Comp: 0.19, 1.07 6m,37s\n",
      "Train Loss Components: C: 3.201, E: 0.902, I: 0.05\n",
      "Test  Corrects: Top-1: 85.00%, 17.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.187, I: 1.067], Loss Comp: [C: 1.689, E: 0.911, I: 0.05], Losses [0: 1.13, 1: 0.56, 2: 0.36, 3: 0.31]Per Epoch: 6m,20s , Alloc: 7.49GiB  \n",
      "Train Corrects: Top-1: 85.55%, Comp: 0.19, 1.07 6m,37s\n",
      "Train Loss Components: C: 1.642, E: 0.911, I: 0.05\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 7,150,271 -> 7,013,053\n",
      "Pre-prune Test  Corrects: Top-1: 86.61%, 17.42 s\n",
      "Post-prune Test  Corrects: Top-1: 86.61%, 17.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.01171875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.001409427528415108\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.08GiB\n",
      "4: 3.98GiB\n",
      "5: 4.80GiB\n",
      "6: 5.18GiB\n",
      "7: 5.50GiB\n",
      "8: 5.80GiB\n",
      "9: 6.22GiB\n",
      "10: 6.30GiB\n",
      "11: 6.30GiB\n",
      "12: 6.38GiB\n",
      "13: 6.52GiB\n",
      "14: 6.71GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.759, Losses [0: 3.3, 1: 1.13, 2: 0.47, 3: 0.78]Per Epoch: 4m,38s , Alloc: 7.11GiB   \n",
      "Train Corrects: Top-1: 78.19%, 4m,54s\n",
      "Test  Corrects: Top-1: 79.52%, 17.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.310, Losses [0: 3.99, 1: 1.71, 2: 0.72, 3: 1.03]Per Epoch: 4m,45s , Alloc: 7.34GiB   \n",
      "Train Corrects: Top-1: 76.02%, 4m,54s\n",
      "Test  Corrects: Top-1: 78.50%, 17.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.407, Losses [0: 2.48, 1: 0.94, 2: 0.45, 3: 0.63]Per Epoch: 4m,40s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 76.89%, 4m,54s\n",
      "Test  Corrects: Top-1: 71.78%, 17.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.909, Losses [0: 2.9, 1: 1.09, 2: 0.72, 3: 0.97]Per Epoch: 4m,52s , Alloc: 7.34GiB   \n",
      "Train Corrects: Top-1: 79.28%, 4m,55s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,013,053 -> 7,013,053\n",
      "Pre-prune Test  Corrects: Top-1: 83.14%, 17.33 s\n",
      "Post-prune Test  Corrects: Top-1: 83.14%, 17.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.645, Losses [0: 2.28, 1: 1.15, 2: 0.74, 3: 1.81]Per Epoch: 4m,44s , Alloc: 7.34GiB   \n",
      "Train Corrects: Top-1: 79.52%, 4m,54s\n",
      "Test  Corrects: Top-1: 81.29%, 17.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.815, Losses [0: 1.34, 1: 0.66, 2: 0.29, 3: 0.36]Per Epoch: 4m,54s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 82.85%, 4m,54s\n",
      "Test  Corrects: Top-1: 84.46%, 17.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.226, Losses [0: 1.56, 1: 0.9, 2: 0.48, 3: 0.64]Per Epoch: 4m,48s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 84.86%, 4m,54s\n",
      "Test  Corrects: Top-1: 86.51%, 17.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.830, Losses [0: 0.9, 1: 0.64, 2: 0.42, 3: 0.44]Per Epoch: 4m,44s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 86.52%, 4m,54s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,013,053 -> 7,013,053\n",
      "Pre-prune Test  Corrects: Top-1: 86.93%, 17.33 s\n",
      "Post-prune Test  Corrects: Top-1: 86.93%, 17.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.187, I: 1.067], Loss Comp: [C: 1.738, E: 1.027, I: 0.06], Losses [0: 0.75, 1: 0.54, 2: 0.33, 3: 0.33]Per Epoch: 6m,25s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 87.09%, Comp: 0.19, 1.07 6m,34s\n",
      "Train Loss Components: C: 1.474, E: 1.027, I: 0.06\n",
      "Test  Corrects: Top-1: 87.35%, 17.26 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.186, I: 1.067], Loss Comp: [C: 5.395, E: 1.023, I: 0.06], Losses [0: 2.03, 1: 0.74, 2: 1.22, 3: 3.51]Per Epoch: 6m,20s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 77.65%, Comp: 0.19, 1.07 6m,34s\n",
      "Train Loss Components: C: 3.437, E: 1.023, I: 0.06\n",
      "Test  Corrects: Top-1: 82.03%, 17.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.185, I: 1.067], Loss Comp: [C: 2.749, E: 1.018, I: 0.06], Losses [0: 3.2, 1: 1.28, 2: 0.43, 3: 0.69]Per Epoch: 6m,12s , Alloc: 7.34GiB    \n",
      "Train Corrects: Top-1: 75.29%, Comp: 0.18, 1.07 6m,34s\n",
      "Train Loss Components: C: 2.600, E: 1.018, I: 0.06\n",
      "Test  Corrects: Top-1: 83.50%, 17.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.183, I: 1.067], Loss Comp: [C: 2.421, E: 1.014, I: 0.06], Losses [0: 1.91, 1: 1.01, 2: 0.58, 3: 0.65]Per Epoch: 6m,9s  , Alloc: 7.34GiB   \n",
      "Train Corrects: Top-1: 79.94%, Comp: 0.18, 1.07 6m,35s\n",
      "Train Loss Components: C: 34.048, E: 1.014, I: 0.06\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 7,013,053 -> 7,013,053\n",
      "Pre-prune Test  Corrects: Top-1: 67.39%, 17.38 s\n",
      "Post-prune Test  Corrects: Top-1: 67.39%, 17.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.185, I: 1.067], Loss Comp: [C: 2.334, E: 1.021, I: 0.06], Losses [0: 1.43, 1: 0.95, 2: 0.42, 3: 0.69]Per Epoch: 6m,12s , Alloc: 7.34GiB   \n",
      "Train Corrects: Top-1: 81.24%, Comp: 0.18, 1.07 6m,34s\n",
      "Train Loss Components: C: 8.877, E: 1.021, I: 0.06\n",
      "Test  Corrects: Top-1: 84.42%, 17.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.185, I: 1.067], Loss Comp: [C: 2.058, E: 1.021, I: 0.06], Losses [0: 1.72, 1: 0.79, 2: 0.35, 3: 0.41]Per Epoch: 6m,9s  , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 83.47%, Comp: 0.18, 1.07 6m,33s\n",
      "Train Loss Components: C: 3.423, E: 1.021, I: 0.06\n",
      "Test  Corrects: Top-1: 85.83%, 17.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.183, I: 1.067], Loss Comp: [C: 1.879, E: 1.010, I: 0.06], Losses [0: 1.35, 1: 0.64, 2: 0.34, 3: 0.34]Per Epoch: 6m,27s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 85.24%, Comp: 0.19, 1.00 6m,34s\n",
      "Train Loss Components: C: 2.054, E: 1.023, I: 0.00\n",
      "Test  Corrects: Top-1: 79.13%, 17.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.185, I: 1.000], Loss Comp: [C: 1.905, E: 1.013, I: 0.00], Losses [0: 1.0, 1: 0.58, 2: 0.41, 3: 0.49]Per Epoch: 6m,22s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 85.30%, Comp: 0.18, 1.00 6m,33s\n",
      "Train Loss Components: C: 2.903, E: 1.013, I: 0.00\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 7,013,053 -> 6,875,836\n",
      "Pre-prune Test  Corrects: Top-1: 85.41%, 17.33 s\n",
      "Post-prune Test  Corrects: Top-1: 85.41%, 17.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 7.01171875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.001057070646311331\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 96.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.08GiB\n",
      "4: 3.98GiB\n",
      "5: 4.80GiB\n",
      "6: 5.18GiB\n",
      "7: 5.50GiB\n",
      "8: 5.80GiB\n",
      "9: 6.22GiB\n",
      "10: 6.30GiB\n",
      "11: 6.30GiB\n",
      "12: 6.34GiB\n",
      "13: 6.52GiB\n",
      "14: 6.71GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.618, Losses [0: 2.45, 1: 0.87, 2: 0.52, 3: 0.85]Per Epoch: 4m,40s , Alloc: 7.11GiB   \n",
      "Train Corrects: Top-1: 78.49%, 4m,53s\n",
      "Test  Corrects: Top-1: 78.10%, 17.23 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 9.694, Losses [0: 4.58, 1: 2.34, 2: 1.81, 3: 7.95]Per Epoch: 4m,48s , Alloc: 7.34GiB   \n",
      "Train Corrects: Top-1: 68.08%, 4m,53s\n",
      "Test  Corrects: Top-1: 58.13%, 17.23 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.792, Losses [0: 4.9, 1: 2.09, 2: 0.96, 3: 1.2]Per Epoch: 4m,40s , Alloc: 7.34GiB     \n",
      "Train Corrects: Top-1: 63.70%, 4m,54s\n",
      "Test  Corrects: Top-1: 77.04%, 17.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.723, Losses [0: 2.89, 1: 1.24, 2: 0.6, 3: 0.78]Per Epoch: 4m,43s , Alloc: 7.34GiB    \n",
      "Train Corrects: Top-1: 71.68%, 4m,53s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 6,875,836 -> 6,859,195\n",
      "Pre-prune Test  Corrects: Top-1: 78.27%, 17.24 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-prune Test  Corrects: Top-1: 78.27%, 17.08 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.699, Losses [0: 1.88, 1: 1.11, 2: 0.74, 3: 0.95]Per Epoch: 4m,44s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 71.86%, 4m,52s\n",
      "Test  Corrects: Top-1: 77.38%, 17.12 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.962, Losses [0: 1.39, 1: 0.76, 2: 0.35, 3: 0.46]Per Epoch: 4m,38s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 76.49%, 4m,51s\n",
      "Test  Corrects: Top-1: 83.31%, 17.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.766, Losses [0: 0.87, 1: 0.61, 2: 0.29, 3: 0.41]Per Epoch: 4m,41s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 81.99%, 4m,52s\n",
      "Test  Corrects: Top-1: 83.75%, 17.08 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.294, Losses [0: 1.68, 1: 0.94, 2: 0.57, 3: 0.66]Per Epoch: 4m,43s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 83.98%, 4m,52s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 6,859,195 -> 6,859,194\n",
      "Pre-prune Test  Corrects: Top-1: 85.69%, 17.09 s\n",
      "Post-prune Test  Corrects: Top-1: 85.69%, 17.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.185, I: 1.000], Loss Comp: [C: 1.904, E: 1.132, I: 0.00], Losses [0: 1.0, 1: 0.68, 2: 0.38, 3: 0.36]Per Epoch: 6m,16s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 84.86%, Comp: 0.18, 1.00 6m,29s\n",
      "Train Loss Components: C: 2.003, E: 1.132, I: 0.00\n",
      "Test  Corrects: Top-1: 85.93%, 17.02 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.180, I: 1.000], Loss Comp: [C: 3.381, E: 1.112, I: 0.00], Losses [0: 3.15, 1: 1.34, 2: 0.69, 3: 1.23]Per Epoch: 6m,24s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 75.31%, Comp: 0.18, 1.00 6m,28s\n",
      "Train Loss Components: C: 23.972, E: 1.112, I: 0.00\n",
      "Test  Corrects: Top-1: 61.64%, 17.10 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.177, I: 1.000], Loss Comp: [C: 7.101, E: 1.098, I: 0.00], Losses [0: 4.7, 1: 2.94, 2: 1.46, 3: 4.18]Per Epoch: 6m,3s  , Alloc: 7.34GiB    \n",
      "Train Corrects: Top-1: 64.99%, Comp: 0.18, 1.00 6m,29s\n",
      "Train Loss Components: C: 6.210, E: 1.098, I: 0.00\n",
      "Test  Corrects: Top-1: 69.48%, 17.02 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.177, I: 1.000], Loss Comp: [C: 4.246, E: 1.092, I: 0.00], Losses [0: 2.93, 1: 1.55, 2: 0.53, 3: 2.15]Per Epoch: 6m,33s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 69.48%, Comp: 0.18, 1.00 6m,30s\n",
      "Train Loss Components: C: 8.653, E: 1.092, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,859,194 -> 6,859,194\n",
      "Pre-prune Test  Corrects: Top-1: 74.84%, 17.11 s\n",
      "Post-prune Test  Corrects: Top-1: 74.84%, 17.13 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.177, I: 1.000], Loss Comp: [C: 5.860, E: 1.092, I: 0.00], Losses [0: 3.23, 1: 1.65, 2: 1.06, 3: 3.58]Per Epoch: 6m,30s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 74.53%, Comp: 0.18, 1.00 6m,30s\n",
      "Train Loss Components: C: 7.488, E: 1.092, I: 0.00\n",
      "Test  Corrects: Top-1: 62.32%, 17.11 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.179, I: 1.000], Loss Comp: [C: 3.103, E: 1.095, I: 0.00], Losses [0: 1.8, 1: 0.98, 2: 0.63, 3: 1.33]Per Epoch: 6m,29s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 69.14%, Comp: 0.18, 1.00 6m,29s\n",
      "Train Loss Components: C: 4.568, E: 1.095, I: 0.00\n",
      "Test  Corrects: Top-1: 74.31%, 17.14 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.179, I: 1.000], Loss Comp: [C: 2.609, E: 1.095, I: 0.00], Losses [0: 1.28, 1: 1.01, 2: 0.51, 3: 0.95]Per Epoch: 6m,23s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 76.50%, Comp: 0.18, 1.00 6m,31s\n",
      "Train Loss Components: C: 3.110, E: 1.095, I: 0.00\n",
      "Test  Corrects: Top-1: 77.72%, 17.15 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.179, I: 1.000], Loss Comp: [C: 2.279, E: 1.095, I: 0.00], Losses [0: 1.64, 1: 0.94, 2: 0.43, 3: 0.58]Per Epoch: 6m,22s , Alloc: 7.34GiB  \n",
      "Train Corrects: Top-1: 79.77%, Comp: 0.18, 1.00 6m,30s\n",
      "Train Loss Components: C: 5.482, E: 1.095, I: 0.00\n",
      "\n",
      "Deadheaded 5 operations\n",
      "Param Delta: 6,859,194 -> 6,149,045\n",
      "Pre-prune Test  Corrects: Top-1: 83.38%, 17.12 s\n",
      "Post-prune Test  Corrects: Top-1: 9.98%, 16.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.79296875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.0007928029847334983\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 92.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.07GiB\n",
      "4: 3.98GiB\n",
      "5: 4.79GiB\n",
      "6: 5.18GiB\n",
      "7: 5.49GiB\n",
      "8: 5.80GiB\n",
      "9: 6.14GiB\n",
      "10: 6.22GiB\n",
      "11: 6.22GiB\n",
      "12: 6.28GiB\n",
      "13: 6.45GiB\n",
      "14: 6.59GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 6.118, Losses [0: 3.13, 1: 1.82, 2: 0.81, 3: 4.97]Per Epoch: 4m,34s , Alloc: 6.88GiB   \n",
      "Train Corrects: Top-1: 71.08%, 4m,45s\n",
      "Test  Corrects: Top-1: 71.98%, 16.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 3.453, Losses [0: 3.97, 1: 2.55, 2: 0.94, 3: 1.96]Per Epoch: 4m,43s , Alloc: 7.09GiB   \n",
      "Train Corrects: Top-1: 69.01%, 4m,45s\n",
      "Test  Corrects: Top-1: 78.11%, 16.80 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.807, Losses [0: 3.02, 1: 1.97, 2: 0.72, 3: 1.67]Per Epoch: 4m,33s , Alloc: 7.09GiB   \n",
      "Train Corrects: Top-1: 71.84%, 4m,45s\n",
      "Test  Corrects: Top-1: 74.88%, 16.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.459, Losses [0: 2.74, 1: 2.58, 2: 0.8, 3: 1.24]Per Epoch: 4m,30s , Alloc: 7.09GiB    \n",
      "Train Corrects: Top-1: 74.78%, 4m,45s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,149,045 -> 6,149,045\n",
      "Pre-prune Test  Corrects: Top-1: 80.43%, 16.82 s\n",
      "Post-prune Test  Corrects: Top-1: 80.43%, 16.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.961, Losses [0: 3.41, 1: 1.17, 2: 0.58, 3: 0.93]Per Epoch: 4m,31s , Alloc: 7.09GiB  \n",
      "Train Corrects: Top-1: 78.85%, 4m,45s\n",
      "Test  Corrects: Top-1: 82.96%, 16.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.458, Losses [0: 2.6, 1: 1.18, 2: 0.51, 3: 0.6]Per Epoch: 4m,40s , Alloc: 7.09GiB   \n",
      "Train Corrects: Top-1: 81.09%, 4m,45s\n",
      "Test  Corrects: Top-1: 83.95%, 16.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.630, Losses [0: 0.83, 1: 0.51, 2: 0.31, 3: 0.3]Per Epoch: 5m,4s  , Alloc: 7.09GiB  \n",
      "Train Corrects: Top-1: 83.38%, 4m,45s\n",
      "Test  Corrects: Top-1: 84.85%, 16.80 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.117, Losses [0: 1.57, 1: 0.94, 2: 0.52, 3: 0.51]Per Epoch: 4m,33s , Alloc: 7.09GiB  \n",
      "Train Corrects: Top-1: 85.02%, 4m,45s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,149,045 -> 6,149,045\n",
      "Pre-prune Test  Corrects: Top-1: 80.53%, 16.81 s\n",
      "Post-prune Test  Corrects: Top-1: 80.53%, 16.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.179, I: 1.000], Loss Comp: [C: 1.957, E: 1.206, I: 0.00], Losses [0: 0.82, 1: 0.57, 2: 0.45, 3: 0.38]Per Epoch: 6m,6s  , Alloc: 7.09GiB  \n",
      "Train Corrects: Top-1: 85.62%, Comp: 0.18, 1.00 6m,22s\n",
      "Train Loss Components: C: 2.564, E: 1.206, I: 0.00\n",
      "Test  Corrects: Top-1: 86.49%, 16.80 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.177, I: 1.000], Loss Comp: [C: 3.501, E: 1.202, I: 0.00], Losses [0: 3.48, 1: 2.07, 2: 0.5, 3: 1.09]Per Epoch: 6m,12s , Alloc: 7.09GiB    \n",
      "Train Corrects: Top-1: 72.42%, Comp: 0.18, 1.00 6m,23s\n",
      "Train Loss Components: C: 2.715, E: 1.199, I: 0.00\n",
      "Test  Corrects: Top-1: 66.88%, 16.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.171, I: 1.000], Loss Comp: [C: 3.606, E: 1.163, I: 0.00], Losses [0: 2.78, 1: 1.9, 2: 0.62, 3: 1.38]Per Epoch: 6m,13s , Alloc: 7.09GiB   \n",
      "Train Corrects: Top-1: 70.35%, Comp: 0.17, 1.00 6m,23s\n",
      "Train Loss Components: C: 2.429, E: 1.163, I: 0.00\n",
      "Test  Corrects: Top-1: 74.61%, 16.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.175, I: 1.000], Loss Comp: [C: 3.355, E: 1.188, I: 0.00], Losses [0: 2.44, 1: 1.17, 2: 0.49, 3: 1.35]Per Epoch: 6m,13s , Alloc: 7.09GiB   \n",
      "Train Corrects: Top-1: 75.35%, Comp: 0.18, 1.00 6m,22s\n",
      "Train Loss Components: C: 3.064, E: 1.188, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,149,045 -> 6,149,045\n",
      "Pre-prune Test  Corrects: Top-1: 75.92%, 16.78 s\n",
      "Post-prune Test  Corrects: Top-1: 75.92%, 16.78 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.175, I: 1.000], Loss Comp: [C: 3.247, E: 1.188, I: 0.00], Losses [0: 2.33, 1: 1.36, 2: 0.75, 3: 1.17]Per Epoch: 6m,0s  , Alloc: 7.09GiB  \n",
      "Train Corrects: Top-1: 78.59%, Comp: 0.18, 1.00 6m,22s\n",
      "Train Loss Components: C: 6.651, E: 1.188, I: 0.00\n",
      "Test  Corrects: Top-1: 84.05%, 16.78 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.173, I: 1.000], Loss Comp: [C: 2.688, E: 1.168, I: 0.00], Losses [0: 1.56, 1: 0.92, 2: 0.54, 3: 0.92]Per Epoch: 6m,11s , Alloc: 7.09GiB   \n",
      "Train Corrects: Top-1: 81.18%, Comp: 0.17, 1.00 6m,21s\n",
      "Train Loss Components: C: 2.418, E: 1.180, I: 0.00\n",
      "Test  Corrects: Top-1: 83.00%, 16.76 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.175, I: 1.000], Loss Comp: [C: 2.411, E: 1.188, I: 0.00], Losses [0: 1.48, 1: 0.61, 2: 0.55, 3: 0.69]Per Epoch: 6m,17s , Alloc: 7.09GiB  \n",
      "Train Corrects: Top-1: 83.00%, Comp: 0.18, 1.00 6m,20s\n",
      "Train Loss Components: C: 4.136, E: 1.188, I: 0.00\n",
      "Test  Corrects: Top-1: 85.45%, 16.75 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.175, I: 1.000], Loss Comp: [C: 2.214, E: 1.188, I: 0.00], Losses [0: 1.22, 1: 0.96, 2: 0.44, 3: 0.5]Per Epoch: 6m,18s , Alloc: 7.09GiB  \n",
      "Train Corrects: Top-1: 84.48%, Comp: 0.18, 1.00 6m,21s\n",
      "Train Loss Components: C: 4.719, E: 1.188, I: 0.00\n",
      "\n",
      "Deadheaded 3 operations\n",
      "Param Delta: 6,149,045 -> 6,147,506\n",
      "Pre-prune Test  Corrects: Top-1: 86.77%, 16.72 s\n",
      "Post-prune Test  Corrects: Top-1: 86.77%, 16.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.765625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.0005946022385501237\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 92.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.07GiB\n",
      "4: 3.98GiB\n",
      "5: 4.79GiB\n",
      "6: 5.18GiB\n",
      "7: 5.49GiB\n",
      "8: 5.80GiB\n",
      "9: 6.14GiB\n",
      "10: 6.22GiB\n",
      "11: 6.22GiB\n",
      "12: 6.26GiB\n",
      "13: 6.43GiB\n",
      "14: 6.57GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.431, Losses [0: 1.59, 1: 1.11, 2: 0.51, 3: 0.79]Per Epoch: 4m,27s , Alloc: 6.84GiB  \n",
      "Train Corrects: Top-1: 75.20%, 4m,43s\n",
      "Test  Corrects: Top-1: 82.21%, 16.67 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.425, Losses [0: 2.24, 1: 1.05, 2: 0.55, 3: 0.66]Per Epoch: 4m,37s , Alloc: 7.05GiB   \n",
      "Train Corrects: Top-1: 75.78%, 4m,43s\n",
      "Test  Corrects: Top-1: 68.00%, 16.71 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.992, Losses [0: 3.07, 1: 1.19, 2: 0.74, 3: 1.99]Per Epoch: 4m,27s , Alloc: 7.05GiB   \n",
      "Train Corrects: Top-1: 74.95%, 4m,44s\n",
      "Test  Corrects: Top-1: 76.03%, 16.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.390, Losses [0: 2.45, 1: 0.93, 2: 0.48, 3: 0.62]Per Epoch: 4m,42s , Alloc: 7.05GiB   \n",
      "Train Corrects: Top-1: 77.75%, 4m,43s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,147,506 -> 6,147,506\n",
      "Pre-prune Test  Corrects: Top-1: 83.16%, 16.69 s\n",
      "Post-prune Test  Corrects: Top-1: 83.16%, 16.71 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.851, Losses [0: 2.84, 1: 1.25, 2: 0.7, 3: 0.89]Per Epoch: 4m,34s , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 80.45%, 4m,44s\n",
      "Test  Corrects: Top-1: 84.52%, 16.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 3.124, Losses [0: 1.98, 1: 1.0, 2: 0.61, 3: 2.41]Per Epoch: 4m,28s , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 82.42%, 4m,43s\n",
      "Test  Corrects: Top-1: 85.39%, 16.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.890, Losses [0: 1.53, 1: 0.65, 2: 0.43, 3: 0.37]Per Epoch: 4m,29s , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 84.50%, 4m,43s\n",
      "Test  Corrects: Top-1: 86.32%, 16.72 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.709, Losses [0: 1.0, 1: 0.54, 2: 0.31, 3: 0.34]Per Epoch: 4m,34s , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 86.05%, 4m,43s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,147,506 -> 6,147,506\n",
      "Pre-prune Test  Corrects: Top-1: 87.59%, 16.70 s\n",
      "Post-prune Test  Corrects: Top-1: 87.59%, 16.73 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.175, I: 1.000], Loss Comp: [C: 2.129, E: 1.297, I: 0.00], Losses [0: 1.35, 1: 0.59, 2: 0.41, 3: 0.36]Per Epoch: 6m,16s , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 86.47%, Comp: 0.18, 1.00 6m,19s\n",
      "Train Loss Components: C: 3.183, E: 1.297, I: 0.00\n",
      "Test  Corrects: Top-1: 87.45%, 16.68 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.174, I: 1.000], Loss Comp: [C: 2.663, E: 1.291, I: 0.00], Losses [0: 3.18, 1: 0.99, 2: 0.38, 3: 0.46]Per Epoch: 6m,2s  , Alloc: 7.05GiB   \n",
      "Train Corrects: Top-1: 80.38%, Comp: 0.17, 1.00 6m,19s\n",
      "Train Loss Components: C: 2.407, E: 1.280, I: 0.00\n",
      "Test  Corrects: Top-1: 82.93%, 16.71 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.169, I: 1.000], Loss Comp: [C: 13.264, E: 1.254, I: 0.00], Losses [0: 7.75, 1: 4.97, 2: 2.59, 3: 8.95]Per Epoch: 6m,5s  , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 73.94%, Comp: 0.17, 1.00 6m,19s\n",
      "Train Loss Components: C: 8.440, E: 1.254, I: 0.00\n",
      "Test  Corrects: Top-1: 41.53%, 16.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.169, I: 1.000], Loss Comp: [C: 3.734, E: 1.262, I: 0.00], Losses [0: 2.6, 1: 1.35, 2: 0.71, 3: 1.54]Per Epoch: 6m,16s , Alloc: 7.05GiB   \n",
      "Train Corrects: Top-1: 67.86%, Comp: 0.17, 1.00 6m,19s\n",
      "Train Loss Components: C: 2.216, E: 1.262, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,147,506 -> 6,147,506\n",
      "Pre-prune Test  Corrects: Top-1: 73.90%, 16.70 s\n",
      "Post-prune Test  Corrects: Top-1: 73.90%, 16.72 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.170, I: 1.000], Loss Comp: [C: 2.443, E: 1.272, I: 0.00], Losses [0: 1.37, 1: 0.99, 2: 0.53, 3: 0.59]Per Epoch: 6m,4s  , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 75.94%, Comp: 0.17, 1.00 6m,20s\n",
      "Train Loss Components: C: 7.516, E: 1.272, I: 0.00\n",
      "Test  Corrects: Top-1: 81.16%, 16.70 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.168, I: 1.000], Loss Comp: [C: 2.542, E: 1.260, I: 0.00], Losses [0: 1.38, 1: 1.16, 2: 0.57, 3: 0.66]Per Epoch: 6m,17s , Alloc: 7.05GiB   \n",
      "Train Corrects: Top-1: 80.06%, Comp: 0.17, 1.00 6m,19s\n",
      "Train Loss Components: C: 2.540, E: 1.260, I: 0.00\n",
      "Test  Corrects: Top-1: 83.87%, 16.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.165, I: 1.000], Loss Comp: [C: 1.896, E: 1.249, I: 0.00], Losses [0: 0.97, 1: 0.44, 2: 0.29, 3: 0.31]Per Epoch: 5m,55s , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 83.09%, Comp: 0.17, 1.00 6m,19s\n",
      "Train Loss Components: C: 2.061, E: 1.249, I: 0.00\n",
      "Test  Corrects: Top-1: 86.09%, 16.70 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.165, I: 1.000], Loss Comp: [C: 2.152, E: 1.257, I: 0.00], Losses [0: 1.53, 1: 0.77, 2: 0.41, 3: 0.35]Per Epoch: 6m,16s , Alloc: 7.05GiB  \n",
      "Train Corrects: Top-1: 84.81%, Comp: 0.17, 1.00 6m,19s\n",
      "Train Loss Components: C: 1.563, E: 1.257, I: 0.00\n",
      "\n",
      "Deadheaded 4 operations\n",
      "Param Delta: 6,147,506 -> 6,009,390\n",
      "Pre-prune Test  Corrects: Top-1: 86.62%, 16.72 s\n",
      "Post-prune Test  Corrects: Top-1: 86.62%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.69921875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.0004459516789125928\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 92.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.00GiB\n",
      "4: 3.98GiB\n",
      "5: 4.79GiB\n",
      "6: 5.18GiB\n",
      "7: 5.47GiB\n",
      "8: 5.80GiB\n",
      "9: 6.12GiB\n",
      "10: 6.21GiB\n",
      "11: 6.21GiB\n",
      "12: 6.21GiB\n",
      "13: 6.36GiB\n",
      "14: 6.50GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.354, Losses [0: 2.29, 1: 1.32, 2: 0.74, 3: 1.48]Per Epoch: 4m,32s , Alloc: 6.79GiB   \n",
      "Train Corrects: Top-1: 74.64%, 4m,39s\n",
      "Test  Corrects: Top-1: 79.08%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.634, Losses [0: 3.17, 1: 1.51, 2: 0.41, 3: 0.62]Per Epoch: 4m,20s , Alloc: 6.98GiB   \n",
      "Train Corrects: Top-1: 76.05%, 4m,39s\n",
      "Test  Corrects: Top-1: 82.34%, 16.49 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 6.679, Losses [0: 3.84, 1: 1.36, 2: 0.37, 3: 5.56]Per Epoch: 4m,34s , Alloc: 6.98GiB   \n",
      "Train Corrects: Top-1: 78.18%, 4m,39s\n",
      "Test  Corrects: Top-1: 81.25%, 16.49 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.717, Losses [0: 2.55, 1: 0.84, 2: 0.59, 3: 0.92]Per Epoch: 4m,34s , Alloc: 6.98GiB   \n",
      "Train Corrects: Top-1: 76.96%, 4m,39s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,009,390 -> 6,009,390\n",
      "Pre-prune Test  Corrects: Top-1: 79.87%, 16.46 s\n",
      "Post-prune Test  Corrects: Top-1: 79.87%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 3.035, Losses [0: 2.78, 1: 1.33, 2: 0.62, 3: 2.09]Per Epoch: 4m,27s , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 80.60%, 4m,39s\n",
      "Test  Corrects: Top-1: 83.08%, 16.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.009, Losses [0: 1.48, 1: 0.43, 2: 0.5, 3: 0.53]Per Epoch: 4m,30s , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 83.88%, 4m,39s\n",
      "Test  Corrects: Top-1: 85.70%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.943, Losses [0: 1.23, 1: 0.67, 2: 0.47, 3: 0.47]Per Epoch: 4m,17s , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 85.97%, 4m,39s\n",
      "Test  Corrects: Top-1: 86.96%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.996, Losses [0: 1.42, 1: 0.78, 2: 0.43, 3: 0.47]Per Epoch: 4m,25s , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 86.84%, 4m,40s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,009,390 -> 6,009,390\n",
      "Pre-prune Test  Corrects: Top-1: 86.94%, 16.50 s\n",
      "Post-prune Test  Corrects: Top-1: 86.94%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.169, I: 1.000], Loss Comp: [C: 2.491, E: 1.365, I: 0.00], Losses [0: 1.43, 1: 0.76, 2: 0.56, 3: 0.57]Per Epoch: 6m,9s  , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 87.23%, Comp: 0.17, 1.00 6m,14s\n",
      "Train Loss Components: C: 1.806, E: 1.379, I: 0.00\n",
      "Test  Corrects: Top-1: 86.59%, 16.44 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.169, I: 1.000], Loss Comp: [C: 4.447, E: 1.365, I: 0.00], Losses [0: 2.5, 1: 1.41, 2: 0.74, 3: 2.15]Per Epoch: 6m,9s  , Alloc: 6.98GiB    \n",
      "Train Corrects: Top-1: 76.84%, Comp: 0.17, 1.00 6m,15s\n",
      "Train Loss Components: C: 5.183, E: 1.365, I: 0.00\n",
      "Test  Corrects: Top-1: 53.87%, 16.51 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.168, I: 1.000], Loss Comp: [C: 4.246, E: 1.365, I: 0.00], Losses [0: 2.03, 1: 1.12, 2: 0.39, 3: 2.17]Per Epoch: 5m,53s , Alloc: 6.98GiB   \n",
      "Train Corrects: Top-1: 77.85%, Comp: 0.17, 1.00 6m,15s\n",
      "Train Loss Components: C: 2.482, E: 1.351, I: 0.00\n",
      "Test  Corrects: Top-1: 73.60%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.169, I: 1.000], Loss Comp: [C: 3.408, E: 1.370, I: 0.00], Losses [0: 4.02, 1: 1.28, 2: 0.59, 3: 0.86]Per Epoch: 6m,9s  , Alloc: 6.98GiB   \n",
      "Train Corrects: Top-1: 78.47%, Comp: 0.17, 1.00 6m,15s\n",
      "Train Loss Components: C: 3.144, E: 1.370, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 6,009,390 -> 6,009,390\n",
      "Pre-prune Test  Corrects: Top-1: 80.79%, 16.47 s\n",
      "Post-prune Test  Corrects: Top-1: 80.79%, 16.49 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.163, I: 1.000], Loss Comp: [C: 3.172, E: 1.341, I: 0.00], Losses [0: 2.24, 1: 0.97, 2: 0.73, 3: 1.04]Per Epoch: 6m,11s , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 81.29%, Comp: 0.16, 1.00 6m,16s\n",
      "Train Loss Components: C: 3.290, E: 1.341, I: 0.00\n",
      "Test  Corrects: Top-1: 78.62%, 16.49 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.163, I: 1.000], Loss Comp: [C: 2.192, E: 1.344, I: 0.00], Losses [0: 1.37, 1: 0.57, 2: 0.38, 3: 0.38]Per Epoch: 5m,53s , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 83.37%, Comp: 0.16, 1.00 6m,15s\n",
      "Train Loss Components: C: 1.861, E: 1.336, I: 0.00\n",
      "Test  Corrects: Top-1: 85.96%, 16.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.162, I: 1.000], Loss Comp: [C: 2.128, E: 1.344, I: 0.00], Losses [0: 0.93, 1: 0.58, 2: 0.43, 3: 0.4]Per Epoch: 6m,1s  , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 85.49%, Comp: 0.16, 1.00 6m,16s\n",
      "Train Loss Components: C: 3.159, E: 1.344, I: 0.00\n",
      "Test  Corrects: Top-1: 87.21%, 16.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.160, I: 1.000], Loss Comp: [C: 2.010, E: 1.322, I: 0.00], Losses [0: 0.67, 1: 0.45, 2: 0.36, 3: 0.39]Per Epoch: 6m,13s , Alloc: 6.98GiB  \n",
      "Train Corrects: Top-1: 86.87%, Comp: 0.16, 1.00 6m,15s\n",
      "Train Loss Components: C: 4.458, E: 1.322, I: 0.00\n",
      "\n",
      "Deadheaded 4 operations\n",
      "Param Delta: 6,009,390 -> 5,698,602\n",
      "Pre-prune Test  Corrects: Top-1: 85.56%, 16.46 s\n",
      "Post-prune Test  Corrects: Top-1: 85.56%, 16.22 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.4375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.0003344637591844446\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 92.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.00GiB\n",
      "4: 3.98GiB\n",
      "5: 4.79GiB\n",
      "6: 5.10GiB\n",
      "7: 5.24GiB\n",
      "8: 5.56GiB\n",
      "9: 5.89GiB\n",
      "10: 5.97GiB\n",
      "11: 5.97GiB\n",
      "12: 5.97GiB\n",
      "13: 6.09GiB\n",
      "14: 6.23GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.428, Losses [0: 3.04, 1: 1.05, 2: 0.4, 3: 0.53]Per Epoch: 4m,26s , Alloc: 6.51GiB  \n",
      "Train Corrects: Top-1: 80.15%, 4m,29s\n",
      "Test  Corrects: Top-1: 84.18%, 16.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 7.292, Losses [0: 3.28, 1: 1.62, 2: 0.97, 3: 6.12]Per Epoch: 4m,18s , Alloc: 6.69GiB   \n",
      "Train Corrects: Top-1: 77.00%, 4m,29s\n",
      "Test  Corrects: Top-1: 50.85%, 16.19 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 3.681, Losses [0: 3.59, 1: 1.81, 2: 0.86, 3: 2.43]Per Epoch: 4m,18s , Alloc: 6.69GiB   \n",
      "Train Corrects: Top-1: 64.66%, 4m,30s\n",
      "Test  Corrects: Top-1: 75.15%, 16.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 3.849, Losses [0: 2.54, 1: 1.19, 2: 1.02, 3: 2.9]Per Epoch: 4m,17s , Alloc: 6.69GiB    \n",
      "Train Corrects: Top-1: 76.65%, 4m,30s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 5,698,602 -> 5,698,089\n",
      "Pre-prune Test  Corrects: Top-1: 68.70%, 16.19 s\n",
      "Post-prune Test  Corrects: Top-1: 68.69%, 16.20 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.033, Losses [0: 1.87, 1: 0.6, 2: 0.39, 3: 0.46]Per Epoch: 4m,24s , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 80.50%, 4m,30s\n",
      "Test  Corrects: Top-1: 84.53%, 16.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.868, Losses [0: 1.22, 1: 0.69, 2: 0.37, 3: 0.41]Per Epoch: 4m,15s , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 83.97%, 4m,28s\n",
      "Test  Corrects: Top-1: 83.83%, 16.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.975, Losses [0: 1.61, 1: 0.74, 2: 0.42, 3: 0.42]Per Epoch: 4m,17s , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 85.52%, 4m,29s\n",
      "Test  Corrects: Top-1: 86.78%, 16.21 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.526, Losses [0: 0.88, 1: 0.38, 2: 0.25, 3: 0.22]Per Epoch: 4m,22s , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 86.93%, 4m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 5,698,089 -> 5,698,089\n",
      "Pre-prune Test  Corrects: Top-1: 87.68%, 16.21 s\n",
      "Post-prune Test  Corrects: Top-1: 87.68%, 16.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.163, I: 1.000], Loss Comp: [C: 2.137, E: 1.446, I: 0.00], Losses [0: 0.8, 1: 0.49, 2: 0.37, 3: 0.36]Per Epoch: 6m,11s , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 87.66%, Comp: 0.16, 1.00 6m,4s\n",
      "Train Loss Components: C: 2.595, E: 1.446, I: 0.00\n",
      "Test  Corrects: Top-1: 84.68%, 16.15 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.162, I: 1.000], Loss Comp: [C: 4.062, E: 1.447, I: 0.00], Losses [0: 3.17, 1: 2.13, 2: 0.73, 3: 1.41]Per Epoch: 5m,49s , Alloc: 6.69GiB   \n",
      "Train Corrects: Top-1: 78.61%, Comp: 0.16, 1.00 6m,3s\n",
      "Train Loss Components: C: 6.235, E: 1.447, I: 0.00\n",
      "Test  Corrects: Top-1: 81.86%, 16.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.164, I: 1.000], Loss Comp: [C: 3.213, E: 1.461, I: 0.00], Losses [0: 2.97, 1: 1.12, 2: 0.52, 3: 0.83]Per Epoch: 6m,7s  , Alloc: 6.69GiB   \n",
      "Train Corrects: Top-1: 77.82%, Comp: 0.16, 1.00 6m,4s\n",
      "Train Loss Components: C: 2.437, E: 1.461, I: 0.00\n",
      "Test  Corrects: Top-1: 81.10%, 16.14 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.162, I: 1.000], Loss Comp: [C: 2.853, E: 1.441, I: 0.00], Losses [0: 1.82, 1: 0.98, 2: 0.47, 3: 0.76]Per Epoch: 5m,49s , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 73.71%, Comp: 0.16, 1.00 6m,4s\n",
      "Train Loss Components: C: 3.797, E: 1.441, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 5,698,089 -> 5,698,089\n",
      "Pre-prune Test  Corrects: Top-1: 78.26%, 16.16 s\n",
      "Post-prune Test  Corrects: Top-1: 78.26%, 16.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.163, I: 1.000], Loss Comp: [C: 2.653, E: 1.456, I: 0.00], Losses [0: 2.03, 1: 0.79, 2: 0.4, 3: 0.55]Per Epoch: 6m,2s  , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 81.03%, Comp: 0.16, 1.00 6m,4s\n",
      "Train Loss Components: C: 3.124, E: 1.456, I: 0.00\n",
      "Test  Corrects: Top-1: 80.94%, 16.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.160, I: 1.000], Loss Comp: [C: 1.966, E: 1.424, I: 0.00], Losses [0: 0.98, 1: 0.34, 2: 0.23, 3: 0.23]Per Epoch: 5m,53s , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 84.69%, Comp: 0.16, 1.00 6m,4s\n",
      "Train Loss Components: C: 5.547, E: 1.433, I: 0.00\n",
      "Test  Corrects: Top-1: 86.31%, 16.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.161, I: 1.000], Loss Comp: [C: 2.544, E: 1.427, I: 0.00], Losses [0: 1.47, 1: 0.7, 2: 0.56, 3: 0.57]Per Epoch: 6m,2s  , Alloc: 6.69GiB  \n",
      "Train Corrects: Top-1: 85.72%, Comp: 0.16, 1.00 6m,3s\n",
      "Train Loss Components: C: 2.922, E: 1.427, I: 0.00\n",
      "Test  Corrects: Top-1: 85.61%, 16.16 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.161, I: 1.000], Loss Comp: [C: 2.149, E: 1.444, I: 0.00], Losses [0: 0.9, 1: 0.5, 2: 0.29, 3: 0.37]Per Epoch: 6m,5s  , Alloc: 6.69GiB   \n",
      "Train Corrects: Top-1: 87.49%, Comp: 0.16, 1.00 6m,2s\n",
      "Train Loss Components: C: 5.450, E: 1.444, I: 0.00\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 5,698,089 -> 5,662,248\n",
      "Pre-prune Test  Corrects: Top-1: 87.21%, 16.14 s\n",
      "Post-prune Test  Corrects: Top-1: 87.21%, 16.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.359375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.00025084781938833345\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 92.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.00GiB\n",
      "4: 3.98GiB\n",
      "5: 4.79GiB\n",
      "6: 5.10GiB\n",
      "7: 5.16GiB\n",
      "8: 5.48GiB\n",
      "9: 5.81GiB\n",
      "10: 5.89GiB\n",
      "11: 5.89GiB\n",
      "12: 5.89GiB\n",
      "13: 6.03GiB\n",
      "14: 6.17GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.358, Losses [0: 3.92, 1: 1.68, 2: 0.7, 3: 1.1]Per Epoch: 4m,13s , Alloc: 6.43GiB    \n",
      "Train Corrects: Top-1: 79.75%, 4m,25s\n",
      "Test  Corrects: Top-1: 73.52%, 16.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.210, Losses [0: 2.19, 1: 0.96, 2: 0.44, 3: 0.49]Per Epoch: 4m,15s , Alloc: 6.61GiB   \n",
      "Train Corrects: Top-1: 78.03%, 4m,27s\n",
      "Test  Corrects: Top-1: 80.99%, 16.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.656, Losses [0: 2.86, 1: 1.12, 2: 0.84, 3: 1.69]Per Epoch: 4m,17s , Alloc: 6.61GiB   \n",
      "Train Corrects: Top-1: 75.49%, 4m,27s\n",
      "Test  Corrects: Top-1: 78.58%, 16.10 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.037, Losses [0: 2.76, 1: 1.41, 2: 0.62, 3: 1.08]Per Epoch: 4m,17s , Alloc: 6.61GiB   \n",
      "Train Corrects: Top-1: 76.88%, 4m,27s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 5,662,248 -> 5,662,248\n",
      "Pre-prune Test  Corrects: Top-1: 75.28%, 16.11 s\n",
      "Post-prune Test  Corrects: Top-1: 75.28%, 16.10 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.618, Losses [0: 0.94, 1: 0.56, 2: 0.26, 3: 0.27]Per Epoch: 4m,18s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 80.82%, 4m,27s\n",
      "Test  Corrects: Top-1: 84.35%, 16.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.698, Losses [0: 0.89, 1: 0.52, 2: 0.33, 3: 0.35]Per Epoch: 4m,16s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 84.21%, 4m,27s\n",
      "Test  Corrects: Top-1: 86.83%, 16.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.117, Losses [0: 1.21, 1: 0.68, 2: 0.49, 3: 0.64]Per Epoch: 4m,12s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 86.14%, 4m,26s\n",
      "Test  Corrects: Top-1: 87.73%, 16.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.004, Losses [0: 1.49, 1: 0.7, 2: 0.44, 3: 0.48]Per Epoch: 4m,9s  , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 87.51%, 4m,26s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 5,662,248 -> 5,662,248\n",
      "Pre-prune Test  Corrects: Top-1: 88.08%, 16.06 s\n",
      "Post-prune Test  Corrects: Top-1: 88.08%, 16.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.163, I: 1.000], Loss Comp: [C: 2.408, E: 1.561, I: 0.00], Losses [0: 1.31, 1: 0.61, 2: 0.38, 3: 0.39]Per Epoch: 5m,49s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 88.11%, Comp: 0.16, 1.00 6m,1s\n",
      "Train Loss Components: C: 3.477, E: 1.561, I: 0.00\n",
      "Test  Corrects: Top-1: 88.57%, 16.05 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.163, I: 1.000], Loss Comp: [C: 2.931, E: 1.561, I: 0.00], Losses [0: 1.93, 1: 0.85, 2: 0.52, 3: 0.71]Per Epoch: 5m,56s , Alloc: 6.61GiB   \n",
      "Train Corrects: Top-1: 80.83%, Comp: 0.16, 1.00 6m,1s\n",
      "Train Loss Components: C: 3.239, E: 1.561, I: 0.00\n",
      "Test  Corrects: Top-1: 83.91%, 16.03 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.161, I: 1.000], Loss Comp: [C: 3.480, E: 1.530, I: 0.00], Losses [0: 3.04, 1: 1.69, 2: 0.69, 3: 0.87]Per Epoch: 5m,47s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 81.24%, Comp: 0.16, 1.00 6m,0s\n",
      "Train Loss Components: C: 2.949, E: 1.530, I: 0.00\n",
      "Test  Corrects: Top-1: 76.43%, 16.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.161, I: 1.000], Loss Comp: [C: 3.163, E: 1.543, I: 0.00], Losses [0: 2.91, 1: 0.9, 2: 0.56, 3: 0.74]Per Epoch: 5m,55s , Alloc: 6.61GiB   \n",
      "Train Corrects: Top-1: 79.51%, Comp: 0.16, 1.00 6m,0s\n",
      "Train Loss Components: C: 5.735, E: 1.543, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 5,662,248 -> 5,662,248\n",
      "Pre-prune Test  Corrects: Top-1: 79.04%, 16.03 s\n",
      "Post-prune Test  Corrects: Top-1: 79.04%, 16.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.160, I: 1.000], Loss Comp: [C: 3.401, E: 1.541, I: 0.00], Losses [0: 2.68, 1: 1.0, 2: 0.53, 3: 1.02]Per Epoch: 5m,39s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 82.89%, Comp: 0.16, 1.00 6m,0s\n",
      "Train Loss Components: C: 2.872, E: 1.541, I: 0.00\n",
      "Test  Corrects: Top-1: 86.02%, 16.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.156, I: 1.000], Loss Comp: [C: 2.714, E: 1.494, I: 0.00], Losses [0: 1.92, 1: 0.48, 2: 0.35, 3: 0.67]Per Epoch: 5m,42s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 84.25%, Comp: 0.16, 1.00 6m,2s\n",
      "Train Loss Components: C: 3.091, E: 1.494, I: 0.00\n",
      "Test  Corrects: Top-1: 82.45%, 16.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.157, I: 1.000], Loss Comp: [C: 2.315, E: 1.504, I: 0.00], Losses [0: 1.32, 1: 0.49, 2: 0.26, 3: 0.4]Per Epoch: 5m,53s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 85.22%, Comp: 0.16, 1.00 6m,1s\n",
      "Train Loss Components: C: 3.849, E: 1.504, I: 0.00\n",
      "Test  Corrects: Top-1: 85.54%, 16.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.158, I: 1.000], Loss Comp: [C: 2.539, E: 1.518, I: 0.00], Losses [0: 1.32, 1: 0.59, 2: 0.41, 3: 0.56]Per Epoch: 5m,58s , Alloc: 6.61GiB  \n",
      "Train Corrects: Top-1: 87.29%, Comp: 0.16, 1.00 6m,0s\n",
      "Train Loss Components: C: 2.567, E: 1.518, I: 0.00\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 5,662,248 -> 5,625,894\n",
      "Pre-prune Test  Corrects: Top-1: 88.38%, 16.05 s\n",
      "Post-prune Test  Corrects: Top-1: 88.38%, 15.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.30859375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.00018813586454125009\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 92.00MiB\n",
      "1: 1.11GiB\n",
      "2: 2.03GiB\n",
      "3: 3.00GiB\n",
      "4: 3.98GiB\n",
      "5: 4.79GiB\n",
      "6: 5.10GiB\n",
      "7: 5.16GiB\n",
      "8: 5.48GiB\n",
      "9: 5.73GiB\n",
      "10: 5.80GiB\n",
      "11: 5.80GiB\n",
      "12: 5.80GiB\n",
      "13: 5.96GiB\n",
      "14: 6.10GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.408, Losses [0: 2.24, 1: 0.91, 2: 0.46, 3: 0.69]Per Epoch: 4m,17s , Alloc: 6.38GiB   \n",
      "Train Corrects: Top-1: 81.60%, 4m,24s\n",
      "Test  Corrects: Top-1: 83.50%, 15.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.967, Losses [0: 3.59, 1: 1.53, 2: 0.59, 3: 0.83]Per Epoch: 4m,10s , Alloc: 6.55GiB   \n",
      "Train Corrects: Top-1: 79.43%, 4m,24s\n",
      "Test  Corrects: Top-1: 82.24%, 15.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.978, Losses [0: 3.68, 1: 1.5, 2: 0.66, 3: 0.81]Per Epoch: 4m,9s  , Alloc: 6.55GiB    \n",
      "Train Corrects: Top-1: 78.96%, 4m,24s\n",
      "Test  Corrects: Top-1: 80.73%, 15.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.232, Losses [0: 2.11, 1: 0.98, 2: 0.44, 3: 0.53]Per Epoch: 4m,13s , Alloc: 6.55GiB  \n",
      "Train Corrects: Top-1: 80.89%, 4m,24s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 5,625,894 -> 5,625,894\n",
      "Pre-prune Test  Corrects: Top-1: 84.75%, 15.93 s\n",
      "Post-prune Test  Corrects: Top-1: 84.75%, 15.96 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.865, Losses [0: 1.39, 1: 0.57, 2: 0.31, 3: 0.41]Per Epoch: 4m,17s , Alloc: 6.55GiB   \n",
      "Train Corrects: Top-1: 84.32%, 4m,24s\n",
      "Test  Corrects: Top-1: 86.87%, 15.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.048, Losses [0: 1.63, 1: 0.56, 2: 0.47, 3: 0.52]Per Epoch: 4m,12s , Alloc: 6.55GiB   \n",
      "Train Corrects: Top-1: 85.47%, 4m,24s\n",
      "Test  Corrects: Top-1: 85.89%, 15.96 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.624, Losses [0: 1.07, 1: 0.35, 2: 0.31, 3: 0.28]Per Epoch: 4m,3s  , Alloc: 6.55GiB  \n",
      "Train Corrects: Top-1: 87.78%, 4m,24s\n",
      "Test  Corrects: Top-1: 88.64%, 15.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.605, Losses [0: 0.74, 1: 0.41, 2: 0.27, 3: 0.32]Per Epoch: 4m,18s , Alloc: 6.55GiB  \n",
      "Train Corrects: Top-1: 89.01%, 4m,24s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 5,625,894 -> 5,090,341\n",
      "Pre-prune Test  Corrects: Top-1: 89.05%, 15.94 s\n",
      "Post-prune Test  Corrects: Top-1: 89.05%, 15.88 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.158, I: 1.000], Loss Comp: [C: 2.212, E: 1.620, I: 0.00], Losses [0: 0.7, 1: 0.53, 2: 0.31, 3: 0.28]Per Epoch: 5m,49s , Alloc: 6.55GiB  \n",
      "Train Corrects: Top-1: 89.03%, Comp: 0.16, 1.00 5m,57s\n",
      "Train Loss Components: C: 2.241, E: 1.620, I: 0.00\n",
      "Test  Corrects: Top-1: 89.42%, 15.85 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.155, I: 1.000], Loss Comp: [C: 3.144, E: 1.593, I: 0.00], Losses [0: 3.09, 1: 1.21, 2: 0.41, 3: 0.61]Per Epoch: 6m,6s  , Alloc: 6.55GiB  \n",
      "Train Corrects: Top-1: 83.43%, Comp: 0.15, 1.00 5m,55s\n",
      "Train Loss Components: C: 6.310, E: 1.593, I: 0.00\n",
      "Test  Corrects: Top-1: 82.24%, 15.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.154, I: 1.000], Loss Comp: [C: 3.172, E: 1.591, I: 0.00], Losses [0: 3.47, 1: 1.04, 2: 0.47, 3: 0.58]Per Epoch: 5m,48s , Alloc: 6.55GiB   \n",
      "Train Corrects: Top-1: 78.40%, Comp: 0.15, 1.00 5m,56s\n",
      "Train Loss Components: C: 8.431, E: 1.591, I: 0.00\n",
      "Test  Corrects: Top-1: 83.68%, 15.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.152, I: 1.000], Loss Comp: [C: 2.495, E: 1.585, I: 0.00], Losses [0: 1.44, 1: 0.71, 2: 0.33, 3: 0.41]Per Epoch: 5m,49s , Alloc: 6.55GiB   \n",
      "Train Corrects: Top-1: 80.48%, Comp: 0.15, 1.00 5m,56s\n",
      "Train Loss Components: C: 2.844, E: 1.570, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 5,090,341 -> 5,090,341\n",
      "Pre-prune Test  Corrects: Top-1: 85.32%, 15.84 s\n",
      "Post-prune Test  Corrects: Top-1: 85.32%, 15.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.150, I: 1.000], Loss Comp: [C: 2.879, E: 1.563, I: 0.00], Losses [0: 2.3, 1: 0.83, 2: 0.48, 3: 0.6]Per Epoch: 5m,36s , Alloc: 6.55GiB    \n",
      "Train Corrects: Top-1: 82.77%, Comp: 0.15, 1.00 5m,57s\n",
      "Train Loss Components: C: 9.720, E: 1.563, I: 0.00\n",
      "Test  Corrects: Top-1: 85.85%, 15.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.150, I: 1.000], Loss Comp: [C: 2.677, E: 1.553, I: 0.00], Losses [0: 1.37, 1: 0.5, 2: 0.4, 3: 0.67]Per Epoch: 5m,43s , Alloc: 6.55GiB   \n",
      "Train Corrects: Top-1: 85.56%, Comp: 0.15, 1.00 5m,57s\n",
      "Train Loss Components: C: 2.486, E: 1.536, I: 0.00\n",
      "Test  Corrects: Top-1: 83.37%, 15.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.148, I: 1.000], Loss Comp: [C: 2.727, E: 1.531, I: 0.00], Losses [0: 1.63, 1: 0.93, 2: 0.51, 3: 0.58]Per Epoch: 5m,43s , Alloc: 6.55GiB  \n",
      "Train Corrects: Top-1: 87.33%, Comp: 0.15, 1.00 5m,56s\n",
      "Train Loss Components: C: 3.208, E: 1.531, I: 0.00\n",
      "Test  Corrects: Top-1: 87.53%, 15.88 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.146, I: 1.000], Loss Comp: [C: 2.331, E: 1.519, I: 0.00], Losses [0: 1.1, 1: 0.49, 2: 0.44, 3: 0.41]Per Epoch: 5m,48s , Alloc: 6.55GiB  \n",
      "Train Corrects: Top-1: 88.76%, Comp: 0.15, 1.00 5m,57s\n",
      "Train Loss Components: C: 4.117, E: 1.519, I: 0.00\n",
      "\n",
      "Deadheaded 6 operations\n",
      "Param Delta: 5,090,341 -> 4,942,111\n",
      "Pre-prune Test  Corrects: Top-1: 89.09%, 15.87 s\n",
      "Post-prune Test  Corrects: Top-1: 89.09%, 15.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 6.078125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.00014110189840593756\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 88.00MiB\n",
      "1: 1.10GiB\n",
      "2: 2.02GiB\n",
      "3: 2.87GiB\n",
      "4: 3.85GiB\n",
      "5: 4.66GiB\n",
      "6: 4.97GiB\n",
      "7: 5.03GiB\n",
      "8: 5.34GiB\n",
      "9: 5.58GiB\n",
      "10: 5.66GiB\n",
      "11: 5.66GiB\n",
      "12: 5.66GiB\n",
      "13: 5.74GiB\n",
      "14: 5.88GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 5.355, Losses [0: 3.76, 1: 1.26, 2: 0.97, 3: 4.16]Per Epoch: 3m,59s , Alloc: 6.14GiB   \n",
      "Train Corrects: Top-1: 70.46%, 4m,13s\n",
      "Test  Corrects: Top-1: 73.17%, 15.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.570, Losses [0: 2.8, 1: 1.51, 2: 0.66, 3: 1.58]Per Epoch: 4m,3s  , Alloc: 6.29GiB    \n",
      "Train Corrects: Top-1: 75.47%, 4m,13s\n",
      "Test  Corrects: Top-1: 67.64%, 15.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.833, Losses [0: 2.55, 1: 0.93, 2: 0.58, 3: 1.02]Per Epoch: 3m,59s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 74.01%, 4m,13s\n",
      "Test  Corrects: Top-1: 74.94%, 15.50 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.288, Losses [0: 4.47, 1: 1.46, 2: 0.62, 3: 0.98]Per Epoch: 4m,9s  , Alloc: 6.29GiB   \n",
      "Train Corrects: Top-1: 76.26%, 4m,14s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 4,942,111 -> 4,906,270\n",
      "Pre-prune Test  Corrects: Top-1: 80.28%, 15.50 s\n",
      "Post-prune Test  Corrects: Top-1: 80.28%, 15.39 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.160, Losses [0: 2.25, 1: 1.27, 2: 0.31, 3: 1.39]Per Epoch: 3m,59s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 81.71%, 4m,13s\n",
      "Test  Corrects: Top-1: 80.66%, 15.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.133, Losses [0: 1.84, 1: 0.72, 2: 0.4, 3: 0.54]Per Epoch: 4m,6s  , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 83.49%, 4m,14s\n",
      "Test  Corrects: Top-1: 86.28%, 15.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.995, Losses [0: 1.04, 1: 0.8, 2: 0.35, 3: 0.56]Per Epoch: 4m,2s  , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 86.28%, 4m,13s\n",
      "Test  Corrects: Top-1: 87.25%, 15.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.756, Losses [0: 1.29, 1: 0.63, 2: 0.35, 3: 0.3]Per Epoch: 4m,11s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 87.41%, 4m,14s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,906,270 -> 4,906,270\n",
      "Pre-prune Test  Corrects: Top-1: 87.83%, 15.37 s\n",
      "Post-prune Test  Corrects: Top-1: 87.83%, 15.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.151, I: 1.000], Loss Comp: [C: 2.116, E: 1.681, I: 0.00], Losses [0: 0.41, 1: 0.41, 2: 0.25, 3: 0.22]Per Epoch: 5m,27s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 88.01%, Comp: 0.15, 1.00 5m,45s\n",
      "Train Loss Components: C: 3.060, E: 1.681, I: 0.00\n",
      "Test  Corrects: Top-1: 88.28%, 15.35 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.148, I: 1.000], Loss Comp: [C: 16.822, E: 1.643, I: 0.00], Losses [0: 4.46, 1: 2.93, 2: 2.55, 3: 13.19]Per Epoch: 5m,40s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 72.95%, Comp: 0.15, 1.00 5m,45s\n",
      "Train Loss Components: C: 19.680, E: 1.643, I: 0.00\n",
      "Test  Corrects: Top-1: 23.17%, 15.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.144, I: 1.000], Loss Comp: [C: 9.191, E: 1.602, I: 0.00], Losses [0: 4.47, 1: 2.53, 2: 1.62, 3: 5.87]Per Epoch: 5m,37s , Alloc: 6.29GiB   \n",
      "Train Corrects: Top-1: 55.12%, Comp: 0.14, 1.00 5m,45s\n",
      "Train Loss Components: C: 24.254, E: 1.602, I: 0.00\n",
      "Test  Corrects: Top-1: 63.76%, 15.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 1.000], Loss Comp: [C: 4.064, E: 1.584, I: 0.00], Losses [0: 2.15, 1: 1.28, 2: 0.87, 3: 1.62]Per Epoch: 5m,45s , Alloc: 6.29GiB   \n",
      "Train Corrects: Top-1: 65.55%, Comp: 0.14, 1.00 5m,45s\n",
      "Train Loss Components: C: 3.969, E: 1.584, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,906,270 -> 4,906,270\n",
      "Pre-prune Test  Corrects: Top-1: 73.25%, 15.33 s\n",
      "Post-prune Test  Corrects: Top-1: 73.25%, 15.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 1.000], Loss Comp: [C: 3.737, E: 1.592, I: 0.00], Losses [0: 2.25, 1: 1.08, 2: 0.66, 3: 1.35]Per Epoch: 5m,35s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 70.94%, Comp: 0.14, 1.00 5m,45s\n",
      "Train Loss Components: C: 2.210, E: 1.592, I: 0.00\n",
      "Test  Corrects: Top-1: 75.70%, 15.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.145, I: 1.000], Loss Comp: [C: 2.869, E: 1.609, I: 0.00], Losses [0: 1.81, 1: 0.71, 2: 0.52, 3: 0.65]Per Epoch: 5m,52s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 76.49%, Comp: 0.15, 1.00 5m,45s\n",
      "Train Loss Components: C: 1.906, E: 1.609, I: 0.00\n",
      "Test  Corrects: Top-1: 80.78%, 15.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.145, I: 1.000], Loss Comp: [C: 3.869, E: 1.610, I: 0.00], Losses [0: 1.55, 1: 0.94, 2: 0.74, 3: 1.61]Per Epoch: 5m,43s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 80.10%, Comp: 0.15, 1.00 5m,44s\n",
      "Train Loss Components: C: 2.644, E: 1.610, I: 0.00\n",
      "Test  Corrects: Top-1: 83.51%, 15.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 1.000], Loss Comp: [C: 2.640, E: 1.575, I: 0.00], Losses [0: 1.29, 1: 0.66, 2: 0.5, 3: 0.58]Per Epoch: 5m,42s , Alloc: 6.29GiB  \n",
      "Train Corrects: Top-1: 82.34%, Comp: 0.14, 1.00 5m,45s\n",
      "Train Loss Components: C: 2.595, E: 1.575, I: 0.00\n",
      "\n",
      "Deadheaded 4 operations\n",
      "Param Delta: 4,906,270 -> 4,883,738\n",
      "Pre-prune Test  Corrects: Top-1: 81.87%, 15.33 s\n",
      "Post-prune Test  Corrects: Top-1: 81.87%, 14.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.80859375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 0.00010582642380445317\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 88.00MiB\n",
      "1: 1.10GiB\n",
      "2: 1.90GiB\n",
      "3: 2.74GiB\n",
      "4: 3.60GiB\n",
      "5: 4.41GiB\n",
      "6: 4.61GiB\n",
      "7: 4.78GiB\n",
      "8: 5.09GiB\n",
      "9: 5.33GiB\n",
      "10: 5.41GiB\n",
      "11: 5.41GiB\n",
      "12: 5.41GiB\n",
      "13: 5.49GiB\n",
      "14: 5.63GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.774, Losses [0: 2.53, 1: 1.0, 2: 0.57, 3: 0.95]Per Epoch: 3m,57s , Alloc: 5.89GiB    \n",
      "Train Corrects: Top-1: 71.76%, 4m,3s\n",
      "Test  Corrects: Top-1: 80.90%, 14.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.304, Losses [0: 1.99, 1: 0.71, 2: 0.42, 3: 0.68]Per Epoch: 3m,50s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 71.67%, 4m,2s\n",
      "Test  Corrects: Top-1: 78.44%, 14.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.541, Losses [0: 2.06, 1: 0.76, 2: 0.55, 3: 0.87]Per Epoch: 4m,1s  , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 73.83%, 4m,3s\n",
      "Test  Corrects: Top-1: 79.81%, 14.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.489, Losses [0: 2.93, 1: 0.95, 2: 0.52, 3: 0.61]Per Epoch: 3m,49s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 77.47%, 4m,2s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,883,738 -> 4,883,738\n",
      "Pre-prune Test  Corrects: Top-1: 82.19%, 14.85 s\n",
      "Post-prune Test  Corrects: Top-1: 82.19%, 14.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.057, Losses [0: 1.8, 1: 0.87, 2: 0.44, 3: 0.43]Per Epoch: 3m,51s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 79.76%, 4m,3s\n",
      "Test  Corrects: Top-1: 81.65%, 14.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.657, Losses [0: 0.96, 1: 0.66, 2: 0.3, 3: 0.27]Per Epoch: 3m,57s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 82.31%, 4m,2s\n",
      "Test  Corrects: Top-1: 84.68%, 14.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.025, Losses [0: 1.5, 1: 0.69, 2: 0.45, 3: 0.5]Per Epoch: 3m,50s , Alloc: 6.04GiB   \n",
      "Train Corrects: Top-1: 84.62%, 4m,2s\n",
      "Test  Corrects: Top-1: 86.63%, 14.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.952, Losses [0: 1.36, 1: 0.56, 2: 0.46, 3: 0.48]Per Epoch: 3m,54s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 85.78%, 4m,2s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,883,738 -> 4,883,738\n",
      "Pre-prune Test  Corrects: Top-1: 86.67%, 14.85 s\n",
      "Post-prune Test  Corrects: Top-1: 86.67%, 14.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.146, I: 1.000], Loss Comp: [C: 2.703, E: 1.723, I: 0.00], Losses [0: 1.11, 1: 0.7, 2: 0.48, 3: 0.52]Per Epoch: 5m,27s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 86.28%, Comp: 0.15, 1.00 5m,33s\n",
      "Train Loss Components: C: 4.210, E: 1.723, I: 0.00\n",
      "Test  Corrects: Top-1: 87.08%, 14.85 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 1.000], Loss Comp: [C: 4.085, E: 1.673, I: 0.00], Losses [0: 3.19, 1: 1.4, 2: 0.69, 3: 1.36]Per Epoch: 5m,28s , Alloc: 6.04GiB   \n",
      "Train Corrects: Top-1: 81.06%, Comp: 0.14, 1.00 5m,33s\n",
      "Train Loss Components: C: 9.438, E: 1.655, I: 0.00\n",
      "Test  Corrects: Top-1: 34.23%, 14.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.145, I: 1.000], Loss Comp: [C: 3.900, E: 1.704, I: 0.00], Losses [0: 2.44, 1: 1.14, 2: 0.66, 3: 1.35]Per Epoch: 5m,33s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 78.21%, Comp: 0.15, 1.00 5m,34s\n",
      "Train Loss Components: C: 3.336, E: 1.704, I: 0.00\n",
      "Test  Corrects: Top-1: 80.14%, 14.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.144, I: 1.000], Loss Comp: [C: 3.502, E: 1.695, I: 0.00], Losses [0: 3.28, 1: 1.15, 2: 0.52, 3: 0.82]Per Epoch: 5m,28s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 80.48%, Comp: 0.14, 1.00 5m,34s\n",
      "Train Loss Components: C: 3.711, E: 1.695, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,883,738 -> 4,883,738\n",
      "Pre-prune Test  Corrects: Top-1: 84.59%, 14.87 s\n",
      "Post-prune Test  Corrects: Top-1: 84.59%, 14.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.145, I: 1.000], Loss Comp: [C: 2.923, E: 1.704, I: 0.00], Losses [0: 1.95, 1: 0.95, 2: 0.43, 3: 0.55]Per Epoch: 5m,10s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 82.56%, Comp: 0.15, 1.00 5m,33s\n",
      "Train Loss Components: C: 3.046, E: 1.704, I: 0.00\n",
      "Test  Corrects: Top-1: 84.07%, 14.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.144, I: 1.000], Loss Comp: [C: 3.095, E: 1.685, I: 0.00], Losses [0: 2.06, 1: 0.78, 2: 0.56, 3: 0.73]Per Epoch: 5m,10s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 84.28%, Comp: 0.14, 1.00 5m,34s\n",
      "Train Loss Components: C: 2.665, E: 1.685, I: 0.00\n",
      "Test  Corrects: Top-1: 85.18%, 14.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.144, I: 1.000], Loss Comp: [C: 2.214, E: 1.685, I: 0.00], Losses [0: 0.97, 1: 0.46, 2: 0.23, 3: 0.2]Per Epoch: 5m,17s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 86.66%, Comp: 0.14, 1.00 5m,34s\n",
      "Train Loss Components: C: 2.802, E: 1.685, I: 0.00\n",
      "Test  Corrects: Top-1: 87.17%, 14.82 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 1.000], Loss Comp: [C: 2.358, E: 1.676, I: 0.00], Losses [0: 0.95, 1: 0.42, 2: 0.34, 3: 0.34]Per Epoch: 5m,33s , Alloc: 6.04GiB  \n",
      "Train Corrects: Top-1: 87.30%, Comp: 0.14, 1.00 5m,38s\n",
      "Train Loss Components: C: 3.493, E: 1.676, I: 0.00\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 4,883,738 -> 4,848,153\n",
      "Pre-prune Test  Corrects: Top-1: 87.85%, 14.84 s\n",
      "Post-prune Test  Corrects: Top-1: 87.85%, 14.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.765625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 7.936981785333988e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 88.00MiB\n",
      "1: 1.10GiB\n",
      "2: 1.90GiB\n",
      "3: 2.74GiB\n",
      "4: 3.60GiB\n",
      "5: 4.35GiB\n",
      "6: 4.54GiB\n",
      "7: 4.72GiB\n",
      "8: 5.02GiB\n",
      "9: 5.25GiB\n",
      "10: 5.32GiB\n",
      "11: 5.32GiB\n",
      "12: 5.32GiB\n",
      "13: 5.44GiB\n",
      "14: 5.58GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.914, Losses [0: 2.84, 1: 1.39, 2: 0.66, 3: 0.94]Per Epoch: 3m,56s , Alloc: 5.82GiB   \n",
      "Train Corrects: Top-1: 81.29%, 4m,1s\n",
      "Test  Corrects: Top-1: 81.42%, 14.77 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.362, Losses [0: 2.56, 1: 1.12, 2: 0.56, 3: 0.51]Per Epoch: 3m,42s , Alloc: 5.98GiB   \n",
      "Train Corrects: Top-1: 79.63%, 4m,0s\n",
      "Test  Corrects: Top-1: 82.44%, 14.73 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.692, Losses [0: 2.21, 1: 1.03, 2: 0.3, 3: 1.98]Per Epoch: 3m,52s , Alloc: 5.98GiB    \n",
      "Train Corrects: Top-1: 79.77%, 4m,1s\n",
      "Test  Corrects: Top-1: 78.09%, 14.79 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.216, Losses [0: 3.95, 1: 1.39, 2: 0.58, 3: 1.03]Per Epoch: 3m,49s , Alloc: 5.98GiB   \n",
      "Train Corrects: Top-1: 79.65%, 4m,0s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,848,153 -> 4,848,153\n",
      "Pre-prune Test  Corrects: Top-1: 82.92%, 14.74 s\n",
      "Post-prune Test  Corrects: Top-1: 82.92%, 14.76 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.127, Losses [0: 3.24, 1: 1.67, 2: 0.69, 3: 1.01]Per Epoch: 3m,58s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 82.50%, 4m,0s\n",
      "Test  Corrects: Top-1: 85.90%, 14.76 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.681, Losses [0: 1.22, 1: 0.73, 2: 0.26, 3: 0.24]Per Epoch: 3m,57s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 85.27%, 4m,0s\n",
      "Test  Corrects: Top-1: 86.92%, 14.75 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.024, Losses [0: 1.55, 1: 0.62, 2: 0.46, 3: 0.5]Per Epoch: 3m,48s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 87.54%, 4m,0s\n",
      "Test  Corrects: Top-1: 87.39%, 14.75 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.901, Losses [0: 1.47, 1: 0.59, 2: 0.4, 3: 0.41]Per Epoch: 3m,43s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 88.43%, 4m,0s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,848,153 -> 4,848,153\n",
      "Pre-prune Test  Corrects: Top-1: 88.82%, 14.74 s\n",
      "Post-prune Test  Corrects: Top-1: 88.82%, 14.76 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 1.000], Loss Comp: [C: 2.674, E: 1.762, I: 0.00], Losses [0: 0.74, 1: 0.57, 2: 0.44, 3: 0.56]Per Epoch: 5m,14s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 89.05%, Comp: 0.14, 1.00 5m,31s\n",
      "Train Loss Components: C: 2.968, E: 1.762, I: 0.00\n",
      "Test  Corrects: Top-1: 86.31%, 14.73 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.142, I: 1.000], Loss Comp: [C: 6.925, E: 1.742, I: 0.00], Losses [0: 2.63, 1: 0.82, 2: 2.02, 3: 4.09]Per Epoch: 5m,16s , Alloc: 5.98GiB   \n",
      "Train Corrects: Top-1: 78.08%, Comp: 0.14, 1.00 5m,31s\n",
      "Train Loss Components: C: 4.409, E: 1.780, I: 0.00\n",
      "Test  Corrects: Top-1: 81.24%, 14.76 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.145, I: 1.000], Loss Comp: [C: 4.568, E: 1.799, I: 0.00], Losses [0: 2.92, 1: 1.44, 2: 0.68, 3: 1.76]Per Epoch: 5m,35s , Alloc: 5.98GiB   \n",
      "Train Corrects: Top-1: 78.19%, Comp: 0.14, 1.00 5m,31s\n",
      "Train Loss Components: C: 3.892, E: 1.779, I: 0.00\n",
      "Test  Corrects: Top-1: 84.11%, 14.74 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.140, I: 1.000], Loss Comp: [C: 3.392, E: 1.742, I: 0.00], Losses [0: 2.26, 1: 0.96, 2: 0.62, 3: 0.88]Per Epoch: 5m,5s  , Alloc: 5.98GiB   \n",
      "Train Corrects: Top-1: 81.28%, Comp: 0.14, 1.00 5m,32s\n",
      "Train Loss Components: C: 6.013, E: 1.751, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,848,153 -> 4,848,153\n",
      "Pre-prune Test  Corrects: Top-1: 81.93%, 14.74 s\n",
      "Post-prune Test  Corrects: Top-1: 81.93%, 14.75 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 1.000], Loss Comp: [C: 2.946, E: 1.759, I: 0.00], Losses [0: 2.66, 1: 0.99, 2: 0.34, 3: 0.39]Per Epoch: 5m,34s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 83.23%, Comp: 0.14, 1.00 5m,31s\n",
      "Train Loss Components: C: 4.885, E: 1.741, I: 0.00\n",
      "Test  Corrects: Top-1: 75.91%, 14.75 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.144, I: 1.000], Loss Comp: [C: 2.696, E: 1.779, I: 0.00], Losses [0: 1.31, 1: 0.4, 2: 0.27, 3: 0.52]Per Epoch: 5m,10s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 85.77%, Comp: 0.14, 1.00 5m,31s\n",
      "Train Loss Components: C: 2.620, E: 1.779, I: 0.00\n",
      "Test  Corrects: Top-1: 86.74%, 14.75 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.144, I: 0.933], Loss Comp: [C: 2.535, E: 1.779, I: 0.17], Losses [0: 1.11, 1: 0.24, 2: 0.25, 3: 0.26]Per Epoch: 5m,23s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 86.84%, Comp: 0.14, 0.93 5m,30s\n",
      "Train Loss Components: C: 2.752, E: 1.779, I: 0.17\n",
      "Test  Corrects: Top-1: 88.15%, 14.73 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.142, I: 1.000], Loss Comp: [C: 2.611, E: 1.745, I: 0.00], Losses [0: 1.34, 1: 0.72, 2: 0.42, 3: 0.37]Per Epoch: 5m,31s , Alloc: 5.98GiB  \n",
      "Train Corrects: Top-1: 88.31%, Comp: 0.14, 0.93 5m,30s\n",
      "Train Loss Components: C: 2.231, E: 1.759, I: 0.17\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 4,848,153 -> 4,311,576\n",
      "Pre-prune Test  Corrects: Top-1: 88.25%, 14.76 s\n",
      "Post-prune Test  Corrects: Top-1: 88.25%, 14.66 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.73828125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 5.952736339000491e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 84.00MiB\n",
      "1: 1.10GiB\n",
      "2: 1.89GiB\n",
      "3: 2.74GiB\n",
      "4: 3.60GiB\n",
      "5: 4.35GiB\n",
      "6: 4.54GiB\n",
      "7: 4.71GiB\n",
      "8: 5.02GiB\n",
      "9: 5.25GiB\n",
      "10: 5.32GiB\n",
      "11: 5.32GiB\n",
      "12: 5.32GiB\n",
      "13: 5.44GiB\n",
      "14: 5.57GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.406, Losses [0: 2.48, 1: 0.98, 2: 0.45, 3: 0.62]Per Epoch: 3m,43s , Alloc: 5.82GiB   \n",
      "Train Corrects: Top-1: 80.58%, 3m,58s\n",
      "Test  Corrects: Top-1: 80.14%, 14.65 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.638, Losses [0: 3.13, 1: 1.27, 2: 0.55, 3: 0.65]Per Epoch: 3m,54s , Alloc: 5.97GiB   \n",
      "Train Corrects: Top-1: 76.62%, 3m,58s\n",
      "Test  Corrects: Top-1: 82.10%, 14.67 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.510, Losses [0: 4.37, 1: 2.11, 2: 0.79, 3: 1.05]Per Epoch: 3m,41s , Alloc: 5.97GiB   \n",
      "Train Corrects: Top-1: 72.65%, 3m,58s\n",
      "Test  Corrects: Top-1: 80.08%, 14.69 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.896, Losses [0: 3.68, 1: 1.37, 2: 0.59, 3: 0.77]Per Epoch: 3m,46s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 77.19%, 3m,58s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 4,311,576 -> 4,311,575\n",
      "Pre-prune Test  Corrects: Top-1: 82.46%, 14.63 s\n",
      "Post-prune Test  Corrects: Top-1: 82.46%, 14.65 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.167, Losses [0: 2.43, 1: 0.93, 2: 0.43, 3: 0.41]Per Epoch: 3m,51s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 81.63%, 3m,58s\n",
      "Test  Corrects: Top-1: 85.58%, 14.66 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.953, Losses [0: 1.61, 1: 0.78, 2: 0.37, 3: 0.4]Per Epoch: 3m,39s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 84.54%, 3m,59s\n",
      "Test  Corrects: Top-1: 86.72%, 14.65 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.154, Losses [0: 1.67, 1: 0.86, 2: 0.46, 3: 0.56]Per Epoch: 3m,45s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 86.33%, 3m,58s\n",
      "Test  Corrects: Top-1: 87.45%, 14.65 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.913, Losses [0: 1.36, 1: 0.73, 2: 0.38, 3: 0.42]Per Epoch: 3m,47s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 87.53%, 3m,58s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,311,575 -> 4,311,575\n",
      "Pre-prune Test  Corrects: Top-1: 87.96%, 14.65 s\n",
      "Post-prune Test  Corrects: Top-1: 87.96%, 14.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.144, I: 0.933], Loss Comp: [C: 2.683, E: 1.873, I: 0.18], Losses [0: 0.82, 1: 0.44, 2: 0.32, 3: 0.31]Per Epoch: 5m,16s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 88.17%, Comp: 0.14, 0.93 5m,30s\n",
      "Train Loss Components: C: 3.026, E: 1.873, I: 0.18\n",
      "Test  Corrects: Top-1: 88.09%, 14.65 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.143, I: 0.933], Loss Comp: [C: 5.988, E: 1.854, I: 0.18], Losses [0: 4.55, 1: 1.74, 2: 1.27, 3: 2.44]Per Epoch: 5m,27s , Alloc: 5.97GiB   \n",
      "Train Corrects: Top-1: 71.45%, Comp: 0.14, 0.93 5m,28s\n",
      "Train Loss Components: C: 4.922, E: 1.854, I: 0.18\n",
      "Test  Corrects: Top-1: 71.57%, 14.66 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.142, I: 0.933], Loss Comp: [C: 4.197, E: 1.854, I: 0.18], Losses [0: 3.5, 1: 1.87, 2: 0.71, 3: 0.95]Per Epoch: 5m,16s , Alloc: 5.97GiB    \n",
      "Train Corrects: Top-1: 68.30%, Comp: 0.14, 0.93 5m,28s\n",
      "Train Loss Components: C: 3.744, E: 1.854, I: 0.18\n",
      "Test  Corrects: Top-1: 80.40%, 14.65 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.140, I: 0.933], Loss Comp: [C: 4.100, E: 1.851, I: 0.18], Losses [0: 3.09, 1: 1.66, 2: 0.63, 3: 0.99]Per Epoch: 5m,12s , Alloc: 5.97GiB   \n",
      "Train Corrects: Top-1: 75.27%, Comp: 0.14, 0.93 5m,29s\n",
      "Train Loss Components: C: 13.434, E: 1.851, I: 0.18\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,311,575 -> 4,311,575\n",
      "Pre-prune Test  Corrects: Top-1: 78.76%, 14.63 s\n",
      "Post-prune Test  Corrects: Top-1: 78.76%, 14.63 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.140, I: 0.933], Loss Comp: [C: 3.247, E: 1.851, I: 0.18], Losses [0: 2.64, 1: 0.95, 2: 0.35, 3: 0.43]Per Epoch: 5m,13s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 78.74%, Comp: 0.14, 0.93 5m,28s\n",
      "Train Loss Components: C: 4.057, E: 1.851, I: 0.18\n",
      "Test  Corrects: Top-1: 82.83%, 14.68 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.139, I: 0.933], Loss Comp: [C: 3.288, E: 1.831, I: 0.18], Losses [0: 1.65, 1: 0.81, 2: 0.51, 3: 0.68]Per Epoch: 5m,5s  , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 82.18%, Comp: 0.14, 0.93 5m,29s\n",
      "Train Loss Components: C: 6.449, E: 1.831, I: 0.18\n",
      "Test  Corrects: Top-1: 85.96%, 14.63 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.137, I: 0.933], Loss Comp: [C: 2.788, E: 1.809, I: 0.18], Losses [0: 1.58, 1: 0.51, 2: 0.31, 3: 0.32]Per Epoch: 5m,23s , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 84.68%, Comp: 0.14, 1.33 5m,29s\n",
      "Train Loss Components: C: 3.193, E: 1.809, I: 0.91\n",
      "Test  Corrects: Top-1: 86.58%, 14.62 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 0.933], Loss Comp: [C: 3.094, E: 1.789, I: 0.18], Losses [0: 1.34, 1: 0.88, 2: 0.49, 3: 0.58]Per Epoch: 5m,9s  , Alloc: 5.97GiB  \n",
      "Train Corrects: Top-1: 86.17%, Comp: 0.14, 1.27 5m,29s\n",
      "Train Loss Components: C: 5.149, E: 1.807, I: 0.73\n",
      "\n",
      "Deadheaded 3 operations\n",
      "Param Delta: 4,311,575 -> 4,275,220\n",
      "Pre-prune Test  Corrects: Top-1: 81.31%, 14.66 s\n",
      "Post-prune Test  Corrects: Top-1: 81.30%, 14.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.6015625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 4.464552254250368e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 84.00MiB\n",
      "1: 1.10GiB\n",
      "2: 1.89GiB\n",
      "3: 2.74GiB\n",
      "4: 3.60GiB\n",
      "5: 4.35GiB\n",
      "6: 4.46GiB\n",
      "7: 4.58GiB\n",
      "8: 4.85GiB\n",
      "9: 5.10GiB\n",
      "10: 5.18GiB\n",
      "11: 5.18GiB\n",
      "12: 5.18GiB\n",
      "13: 5.30GiB\n",
      "14: 5.43GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 5.668, Losses [0: 3.57, 1: 1.99, 2: 1.49, 3: 4.26]Per Epoch: 3m,48s , Alloc: 5.67GiB   \n",
      "Train Corrects: Top-1: 62.80%, 3m,53s\n",
      "Test  Corrects: Top-1: 68.59%, 14.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.422, Losses [0: 2.82, 1: 1.47, 2: 0.66, 3: 1.43]Per Epoch: 3m,47s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 66.67%, 3m,54s\n",
      "Test  Corrects: Top-1: 76.76%, 14.48 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.718, Losses [0: 2.78, 1: 1.06, 2: 0.55, 3: 0.84]Per Epoch: 3m,49s , Alloc: 5.82GiB   \n",
      "Train Corrects: Top-1: 70.16%, 3m,53s\n",
      "Test  Corrects: Top-1: 77.65%, 14.49 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.754, Losses [0: 4.24, 1: 1.7, 2: 0.84, 3: 1.4]Per Epoch: 3m,48s , Alloc: 5.82GiB   \n",
      "Train Corrects: Top-1: 75.17%, 3m,53s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 4,275,220 -> 4,274,963\n",
      "Pre-prune Test  Corrects: Top-1: 78.92%, 14.48 s\n",
      "Post-prune Test  Corrects: Top-1: 78.92%, 14.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.617, Losses [0: 2.03, 1: 1.26, 2: 0.55, 3: 0.85]Per Epoch: 3m,46s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 77.34%, 3m,54s\n",
      "Test  Corrects: Top-1: 83.53%, 14.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.575, Losses [0: 2.0, 1: 1.28, 2: 0.71, 3: 0.78]Per Epoch: 3m,51s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 81.57%, 3m,54s\n",
      "Test  Corrects: Top-1: 84.47%, 14.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.920, Losses [0: 2.08, 1: 0.77, 2: 0.35, 3: 0.28]Per Epoch: 3m,48s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 82.72%, 3m,54s\n",
      "Test  Corrects: Top-1: 85.73%, 14.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.395, Losses [0: 0.53, 1: 0.3, 2: 0.21, 3: 0.19]Per Epoch: 3m,42s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 84.42%, 3m,54s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,274,963 -> 4,274,963\n",
      "Pre-prune Test  Corrects: Top-1: 86.29%, 14.46 s\n",
      "Post-prune Test  Corrects: Top-1: 86.29%, 14.51 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.138, I: 1.000], Loss Comp: [C: 2.810, E: 1.920, I: 0.00], Losses [0: 0.87, 1: 0.55, 2: 0.48, 3: 0.51]Per Epoch: 5m,1s  , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 85.11%, Comp: 0.14, 1.00 5m,22s\n",
      "Train Loss Components: C: 3.651, E: 1.920, I: 0.00\n",
      "Test  Corrects: Top-1: 86.48%, 14.40 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.138, I: 1.600], Loss Comp: [C: 7.886, E: 1.930, I: 1.72], Losses [0: 3.76, 1: 2.11, 2: 1.02, 3: 2.86]Per Epoch: 5m,5s  , Alloc: 5.82GiB   \n",
      "Train Corrects: Top-1: 69.16%, Comp: 0.14, 1.33 5m,24s\n",
      "Train Loss Components: C: 8.051, E: 1.930, I: 0.95\n",
      "Test  Corrects: Top-1: 74.48%, 14.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.137, I: 0.933], Loss Comp: [C: 4.306, E: 1.908, I: 0.19], Losses [0: 2.63, 1: 1.63, 2: 0.8, 3: 1.19]Per Epoch: 5m,3s  , Alloc: 5.82GiB    \n",
      "Train Corrects: Top-1: 73.04%, Comp: 0.14, 0.93 5m,24s\n",
      "Train Loss Components: C: 4.104, E: 1.908, I: 0.19\n",
      "Test  Corrects: Top-1: 76.55%, 14.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 0.933], Loss Comp: [C: 9.991, E: 1.885, I: 0.19], Losses [0: 5.27, 1: 3.32, 2: 2.4, 3: 5.71]Per Epoch: 5m,15s , Alloc: 5.82GiB     \n",
      "Train Corrects: Top-1: 46.16%, Comp: 0.14, 1.33 5m,23s\n",
      "Train Loss Components: C: 42.211, E: 1.885, I: 0.95\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,274,963 -> 4,274,963\n",
      "Pre-prune Test  Corrects: Top-1: 20.35%, 14.44 s\n",
      "Post-prune Test  Corrects: Top-1: 20.35%, 14.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.400], Loss Comp: [C: 14.025, E: 1.885, I: 1.15], Losses [0: 4.72, 1: 3.08, 2: 3.01, 3: 8.83]Per Epoch: 5m,24s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 32.51%, Comp: 0.14, 1.33 5m,24s\n",
      "Train Loss Components: C: 22.159, E: 1.885, I: 0.95\n",
      "Test  Corrects: Top-1: 41.17%, 14.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.135, I: 0.933], Loss Comp: [C: 9.012, E: 1.864, I: 0.19], Losses [0: 2.15, 1: 2.0, 2: 2.17, 3: 5.69]Per Epoch: 5m,1s  , Alloc: 5.82GiB    \n",
      "Train Corrects: Top-1: 35.89%, Comp: 0.13, 0.93 5m,24s\n",
      "Train Loss Components: C: 6.386, E: 1.864, I: 0.19\n",
      "Test  Corrects: Top-1: 44.10%, 14.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.267], Loss Comp: [C: 5.961, E: 1.885, I: 0.76], Losses [0: 2.19, 1: 1.66, 2: 1.77, 3: 2.19]Per Epoch: 5m,14s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 42.23%, Comp: 0.14, 1.27 5m,22s\n",
      "Train Loss Components: C: 7.784, E: 1.885, I: 0.76\n",
      "Test  Corrects: Top-1: 47.86%, 14.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.067], Loss Comp: [C: 4.121, E: 1.885, I: 0.19], Losses [0: 1.35, 1: 1.22, 2: 1.3, 3: 1.27]Per Epoch: 5m,20s , Alloc: 5.82GiB  \n",
      "Train Corrects: Top-1: 47.05%, Comp: 0.14, 1.07 5m,22s\n",
      "Train Loss Components: C: 6.431, E: 1.885, I: 0.19\n",
      "\n",
      "Deadheaded 3 operations\n",
      "Param Delta: 4,274,963 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 48.11%, 14.44 s\n",
      "Post-prune Test  Corrects: Top-1: 48.09%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.37890625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 3.348414190687776e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 84.00MiB\n",
      "1: 1.10GiB\n",
      "2: 1.89GiB\n",
      "3: 2.61GiB\n",
      "4: 3.47GiB\n",
      "5: 4.13GiB\n",
      "6: 4.23GiB\n",
      "7: 4.34GiB\n",
      "8: 4.61GiB\n",
      "9: 4.84GiB\n",
      "10: 4.91GiB\n",
      "11: 4.91GiB\n",
      "12: 4.93GiB\n",
      "13: 5.07GiB\n",
      "14: 5.21GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 6.748, Losses [0: 4.59, 1: 2.99, 2: 2.02, 3: 4.83]Per Epoch: 3m,32s , Alloc: 5.45GiB    \n",
      "Train Corrects: Top-1: 28.51%, 3m,45s\n",
      "Test  Corrects: Top-1: 27.90%, 14.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 10.868, Losses [0: 6.88, 1: 3.37, 2: 2.86, 3: 8.25]Per Epoch: 3m,45s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 29.05%, 3m,44s\n",
      "Test  Corrects: Top-1: 38.23%, 14.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 5.192, Losses [0: 3.75, 1: 1.87, 2: 1.62, 3: 3.74]Per Epoch: 3m,35s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 32.18%, 3m,45s\n",
      "Test  Corrects: Top-1: 41.39%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 13.911, Losses [0: 5.9, 1: 3.13, 2: 2.36, 3: 11.63]Per Epoch: 3m,42s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 33.82%, 3m,44s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,229,136 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 30.19%, 14.05 s\n",
      "Post-prune Test  Corrects: Top-1: 30.19%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 6.353, Losses [0: 4.46, 1: 2.27, 2: 2.96, 3: 4.42]Per Epoch: 3m,35s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 33.90%, 3m,45s\n",
      "Test  Corrects: Top-1: 48.00%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 4.107, Losses [0: 2.77, 1: 1.81, 2: 1.54, 3: 2.88]Per Epoch: 3m,37s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 42.24%, 3m,44s\n",
      "Test  Corrects: Top-1: 46.65%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 2.888, Losses [0: 2.6, 1: 1.69, 2: 1.6, 3: 1.71]Per Epoch: 3m,38s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 46.72%, 3m,45s\n",
      "Test  Corrects: Top-1: 55.24%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 2.578, Losses [0: 1.93, 1: 1.5, 2: 1.45, 3: 1.6]Per Epoch: 3m,47s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 51.02%, 3m,44s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,229,136 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 59.76%, 14.05 s\n",
      "Post-prune Test  Corrects: Top-1: 59.76%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.000], Loss Comp: [C: 4.496, E: 1.975, I: 0.00], Losses [0: 1.34, 1: 1.29, 2: 1.37, 3: 1.72]Per Epoch: 4m,59s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 54.75%, Comp: 0.14, 0.93 5m,14s\n",
      "Train Loss Components: C: 5.329, E: 1.975, I: 0.20\n",
      "Test  Corrects: Top-1: 60.97%, 14.03 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.135, I: 1.600], Loss Comp: [C: 13.984, E: 1.964, I: 1.80], Losses [0: 6.55, 1: 3.27, 2: 3.74, 3: 7.51]Per Epoch: 4m,51s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 35.46%, Comp: 0.13, 0.93 5m,14s\n",
      "Train Loss Components: C: 23.460, E: 1.964, I: 0.20\n",
      "Test  Corrects: Top-1: 10.03%, 14.02 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.135, I: 0.933], Loss Comp: [C: 6.562, E: 1.964, I: 0.20], Losses [0: 5.84, 1: 2.9, 2: 1.83, 3: 2.28]Per Epoch: 5m,3s  , Alloc: 5.60GiB    \n",
      "Train Corrects: Top-1: 37.66%, Comp: 0.13, 1.20 5m,14s\n",
      "Train Loss Components: C: 14.194, E: 1.964, I: 0.60\n",
      "Test  Corrects: Top-1: 10.00%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.200], Loss Comp: [C: 13.626, E: 1.975, I: 0.60], Losses [0: 4.12, 1: 3.01, 2: 2.65, 3: 9.09]Per Epoch: 4m,54s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 29.60%, Comp: 0.14, 0.93 5m,13s\n",
      "Train Loss Components: C: 13.960, E: 1.975, I: 0.20\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,229,136 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 10.19%, 14.02 s\n",
      "Post-prune Test  Corrects: Top-1: 10.19%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.600], Loss Comp: [C: 9.534, E: 1.975, I: 1.80], Losses [0: 4.09, 1: 2.27, 2: 1.74, 3: 4.14]Per Epoch: 5m,13s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 35.03%, Comp: 0.14, 1.20 5m,13s\n",
      "Train Loss Components: C: 16.052, E: 1.975, I: 0.60\n",
      "Test  Corrects: Top-1: 11.80%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.600], Loss Comp: [C: 6.477, E: 1.975, I: 1.80], Losses [0: 2.42, 1: 1.69, 2: 1.36, 3: 1.61]Per Epoch: 5m,22s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 41.11%, Comp: 0.14, 1.47 5m,13s\n",
      "Train Loss Components: C: 6.759, E: 1.975, I: 1.40\n",
      "Test  Corrects: Top-1: 11.51%, 14.03 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 0.933], Loss Comp: [C: 4.658, E: 1.975, I: 0.20], Losses [0: 1.75, 1: 1.51, 2: 1.24, 3: 1.58]Per Epoch: 5m,13s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 47.24%, Comp: 0.14, 0.93 5m,13s\n",
      "Train Loss Components: C: 5.766, E: 1.975, I: 0.20\n",
      "Test  Corrects: Top-1: 14.17%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.267], Loss Comp: [C: 5.846, E: 1.975, I: 0.80], Losses [0: 1.38, 1: 1.15, 2: 1.19, 3: 2.33]Per Epoch: 4m,59s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 51.45%, Comp: 0.14, 1.13 5m,14s\n",
      "Train Loss Components: C: 9.065, E: 1.975, I: 0.40\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,229,136 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 41.34%, 14.05 s\n",
      "Post-prune Test  Corrects: Top-1: 41.34%, 14.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.390625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 2.511310643015832e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 84.00MiB\n",
      "1: 1.10GiB\n",
      "2: 1.89GiB\n",
      "3: 2.61GiB\n",
      "4: 3.47GiB\n",
      "5: 4.13GiB\n",
      "6: 4.23GiB\n",
      "7: 4.34GiB\n",
      "8: 4.61GiB\n",
      "9: 4.84GiB\n",
      "10: 4.91GiB\n",
      "11: 4.91GiB\n",
      "12: 4.93GiB\n",
      "13: 5.07GiB\n",
      "14: 5.21GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 11.828, Losses [0: 8.24, 1: 3.24, 2: 2.3, 3: 9.07]Per Epoch: 3m,28s , Alloc: 5.45GiB   \n",
      "Train Corrects: Top-1: 39.90%, 3m,44s\n",
      "Test  Corrects: Top-1: 10.02%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 6.547, Losses [0: 4.69, 1: 2.67, 2: 1.52, 3: 4.77]Per Epoch: 3m,38s , Alloc: 5.60GiB    \n",
      "Train Corrects: Top-1: 36.20%, 3m,45s\n",
      "Test  Corrects: Top-1: 11.44%, 14.02 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 14.226, Losses [0: 5.33, 1: 3.6, 2: 4.1, 3: 11.62]Per Epoch: 3m,30s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 32.12%, 3m,45s\n",
      "Test  Corrects: Top-1: 10.33%, 14.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 5.063, Losses [0: 4.23, 1: 2.7, 2: 1.57, 3: 3.36]Per Epoch: 3m,40s , Alloc: 5.60GiB    \n",
      "Train Corrects: Top-1: 37.62%, 3m,45s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,229,136 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 14.30%, 14.06 s\n",
      "Post-prune Test  Corrects: Top-1: 14.30%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 10.213, Losses [0: 3.13, 1: 1.85, 2: 2.17, 3: 8.78]Per Epoch: 3m,30s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 41.62%, 3m,45s\n",
      "Test  Corrects: Top-1: 11.00%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 2.808, Losses [0: 3.07, 1: 2.14, 2: 1.28, 3: 1.51]Per Epoch: 3m,34s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 51.02%, 3m,45s\n",
      "Test  Corrects: Top-1: 14.41%, 14.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 5.589, Losses [0: 2.23, 1: 1.27, 2: 1.45, 3: 4.6]Per Epoch: 3m,34s , Alloc: 5.60GiB    \n",
      "Train Corrects: Top-1: 53.57%, 3m,44s\n",
      "Test  Corrects: Top-1: 37.48%, 14.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 4.796, Losses [0: 1.49, 1: 1.08, 2: 1.72, 3: 3.94]Per Epoch: 3m,38s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 56.08%, 3m,45s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,229,136 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 57.53%, 14.05 s\n",
      "Post-prune Test  Corrects: Top-1: 57.53%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.136, I: 1.067], Loss Comp: [C: 4.524, E: 2.065, I: 0.21], Losses [0: 1.44, 1: 1.35, 2: 1.38, 3: 1.42]Per Epoch: 5m,7s  , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 57.17%, Comp: 0.14, 1.07 5m,14s\n",
      "Train Loss Components: C: 3.785, E: 2.065, I: 0.21\n",
      "Test  Corrects: Top-1: 62.15%, 14.05 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.133, I: 0.933], Loss Comp: [C: 14.817, E: 2.024, I: 0.21], Losses [0: 4.09, 1: 2.32, 2: 3.25, 3: 10.65]Per Epoch: 5m,2s  , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 36.23%, Comp: 0.13, 0.93 5m,13s\n",
      "Train Loss Components: C: 20.231, E: 2.024, I: 0.21\n",
      "Test  Corrects: Top-1: 10.26%, 14.06 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.133, I: 0.933], Loss Comp: [C: 12.522, E: 2.024, I: 0.21], Losses [0: 6.54, 1: 3.15, 2: 2.2, 3: 7.91]Per Epoch: 4m,58s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 38.81%, Comp: 0.13, 0.93 5m,12s\n",
      "Train Loss Components: C: 9.008, E: 2.024, I: 0.21\n",
      "Test  Corrects: Top-1: 11.15%, 14.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.131, I: 1.467], Loss Comp: [C: 7.665, E: 1.979, I: 1.46], Losses [0: 5.02, 1: 2.41, 2: 1.18, 3: 2.5]Per Epoch: 5m,2s  , Alloc: 5.60GiB    \n",
      "Train Corrects: Top-1: 40.53%, Comp: 0.13, 0.93 5m,12s\n",
      "Train Loss Components: C: 16.303, E: 1.979, I: 0.21\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 4,229,136 -> 4,229,136\n",
      "Pre-prune Test  Corrects: Top-1: 21.50%, 14.02 s\n",
      "Post-prune Test  Corrects: Top-1: 21.50%, 14.07 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.131, I: 1.267], Loss Comp: [C: 12.483, E: 1.979, I: 0.84], Losses [0: 5.27, 1: 2.7, 2: 2.4, 3: 7.59]Per Epoch: 5m,7s  , Alloc: 5.60GiB    \n",
      "Train Corrects: Top-1: 44.29%, Comp: 0.13, 0.93 5m,13s\n",
      "Train Loss Components: C: 7.111, E: 1.979, I: 0.21\n",
      "Test  Corrects: Top-1: 19.92%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.131, I: 1.533], Loss Comp: [C: 8.805, E: 1.979, I: 1.67], Losses [0: 2.39, 1: 1.7, 2: 1.57, 3: 4.02]Per Epoch: 5m,5s  , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 48.49%, Comp: 0.13, 1.20 5m,13s\n",
      "Train Loss Components: C: 6.423, E: 1.979, I: 0.63\n",
      "Test  Corrects: Top-1: 31.81%, 14.05 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.131, I: 1.333], Loss Comp: [C: 6.341, E: 1.979, I: 1.05], Losses [0: 1.29, 1: 1.2, 2: 1.02, 3: 2.62]Per Epoch: 4m,55s , Alloc: 5.60GiB   \n",
      "Train Corrects: Top-1: 52.81%, Comp: 0.13, 0.93 5m,14s\n",
      "Train Loss Components: C: 4.878, E: 1.979, I: 0.21\n",
      "Test  Corrects: Top-1: 42.28%, 14.04 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.131, I: 1.133], Loss Comp: [C: 4.305, E: 1.979, I: 0.42], Losses [0: 1.64, 1: 1.21, 2: 1.01, 3: 1.14]Per Epoch: 5m,10s , Alloc: 5.60GiB  \n",
      "Train Corrects: Top-1: 56.40%, Comp: 0.13, 0.93 5m,13s\n",
      "Train Loss Components: C: 8.443, E: 1.979, I: 0.21\n",
      "\n",
      "Deadheaded 4 operations\n",
      "Param Delta: 4,229,136 -> 3,137,548\n",
      "Pre-prune Test  Corrects: Top-1: 57.48%, 14.04 s\n",
      "Post-prune Test  Corrects: Top-1: 57.48%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.095703125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.883482982261874e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.68GiB\n",
      "13: 4.81GiB\n",
      "14: 4.95GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 10.505, Losses [0: 5.55, 1: 2.71, 2: 2.71, 3: 8.31]Per Epoch: 3m,25s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 44.53%, 3m,32s\n",
      "Test  Corrects: Top-1: 13.68%, 13.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 7.271, Losses [0: 4.94, 1: 2.34, 2: 1.86, 3: 5.44]Per Epoch: 3m,28s , Alloc: 5.31GiB    \n",
      "Train Corrects: Top-1: 46.16%, 3m,32s\n",
      "Test  Corrects: Top-1: 30.99%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 5.616, Losses [0: 4.14, 1: 3.23, 2: 1.32, 3: 3.88]Per Epoch: 3m,27s , Alloc: 5.31GiB    \n",
      "Train Corrects: Top-1: 48.47%, 3m,32s\n",
      "Test  Corrects: Top-1: 24.01%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 9.144, Losses [0: 4.19, 1: 1.98, 2: 2.04, 3: 7.5]Per Epoch: 3m,18s , Alloc: 5.31GiB    \n",
      "Train Corrects: Top-1: 50.65%, 3m,32s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,137,548 -> 3,137,548\n",
      "Pre-prune Test  Corrects: Top-1: 14.44%, 13.45 s\n",
      "Post-prune Test  Corrects: Top-1: 14.44%, 13.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 3.232, Losses [0: 2.41, 1: 1.35, 2: 0.91, 3: 2.3]Per Epoch: 3m,22s , Alloc: 5.31GiB    \n",
      "Train Corrects: Top-1: 53.78%, 3m,32s\n",
      "Test  Corrects: Top-1: 40.11%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 3.990, Losses [0: 2.97, 1: 1.93, 2: 1.17, 3: 2.78]Per Epoch: 3m,18s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 57.33%, 3m,31s\n",
      "Test  Corrects: Top-1: 45.15%, 13.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 2.975, Losses [0: 1.77, 1: 1.16, 2: 1.01, 3: 2.19]Per Epoch: 3m,27s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 60.71%, 3m,32s\n",
      "Test  Corrects: Top-1: 57.15%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.980, Losses [0: 1.22, 1: 1.19, 2: 0.91, 3: 1.32]Per Epoch: 3m,26s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 64.34%, 3m,31s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,137,548 -> 3,137,548\n",
      "Pre-prune Test  Corrects: Top-1: 63.22%, 13.49 s\n",
      "Post-prune Test  Corrects: Top-1: 63.22%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.131, I: 1.000], Loss Comp: [C: 3.925, E: 2.065, I: 0.00], Losses [0: 1.58, 1: 0.95, 2: 0.87, 3: 1.18]Per Epoch: 4m,54s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 66.77%, Comp: 0.13, 1.00 5m,0s\n",
      "Train Loss Components: C: 6.291, E: 2.065, I: 0.00\n",
      "Test  Corrects: Top-1: 71.10%, 13.42 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.130, I: 1.600], Loss Comp: [C: 11.051, E: 2.062, I: 1.96], Losses [0: 6.92, 1: 3.68, 2: 1.45, 3: 4.61]Per Epoch: 4m,41s , Alloc: 5.31GiB   \n",
      "Train Corrects: Top-1: 49.90%, Comp: 0.13, 1.60 5m,1s\n",
      "Train Loss Components: C: 11.565, E: 2.062, I: 1.96\n",
      "Test  Corrects: Top-1: 24.26%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.400], Loss Comp: [C: 10.599, E: 2.049, I: 1.31], Losses [0: 7.2, 1: 3.68, 2: 1.85, 3: 4.7]Per Epoch: 4m,38s , Alloc: 5.31GiB    \n",
      "Train Corrects: Top-1: 52.36%, Comp: 0.13, 0.93 5m,0s\n",
      "Train Loss Components: C: 7.550, E: 2.049, I: 0.22\n",
      "Test  Corrects: Top-1: 22.37%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.130, I: 0.933], Loss Comp: [C: 7.016, E: 2.062, I: 0.22], Losses [0: 2.87, 1: 2.26, 2: 1.06, 3: 3.5]Per Epoch: 4m,43s , Alloc: 5.31GiB    \n",
      "Train Corrects: Top-1: 55.72%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 6.875, E: 2.062, I: 0.22\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,137,548 -> 3,137,548\n",
      "Pre-prune Test  Corrects: Top-1: 39.10%, 13.44 s\n",
      "Post-prune Test  Corrects: Top-1: 39.10%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.333], Loss Comp: [C: 7.777, E: 2.041, I: 1.09], Losses [0: 3.09, 1: 1.23, 2: 1.17, 3: 3.55]Per Epoch: 4m,52s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 58.87%, Comp: 0.13, 0.93 5m,0s\n",
      "Train Loss Components: C: 11.559, E: 2.041, I: 0.22\n",
      "Test  Corrects: Top-1: 39.56%, 13.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 6.291, E: 2.041, I: 0.22], Losses [0: 3.7, 1: 1.38, 2: 1.27, 3: 2.76]Per Epoch: 4m,44s , Alloc: 5.31GiB   \n",
      "Train Corrects: Top-1: 61.90%, Comp: 0.13, 0.93 5m,0s\n",
      "Train Loss Components: C: 5.532, E: 2.041, I: 0.22\n",
      "Test  Corrects: Top-1: 29.55%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.600], Loss Comp: [C: 6.428, E: 2.041, I: 1.96], Losses [0: 1.42, 1: 1.26, 2: 0.86, 3: 1.72]Per Epoch: 4m,39s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 64.82%, Comp: 0.13, 1.40 4m,59s\n",
      "Train Loss Components: C: 6.476, E: 2.041, I: 1.31\n",
      "Test  Corrects: Top-1: 54.18%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 3.745, E: 2.041, I: 0.00], Losses [0: 1.38, 1: 0.88, 2: 0.85, 3: 1.08]Per Epoch: 4m,56s , Alloc: 5.31GiB  \n",
      "Train Corrects: Top-1: 68.45%, Comp: 0.13, 1.07 5m,1s\n",
      "Train Loss Components: C: 6.602, E: 2.041, I: 0.22\n",
      "\n",
      "Deadheaded 2 operations\n",
      "Param Delta: 3,137,548 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 63.07%, 13.45 s\n",
      "Post-prune Test  Corrects: Top-1: 63.07%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.087890625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.4126122366964055e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.95GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 5.083, Losses [0: 2.84, 1: 1.82, 2: 1.19, 3: 3.91]Per Epoch: 3m,26s , Alloc: 5.15GiB  \n",
      "Train Corrects: Top-1: 56.34%, 3m,32s\n",
      "Test  Corrects: Top-1: 13.43%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 4.264, Losses [0: 5.01, 1: 2.8, 2: 0.97, 3: 2.51]Per Epoch: 3m,17s , Alloc: 5.29GiB    \n",
      "Train Corrects: Top-1: 57.67%, 3m,32s\n",
      "Test  Corrects: Top-1: 24.77%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 4.445, Losses [0: 4.24, 1: 2.43, 2: 1.15, 3: 2.88]Per Epoch: 3m,14s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 56.46%, 3m,31s\n",
      "Test  Corrects: Top-1: 38.10%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 6.409, Losses [0: 5.33, 1: 2.49, 2: 1.64, 3: 4.52]Per Epoch: 3m,25s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 59.94%, 3m,31s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 30.52%, 13.40 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-prune Test  Corrects: Top-1: 30.52%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 4.921, Losses [0: 3.63, 1: 2.3, 2: 1.16, 3: 3.5]Per Epoch: 3m,22s , Alloc: 5.29GiB   \n",
      "Train Corrects: Top-1: 63.39%, 3m,31s\n",
      "Test  Corrects: Top-1: 27.57%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 4.850, Losses [0: 3.23, 1: 1.45, 2: 1.15, 3: 3.68]Per Epoch: 3m,18s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 66.54%, 3m,31s\n",
      "Test  Corrects: Top-1: 31.37%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 2.370, Losses [0: 1.62, 1: 1.01, 2: 0.85, 3: 1.67]Per Epoch: 3m,20s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 69.65%, 3m,32s\n",
      "Test  Corrects: Top-1: 35.87%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.794, Losses [0: 1.46, 1: 0.99, 2: 0.67, 3: 1.17]Per Epoch: 3m,26s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 72.57%, 3m,31s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 59.91%, 13.42 s\n",
      "Post-prune Test  Corrects: Top-1: 59.91%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 3.414, E: 2.126, I: 0.00], Losses [0: 1.33, 1: 0.66, 2: 0.58, 3: 0.77]Per Epoch: 4m,38s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 74.72%, Comp: 0.13, 1.00 5m,0s\n",
      "Train Loss Components: C: 3.585, E: 2.126, I: 0.00\n",
      "Test  Corrects: Top-1: 76.17%, 13.43 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 6.608, E: 2.106, I: 0.23], Losses [0: 4.31, 1: 1.32, 2: 0.94, 3: 2.96]Per Epoch: 4m,59s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 61.57%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 6.020, E: 2.106, I: 0.23\n",
      "Test  Corrects: Top-1: 21.78%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 9.167, E: 2.126, I: 0.23], Losses [0: 3.6, 1: 1.62, 2: 1.15, 3: 5.54]Per Epoch: 4m,42s , Alloc: 5.29GiB   \n",
      "Train Corrects: Top-1: 62.89%, Comp: 0.13, 1.07 4m,59s\n",
      "Train Loss Components: C: 4.782, E: 2.126, I: 0.23\n",
      "Test  Corrects: Top-1: 27.37%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.333], Loss Comp: [C: 7.894, E: 2.126, I: 1.14], Losses [0: 4.41, 1: 1.75, 2: 1.1, 3: 3.18]Per Epoch: 4m,44s , Alloc: 5.29GiB   \n",
      "Train Corrects: Top-1: 64.46%, Comp: 0.13, 1.07 4m,59s\n",
      "Train Loss Components: C: 5.857, E: 2.126, I: 0.23\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 20.74%, 13.42 s\n",
      "Post-prune Test  Corrects: Top-1: 20.74%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 5.140, E: 2.126, I: 0.00], Losses [0: 2.4, 1: 1.28, 2: 0.69, 3: 2.14]Per Epoch: 4m,52s , Alloc: 5.29GiB   \n",
      "Train Corrects: Top-1: 67.14%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 4.423, E: 2.126, I: 0.23\n",
      "Test  Corrects: Top-1: 29.95%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 4.733, E: 2.126, I: 0.23], Losses [0: 1.79, 1: 0.78, 2: 0.7, 3: 1.73]Per Epoch: 4m,51s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 70.02%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 4.200, E: 2.126, I: 0.23\n",
      "Test  Corrects: Top-1: 33.88%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 3.263, E: 2.126, I: 0.00], Losses [0: 0.82, 1: 0.51, 2: 0.36, 3: 0.8]Per Epoch: 4m,42s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 73.00%, Comp: 0.13, 1.00 5m,0s\n",
      "Train Loss Components: C: 3.828, E: 2.126, I: 0.00\n",
      "Test  Corrects: Top-1: 56.51%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 4.033, E: 2.126, I: 0.00], Losses [0: 1.65, 1: 1.08, 2: 0.84, 3: 1.19]Per Epoch: 4m,53s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 76.03%, Comp: 0.13, 0.93 5m,0s\n",
      "Train Loss Components: C: 4.967, E: 2.126, I: 0.23\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 67.01%, 13.41 s\n",
      "Post-prune Test  Corrects: Top-1: 67.01%, 13.38 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.091796875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.0594591775223041e-05\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.95GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 4.148, Losses [0: 3.3, 1: 1.6, 2: 1.08, 3: 2.95]Per Epoch: 3m,24s , Alloc: 5.15GiB   \n",
      "Train Corrects: Top-1: 64.85%, 3m,31s\n",
      "Test  Corrects: Top-1: 32.95%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 4.916, Losses [0: 3.35, 1: 1.97, 2: 0.89, 3: 3.67]Per Epoch: 3m,13s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 65.35%, 3m,31s\n",
      "Test  Corrects: Top-1: 37.91%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 3.757, Losses [0: 2.36, 1: 1.38, 2: 0.86, 3: 2.84]Per Epoch: 3m,20s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 66.60%, 3m,31s\n",
      "Test  Corrects: Top-1: 34.52%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 5.754, Losses [0: 3.95, 1: 2.29, 2: 1.38, 3: 4.23]Per Epoch: 3m,17s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 68.08%, 3m,32s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 41.79%, 13.41 s\n",
      "Post-prune Test  Corrects: Top-1: 41.79%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 3.336, Losses [0: 2.24, 1: 1.44, 2: 0.68, 3: 2.46]Per Epoch: 3m,16s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 71.00%, 3m,31s\n",
      "Test  Corrects: Top-1: 33.05%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 3.687, Losses [0: 3.1, 1: 2.01, 2: 0.66, 3: 2.53]Per Epoch: 3m,16s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 73.09%, 3m,31s\n",
      "Test  Corrects: Top-1: 33.75%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 2.174, Losses [0: 1.29, 1: 0.98, 2: 0.77, 3: 1.57]Per Epoch: 3m,29s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 76.21%, 3m,32s\n",
      "Test  Corrects: Top-1: 54.87%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.465, Losses [0: 1.05, 1: 0.75, 2: 0.64, 3: 0.98]Per Epoch: 3m,31s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 78.14%, 3m,32s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 75.30%, 13.41 s\n",
      "Post-prune Test  Corrects: Top-1: 75.30%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 3.623, E: 2.211, I: 0.24], Losses [0: 1.3, 1: 0.66, 2: 0.56, 3: 0.67]Per Epoch: 4m,58s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 80.24%, Comp: 0.13, 1.00 4m,58s\n",
      "Train Loss Components: C: 3.881, E: 2.211, I: 0.00\n",
      "Test  Corrects: Top-1: 80.97%, 13.42 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.333], Loss Comp: [C: 9.334, E: 2.199, I: 1.18], Losses [0: 3.45, 1: 1.63, 2: 1.02, 3: 4.73]Per Epoch: 4m,50s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 67.93%, Comp: 0.13, 1.40 4m,59s\n",
      "Train Loss Components: C: 7.179, E: 2.199, I: 1.42\n",
      "Test  Corrects: Top-1: 17.89%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.133], Loss Comp: [C: 6.821, E: 2.211, I: 0.47], Losses [0: 2.93, 1: 1.04, 2: 0.61, 3: 3.22]Per Epoch: 4m,55s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 68.05%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 10.482, E: 2.211, I: 0.24\n",
      "Test  Corrects: Top-1: 23.08%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 5.886, E: 2.190, I: 0.24], Losses [0: 2.14, 1: 1.39, 2: 0.64, 3: 2.62]Per Epoch: 4m,52s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 69.63%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 7.455, E: 2.190, I: 0.24\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 43.19%, 13.41 s\n",
      "Post-prune Test  Corrects: Top-1: 43.19%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.133], Loss Comp: [C: 6.816, E: 2.211, I: 0.47], Losses [0: 3.08, 1: 1.06, 2: 0.84, 3: 3.14]Per Epoch: 4m,42s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 72.75%, Comp: 0.13, 1.40 4m,59s\n",
      "Train Loss Components: C: 4.847, E: 2.211, I: 1.42\n",
      "Test  Corrects: Top-1: 43.89%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 4.146, E: 2.211, I: 0.00], Losses [0: 2.33, 1: 0.83, 2: 0.53, 3: 1.2]Per Epoch: 4m,33s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 75.04%, Comp: 0.13, 1.00 4m,59s\n",
      "Train Loss Components: C: 4.331, E: 2.211, I: 0.00\n",
      "Test  Corrects: Top-1: 49.90%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 3.909, E: 2.211, I: 0.24], Losses [0: 1.53, 1: 0.83, 2: 0.55, 3: 0.88]Per Epoch: 5m,4s  , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 77.43%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 3.487, E: 2.211, I: 0.24\n",
      "Test  Corrects: Top-1: 64.05%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 2.937, E: 2.211, I: 0.00], Losses [0: 0.85, 1: 0.43, 2: 0.29, 3: 0.41]Per Epoch: 5m,5s  , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 79.95%, Comp: 0.13, 1.00 5m,0s\n",
      "Train Loss Components: C: 3.116, E: 2.211, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 76.30%, 13.42 s\n",
      "Post-prune Test  Corrects: Top-1: 76.30%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.095703125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 7.94594383141728e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.95GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 3.349, Losses [0: 2.63, 1: 1.15, 2: 0.67, 3: 2.46]Per Epoch: 3m,17s , Alloc: 5.15GiB  \n",
      "Train Corrects: Top-1: 69.70%, 3m,31s\n",
      "Test  Corrects: Top-1: 28.22%, 13.46 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.990, Losses [0: 2.33, 1: 0.99, 2: 0.62, 3: 2.2]Per Epoch: 3m,26s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 69.69%, 3m,31s\n",
      "Test  Corrects: Top-1: 20.68%, 13.38 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 3.433, Losses [0: 3.71, 1: 1.27, 2: 0.75, 3: 2.29]Per Epoch: 3m,16s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 70.65%, 3m,32s\n",
      "Test  Corrects: Top-1: 32.85%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.561, Losses [0: 1.62, 1: 0.91, 2: 0.48, 3: 0.96]Per Epoch: 3m,21s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 72.02%, 3m,31s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 35.29%, 13.40 s\n",
      "Post-prune Test  Corrects: Top-1: 35.29%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.459, Losses [0: 1.53, 1: 0.81, 2: 0.57, 3: 1.88]Per Epoch: 3m,22s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 74.46%, 3m,31s\n",
      "Test  Corrects: Top-1: 35.95%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.991, Losses [0: 1.79, 1: 0.8, 2: 0.66, 3: 1.34]Per Epoch: 3m,18s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 75.85%, 3m,31s\n",
      "Test  Corrects: Top-1: 59.36%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.317, Losses [0: 1.09, 1: 0.75, 2: 0.49, 3: 0.85]Per Epoch: 3m,25s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 79.56%, 3m,31s\n",
      "Test  Corrects: Top-1: 60.66%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.995, Losses [0: 1.1, 1: 0.57, 2: 0.44, 3: 0.57]Per Epoch: 3m,26s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 81.51%, 3m,32s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 74.43%, 13.43 s\n",
      "Post-prune Test  Corrects: Top-1: 74.43%, 13.45 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 3.508, E: 2.296, I: 0.00], Losses [0: 1.59, 1: 0.74, 2: 0.54, 3: 0.64]Per Epoch: 5m,0s  , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 82.58%, Comp: 0.13, 1.00 4m,59s\n",
      "Train Loss Components: C: 3.440, E: 2.296, I: 0.00\n",
      "Test  Corrects: Top-1: 83.29%, 13.44 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 6.471, E: 2.296, I: 0.25], Losses [0: 2.89, 1: 1.5, 2: 0.98, 3: 2.85]Per Epoch: 4m,59s , Alloc: 5.29GiB   \n",
      "Train Corrects: Top-1: 69.32%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 5.489, E: 2.296, I: 0.25\n",
      "Test  Corrects: Top-1: 18.09%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.333], Loss Comp: [C: 11.488, E: 2.296, I: 1.23], Losses [0: 3.41, 1: 1.46, 2: 1.62, 3: 6.67]Per Epoch: 5m,5s  , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 69.80%, Comp: 0.13, 1.60 4m,59s\n",
      "Train Loss Components: C: 10.082, E: 2.296, I: 2.21\n",
      "Test  Corrects: Top-1: 34.42%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 4.412, E: 2.296, I: 0.25], Losses [0: 2.69, 1: 1.1, 2: 0.55, 3: 1.0]Per Epoch: 4m,52s , Alloc: 5.29GiB   \n",
      "Train Corrects: Top-1: 72.65%, Comp: 0.13, 0.93 5m,0s\n",
      "Train Loss Components: C: 6.505, E: 2.296, I: 0.25\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 49.49%, 13.38 s\n",
      "Post-prune Test  Corrects: Top-1: 49.49%, 13.38 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 4.818, E: 2.296, I: 0.25], Losses [0: 2.59, 1: 1.15, 2: 0.63, 3: 1.4]Per Epoch: 4m,49s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 75.67%, Comp: 0.13, 1.00 5m,0s\n",
      "Train Loss Components: C: 5.357, E: 2.296, I: 0.00\n",
      "Test  Corrects: Top-1: 43.82%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 3.685, E: 2.296, I: 0.25], Losses [0: 1.1, 1: 0.76, 2: 0.44, 3: 0.68]Per Epoch: 4m,40s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 78.03%, Comp: 0.13, 1.00 5m,0s\n",
      "Train Loss Components: C: 6.227, E: 2.296, I: 0.00\n",
      "Test  Corrects: Top-1: 64.36%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 4.386, E: 2.296, I: 0.25], Losses [0: 1.63, 1: 1.0, 2: 0.64, 3: 1.19]Per Epoch: 4m,52s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 80.60%, Comp: 0.13, 1.00 4m,59s\n",
      "Train Loss Components: C: 2.704, E: 2.296, I: 0.00\n",
      "Test  Corrects: Top-1: 72.10%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 3.529, E: 2.296, I: 0.25], Losses [0: 1.17, 1: 0.7, 2: 0.45, 3: 0.52]Per Epoch: 4m,57s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 82.54%, Comp: 0.13, 1.00 4m,59s\n",
      "Train Loss Components: C: 3.348, E: 2.296, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 80.45%, 13.40 s\n",
      "Post-prune Test  Corrects: Top-1: 80.45%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.099609375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 5.95945787356296e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.95GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.945, Losses [0: 3.03, 1: 0.97, 2: 0.63, 3: 2.02]Per Epoch: 3m,15s , Alloc: 5.15GiB  \n",
      "Train Corrects: Top-1: 69.35%, 3m,31s\n",
      "Test  Corrects: Top-1: 25.54%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 4.581, Losses [0: 3.87, 1: 1.77, 2: 1.09, 3: 3.23]Per Epoch: 3m,16s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 70.26%, 3m,32s\n",
      "Test  Corrects: Top-1: 15.30%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.408, Losses [0: 3.13, 1: 0.79, 2: 0.55, 3: 1.51]Per Epoch: 3m,17s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 72.02%, 3m,31s\n",
      "Test  Corrects: Top-1: 30.30%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 4.176, Losses [0: 5.14, 1: 2.26, 2: 0.93, 3: 2.51]Per Epoch: 3m,24s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 73.72%, 3m,32s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 27.04%, 13.40 s\n",
      "Post-prune Test  Corrects: Top-1: 27.04%, 13.39 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.041, Losses [0: 1.31, 1: 0.8, 2: 0.3, 3: 0.56]Per Epoch: 3m,18s , Alloc: 5.29GiB   \n",
      "Train Corrects: Top-1: 76.46%, 3m,32s\n",
      "Test  Corrects: Top-1: 26.65%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.990, Losses [0: 1.06, 1: 0.6, 2: 0.34, 3: 0.59]Per Epoch: 3m,25s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 79.13%, 3m,32s\n",
      "Test  Corrects: Top-1: 41.35%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.289, Losses [0: 1.56, 1: 0.84, 2: 0.48, 3: 0.71]Per Epoch: 3m,26s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 81.32%, 3m,31s\n",
      "Test  Corrects: Top-1: 63.46%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.131, Losses [0: 1.58, 1: 0.87, 2: 0.49, 3: 0.54]Per Epoch: 3m,28s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 83.51%, 3m,33s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 74.98%, 13.41 s\n",
      "Post-prune Test  Corrects: Top-1: 74.98%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 3.668, E: 2.359, I: 0.25], Losses [0: 0.87, 1: 0.66, 2: 0.52, 3: 0.65]Per Epoch: 4m,42s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 84.12%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 4.823, E: 2.359, I: 0.25\n",
      "Test  Corrects: Top-1: 82.14%, 13.39 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.200], Loss Comp: [C: 6.397, E: 2.381, I: 0.76], Losses [0: 2.79, 1: 1.8, 2: 0.8, 3: 2.18]Per Epoch: 4m,41s , Alloc: 5.29GiB    \n",
      "Train Corrects: Top-1: 73.06%, Comp: 0.13, 1.13 5m,0s\n",
      "Train Loss Components: C: 7.978, E: 2.381, I: 0.51\n",
      "Test  Corrects: Top-1: 33.74%, 13.47 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 5.408, E: 2.359, I: 0.25], Losses [0: 2.73, 1: 1.42, 2: 0.7, 3: 1.82]Per Epoch: 4m,50s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 72.17%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 9.457, E: 2.359, I: 0.25\n",
      "Test  Corrects: Top-1: 30.68%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.133], Loss Comp: [C: 8.727, E: 2.351, I: 0.51], Losses [0: 2.82, 1: 1.29, 2: 1.42, 3: 4.76]Per Epoch: 4m,53s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 75.12%, Comp: 0.13, 1.13 5m,0s\n",
      "Train Loss Components: C: 5.152, E: 2.329, I: 0.51\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 39.98%, 13.41 s\n",
      "Post-prune Test  Corrects: Top-1: 39.98%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 4.312, E: 2.381, I: 0.25], Losses [0: 2.68, 1: 0.98, 2: 0.55, 3: 0.83]Per Epoch: 4m,59s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 76.89%, Comp: 0.13, 1.27 5m,1s\n",
      "Train Loss Components: C: 7.675, E: 2.381, I: 1.02\n",
      "Test  Corrects: Top-1: 53.20%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 4.010, E: 2.381, I: 0.00], Losses [0: 2.07, 1: 1.07, 2: 0.53, 3: 0.89]Per Epoch: 4m,55s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 79.21%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 4.165, E: 2.381, I: 0.25\n",
      "Test  Corrects: Top-1: 57.38%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 0.933], Loss Comp: [C: 3.562, E: 2.381, I: 0.25], Losses [0: 1.48, 1: 0.75, 2: 0.38, 3: 0.41]Per Epoch: 4m,54s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 82.42%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 5.740, E: 2.381, I: 0.25\n",
      "Test  Corrects: Top-1: 74.84%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 3.437, E: 2.381, I: 0.00], Losses [0: 1.37, 1: 0.75, 2: 0.51, 3: 0.53]Per Epoch: 4m,50s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 83.91%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 3.846, E: 2.381, I: 0.25\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 81.73%, 13.45 s\n",
      "Post-prune Test  Corrects: Top-1: 81.73%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.095703125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 4.4695934051722205e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.95GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.262, Losses [0: 2.29, 1: 0.97, 2: 0.62, 3: 1.49]Per Epoch: 3m,16s , Alloc: 5.15GiB  \n",
      "Train Corrects: Top-1: 74.18%, 3m,31s\n",
      "Test  Corrects: Top-1: 53.54%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 3.280, Losses [0: 3.51, 1: 1.73, 2: 0.75, 3: 2.08]Per Epoch: 3m,27s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 72.93%, 3m,32s\n",
      "Test  Corrects: Top-1: 38.33%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.281, Losses [0: 2.2, 1: 1.3, 2: 0.49, 3: 1.48]Per Epoch: 3m,18s , Alloc: 5.29GiB    \n",
      "Train Corrects: Top-1: 71.46%, 3m,32s\n",
      "Test  Corrects: Top-1: 55.76%, 13.43 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.689, Losses [0: 3.12, 1: 1.18, 2: 0.66, 3: 1.7]Per Epoch: 3m,23s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 74.86%, 3m,31s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 53.29%, 13.42 s\n",
      "Post-prune Test  Corrects: Top-1: 53.29%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.440, Losses [0: 1.33, 1: 0.61, 2: 0.42, 3: 0.97]Per Epoch: 3m,23s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 77.24%, 3m,32s\n",
      "Test  Corrects: Top-1: 56.98%, 13.44 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.488, Losses [0: 1.87, 1: 0.76, 2: 0.5, 3: 0.86]Per Epoch: 3m,27s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 80.13%, 3m,31s\n",
      "Test  Corrects: Top-1: 68.02%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.322, Losses [0: 1.4, 1: 0.7, 2: 0.49, 3: 0.8]Per Epoch: 3m,28s , Alloc: 5.29GiB    \n",
      "Train Corrects: Top-1: 82.53%, 3m,30s\n",
      "Test  Corrects: Top-1: 73.63%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.844, Losses [0: 1.26, 1: 0.58, 2: 0.34, 3: 0.41]Per Epoch: 3m,17s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 84.31%, 3m,32s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 83.05%, 13.42 s\n",
      "Post-prune Test  Corrects: Top-1: 83.05%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.129, I: 1.000], Loss Comp: [C: 3.095, E: 2.466, I: 0.00], Losses [0: 0.67, 1: 0.49, 2: 0.33, 3: 0.33]Per Epoch: 4m,54s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 85.44%, Comp: 0.13, 1.00 5m,0s\n",
      "Train Loss Components: C: 2.841, E: 2.443, I: 0.00\n",
      "Test  Corrects: Top-1: 85.18%, 13.39 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 4.315, E: 2.442, I: 0.26], Losses [0: 2.68, 1: 0.95, 2: 0.41, 3: 0.8]Per Epoch: 4m,37s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 75.22%, Comp: 0.13, 0.93 5m,0s\n",
      "Train Loss Components: C: 4.844, E: 2.442, I: 0.26\n",
      "Test  Corrects: Top-1: 64.26%, 13.42 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 4.539, E: 2.453, I: 0.26], Losses [0: 2.22, 1: 0.95, 2: 0.39, 3: 1.11]Per Epoch: 4m,37s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 75.61%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 5.995, E: 2.453, I: 0.26\n",
      "Test  Corrects: Top-1: 50.91%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 6.876, E: 2.453, I: 2.37], Losses [0: 2.5, 1: 1.06, 2: 0.53, 3: 1.23]Per Epoch: 4m,54s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 76.37%, Comp: 0.13, 1.27 4m,59s\n",
      "Train Loss Components: C: 5.900, E: 2.453, I: 1.05\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 3,136,010 -> 3,136,010\n",
      "Pre-prune Test  Corrects: Top-1: 67.62%, 13.40 s\n",
      "Post-prune Test  Corrects: Top-1: 67.62%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 6.153, E: 2.453, I: 2.37], Losses [0: 1.8, 1: 0.67, 2: 0.39, 3: 0.76]Per Epoch: 4m,49s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 78.58%, Comp: 0.13, 1.27 4m,59s\n",
      "Train Loss Components: C: 4.442, E: 2.453, I: 1.05\n",
      "Test  Corrects: Top-1: 70.95%, 13.41 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 5.894, E: 2.453, I: 2.37], Losses [0: 1.43, 1: 0.7, 2: 0.45, 3: 0.55]Per Epoch: 4m,54s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 81.59%, Comp: 0.13, 1.60 5m,0s\n",
      "Train Loss Components: C: 6.439, E: 2.453, I: 2.37\n",
      "Test  Corrects: Top-1: 79.52%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.267], Loss Comp: [C: 4.370, E: 2.453, I: 1.05], Losses [0: 1.16, 1: 0.45, 2: 0.37, 3: 0.47]Per Epoch: 4m,51s , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 83.81%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 3.175, E: 2.453, I: 0.26\n",
      "Test  Corrects: Top-1: 81.65%, 13.40 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 3.980, E: 2.453, I: 0.26], Losses [0: 1.56, 1: 0.86, 2: 0.57, 3: 0.67]Per Epoch: 5m,7s  , Alloc: 5.29GiB  \n",
      "Train Corrects: Top-1: 85.39%, Comp: 0.13, 1.20 4m,59s\n",
      "Train Loss Components: C: 4.562, E: 2.453, I: 0.79\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 3,136,010 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 84.69%, 13.38 s\n",
      "Post-prune Test  Corrects: Top-1: 84.69%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.060546875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 3.3521950538791656e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.972, Losses [0: 1.46, 1: 0.78, 2: 0.64, 3: 1.4]Per Epoch: 3m,15s , Alloc: 5.13GiB   \n",
      "Train Corrects: Top-1: 77.40%, 3m,30s\n",
      "Test  Corrects: Top-1: 66.99%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.742, Losses [0: 2.62, 1: 0.85, 2: 0.44, 3: 0.96]Per Epoch: 3m,17s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 76.67%, 3m,30s\n",
      "Test  Corrects: Top-1: 63.08%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.959, Losses [0: 2.14, 1: 0.81, 2: 0.52, 3: 1.26]Per Epoch: 3m,21s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 77.28%, 3m,29s\n",
      "Test  Corrects: Top-1: 65.25%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.831, Losses [0: 2.39, 1: 1.22, 2: 0.44, 3: 1.02]Per Epoch: 3m,26s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 78.63%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 65.62%, 13.36 s\n",
      "Post-prune Test  Corrects: Top-1: 65.62%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.181, Losses [0: 1.59, 1: 0.33, 2: 0.35, 3: 0.73]Per Epoch: 3m,14s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 80.66%, 3m,30s\n",
      "Test  Corrects: Top-1: 74.51%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.648, Losses [0: 1.33, 1: 0.4, 2: 0.27, 3: 0.25]Per Epoch: 3m,16s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 82.79%, 3m,29s\n",
      "Test  Corrects: Top-1: 78.59%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.803, Losses [0: 1.22, 1: 0.48, 2: 0.31, 3: 0.4]Per Epoch: 3m,14s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 84.90%, 3m,30s\n",
      "Test  Corrects: Top-1: 82.93%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.594, Losses [0: 0.8, 1: 0.38, 2: 0.33, 3: 0.29]Per Epoch: 3m,25s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 86.79%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 86.33%, 13.35 s\n",
      "Post-prune Test  Corrects: Top-1: 86.33%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.000], Loss Comp: [C: 2.842, E: 2.537, I: 0.00], Losses [0: 0.46, 1: 0.2, 2: 0.19, 3: 0.13]Per Epoch: 4m,37s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.07%, Comp: 0.13, 1.00 4m,56s\n",
      "Train Loss Components: C: 3.431, E: 2.537, I: 0.00\n",
      "Test  Corrects: Top-1: 87.38%, 13.30 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 4.706, E: 2.513, I: 0.27], Losses [0: 2.31, 1: 1.46, 2: 0.6, 3: 1.05]Per Epoch: 4m,50s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 78.97%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 3.370, E: 2.481, I: 0.27\n",
      "Test  Corrects: Top-1: 70.85%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.400], Loss Comp: [C: 7.181, E: 2.521, I: 1.64], Losses [0: 2.64, 1: 0.93, 2: 0.46, 3: 2.22]Per Epoch: 4m,37s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 77.98%, Comp: 0.13, 1.40 4m,59s\n",
      "Train Loss Components: C: 6.131, E: 2.521, I: 1.64\n",
      "Test  Corrects: Top-1: 73.56%, 13.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 5.328, E: 2.537, I: 0.27], Losses [0: 3.42, 1: 1.34, 2: 0.73, 3: 1.42]Per Epoch: 4m,56s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 77.75%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 6.521, E: 2.537, I: 0.27\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 70.58%, 13.33 s\n",
      "Post-prune Test  Corrects: Top-1: 70.58%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.400], Loss Comp: [C: 5.657, E: 2.508, I: 1.64], Losses [0: 1.59, 1: 0.63, 2: 0.33, 3: 1.0]Per Epoch: 4m,42s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 80.23%, Comp: 0.13, 1.40 4m,58s\n",
      "Train Loss Components: C: 8.364, E: 2.508, I: 1.64\n",
      "Test  Corrects: Top-1: 74.24%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 4.276, E: 2.537, I: 0.27], Losses [0: 1.98, 1: 0.91, 2: 0.55, 3: 0.78]Per Epoch: 4m,52s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 83.00%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 4.336, E: 2.537, I: 0.27\n",
      "Test  Corrects: Top-1: 78.39%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.200], Loss Comp: [C: 4.824, E: 2.537, I: 0.82], Losses [0: 1.99, 1: 0.89, 2: 0.58, 3: 0.78]Per Epoch: 4m,56s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 85.52%, Comp: 0.13, 1.20 4m,58s\n",
      "Train Loss Components: C: 4.392, E: 2.537, I: 0.82\n",
      "Test  Corrects: Top-1: 85.50%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.000], Loss Comp: [C: 3.215, E: 2.537, I: 0.00], Losses [0: 0.85, 1: 0.43, 2: 0.31, 3: 0.36]Per Epoch: 4m,40s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 86.88%, Comp: 0.13, 1.00 4m,59s\n",
      "Train Loss Components: C: 3.462, E: 2.537, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 86.55%, 13.35 s\n",
      "Post-prune Test  Corrects: Top-1: 86.55%, 13.38 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.056640625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 2.514146290409374e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.579, Losses [0: 2.17, 1: 1.19, 2: 0.43, 3: 0.82]Per Epoch: 3m,28s , Alloc: 5.13GiB  \n",
      "Train Corrects: Top-1: 77.61%, 3m,29s\n",
      "Test  Corrects: Top-1: 70.38%, 13.39 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.668, Losses [0: 2.44, 1: 0.67, 2: 0.44, 3: 0.96]Per Epoch: 3m,25s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 75.29%, 3m,30s\n",
      "Test  Corrects: Top-1: 79.32%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 0.993, Losses [0: 2.38, 1: 0.95, 2: 0.29, 3: 0.27]Per Epoch: 3m,14s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 77.77%, 3m,29s\n",
      "Test  Corrects: Top-1: 74.02%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.852, Losses [0: 2.73, 1: 0.88, 2: 0.51, 3: 1.03]Per Epoch: 3m,16s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 79.98%, 3m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 76.06%, 13.33 s\n",
      "Post-prune Test  Corrects: Top-1: 76.06%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.376, Losses [0: 2.33, 1: 0.8, 2: 0.43, 3: 0.66]Per Epoch: 3m,15s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 81.69%, 3m,29s\n",
      "Test  Corrects: Top-1: 72.67%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.670, Losses [0: 0.57, 1: 0.44, 2: 0.24, 3: 0.42]Per Epoch: 3m,25s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 84.41%, 3m,30s\n",
      "Test  Corrects: Top-1: 83.04%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.783, Losses [0: 1.52, 1: 0.69, 2: 0.33, 3: 0.27]Per Epoch: 3m,11s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 86.28%, 3m,29s\n",
      "Test  Corrects: Top-1: 85.09%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.529, Losses [0: 0.95, 1: 0.32, 2: 0.25, 3: 0.22]Per Epoch: 3m,15s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.87%, 3m,31s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 87.93%, 13.32 s\n",
      "Post-prune Test  Corrects: Top-1: 87.93%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.000], Loss Comp: [C: 3.260, E: 2.622, I: 0.00], Losses [0: 0.72, 1: 0.45, 2: 0.35, 3: 0.33]Per Epoch: 4m,42s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 88.31%, Comp: 0.13, 1.07 4m,57s\n",
      "Train Loss Components: C: 3.836, E: 2.622, I: 0.28\n",
      "Test  Corrects: Top-1: 88.28%, 13.29 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.400], Loss Comp: [C: 6.073, E: 2.622, I: 1.69], Losses [0: 2.37, 1: 1.03, 2: 0.55, 3: 0.97]Per Epoch: 4m,58s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 78.80%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 5.489, E: 2.622, I: 0.28\n",
      "Test  Corrects: Top-1: 73.03%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 5.075, E: 2.622, I: 0.28], Losses [0: 4.15, 1: 1.77, 2: 0.6, 3: 0.87]Per Epoch: 4m,47s , Alloc: 5.26GiB    \n",
      "Train Corrects: Top-1: 75.38%, Comp: 0.13, 1.40 4m,58s\n",
      "Train Loss Components: C: 8.606, E: 2.622, I: 1.69\n",
      "Test  Corrects: Top-1: 62.10%, 13.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.400], Loss Comp: [C: 6.192, E: 2.622, I: 1.69], Losses [0: 2.96, 1: 1.33, 2: 0.57, 3: 0.91]Per Epoch: 4m,47s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 79.78%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 4.008, E: 2.622, I: 0.28\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 77.16%, 13.29 s\n",
      "Post-prune Test  Corrects: Top-1: 77.16%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 4.375, E: 2.622, I: 0.28], Losses [0: 2.34, 1: 0.95, 2: 0.58, 3: 0.7]Per Epoch: 4m,48s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 81.53%, Comp: 0.13, 1.40 4m,58s\n",
      "Train Loss Components: C: 8.515, E: 2.622, I: 1.69\n",
      "Test  Corrects: Top-1: 77.70%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.400], Loss Comp: [C: 5.243, E: 2.622, I: 1.69], Losses [0: 1.08, 1: 0.53, 2: 0.4, 3: 0.53]Per Epoch: 4m,53s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 83.61%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 3.274, E: 2.622, I: 0.28\n",
      "Test  Corrects: Top-1: 83.05%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 0.933], Loss Comp: [C: 4.337, E: 2.566, I: 0.28], Losses [0: 2.34, 1: 0.87, 2: 0.51, 3: 0.75]Per Epoch: 4m,44s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 85.71%, Comp: 0.13, 1.13 4m,57s\n",
      "Train Loss Components: C: 5.078, E: 2.566, I: 0.56\n",
      "Test  Corrects: Top-1: 82.32%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.133], Loss Comp: [C: 3.814, E: 2.622, I: 0.56], Losses [0: 1.02, 1: 0.36, 2: 0.31, 3: 0.29]Per Epoch: 4m,36s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.48%, Comp: 0.13, 1.13 4m,58s\n",
      "Train Loss Components: C: 4.114, E: 2.622, I: 0.56\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 87.48%, 13.32 s\n",
      "Post-prune Test  Corrects: Top-1: 87.48%, 13.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.056640625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.8856097178070307e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 7.433, Losses [0: 6.82, 1: 2.92, 2: 2.07, 3: 5.07]Per Epoch: 3m,14s , Alloc: 5.13GiB  \n",
      "Train Corrects: Top-1: 74.86%, 3m,29s\n",
      "Test  Corrects: Top-1: 48.82%, 13.39 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.281, Losses [0: 2.24, 1: 0.58, 2: 0.45, 3: 1.63]Per Epoch: 3m,16s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 69.88%, 3m,29s\n",
      "Test  Corrects: Top-1: 67.06%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.271, Losses [0: 3.25, 1: 1.19, 2: 0.6, 3: 1.26]Per Epoch: 3m,25s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 75.54%, 3m,29s\n",
      "Test  Corrects: Top-1: 47.71%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.914, Losses [0: 4.7, 1: 1.68, 2: 0.66, 3: 1.51]Per Epoch: 3m,23s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 76.98%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 64.02%, 13.37 s\n",
      "Post-prune Test  Corrects: Top-1: 64.02%, 13.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.708, Losses [0: 2.69, 1: 1.07, 2: 0.55, 3: 0.85]Per Epoch: 3m,16s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 79.83%, 3m,29s\n",
      "Test  Corrects: Top-1: 74.05%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.103, Losses [0: 1.46, 1: 0.91, 2: 0.44, 3: 0.54]Per Epoch: 3m,22s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 83.62%, 3m,31s\n",
      "Test  Corrects: Top-1: 79.21%, 13.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.418, Losses [0: 2.04, 1: 0.85, 2: 0.54, 3: 0.73]Per Epoch: 3m,25s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 85.82%, 3m,30s\n",
      "Test  Corrects: Top-1: 84.45%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.864, Losses [0: 1.13, 1: 0.6, 2: 0.37, 3: 0.44]Per Epoch: 3m,9s  , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 86.85%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 86.56%, 13.34 s\n",
      "Post-prune Test  Corrects: Top-1: 86.56%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.000], Loss Comp: [C: 3.357, E: 2.681, I: 0.00], Losses [0: 0.76, 1: 0.55, 2: 0.34, 3: 0.35]Per Epoch: 4m,55s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.50%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 3.846, E: 2.675, I: 0.29\n",
      "Test  Corrects: Top-1: 86.38%, 13.30 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 5.392, E: 2.706, I: 0.29], Losses [0: 3.35, 1: 1.36, 2: 0.66, 3: 1.32]Per Epoch: 4m,50s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 77.80%, Comp: 0.13, 1.07 4m,59s\n",
      "Train Loss Components: C: 6.560, E: 2.706, I: 0.29\n",
      "Test  Corrects: Top-1: 62.78%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 5.050, E: 2.706, I: 0.29], Losses [0: 3.53, 1: 1.25, 2: 0.63, 3: 0.97]Per Epoch: 4m,54s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 75.69%, Comp: 0.13, 1.07 4m,58s\n",
      "Train Loss Components: C: 5.105, E: 2.706, I: 0.29\n",
      "Test  Corrects: Top-1: 71.49%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 8.078, E: 2.706, I: 2.62], Losses [0: 3.07, 1: 0.96, 2: 0.69, 3: 1.81]Per Epoch: 4m,35s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 74.30%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 8.997, E: 2.706, I: 0.29\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 62.88%, 13.34 s\n",
      "Post-prune Test  Corrects: Top-1: 62.88%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.067], Loss Comp: [C: 4.096, E: 2.706, I: 0.29], Losses [0: 1.62, 1: 0.59, 2: 0.39, 3: 0.58]Per Epoch: 4m,39s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 79.21%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 4.666, E: 2.706, I: 0.29\n",
      "Test  Corrects: Top-1: 73.43%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 3.890, E: 2.689, I: 0.29], Losses [0: 1.46, 1: 0.58, 2: 0.25, 3: 0.45]Per Epoch: 5m,1s  , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 82.94%, Comp: 0.13, 1.60 4m,58s\n",
      "Train Loss Components: C: 6.225, E: 2.689, I: 2.62\n",
      "Test  Corrects: Top-1: 79.91%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 1.400], Loss Comp: [C: 5.880, E: 2.649, I: 1.75], Losses [0: 2.09, 1: 1.28, 2: 0.63, 3: 0.68]Per Epoch: 4m,37s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 85.28%, Comp: 0.13, 1.40 4m,57s\n",
      "Train Loss Components: C: 5.150, E: 2.649, I: 1.75\n",
      "Test  Corrects: Top-1: 81.96%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 3.473, E: 2.706, I: 0.29], Losses [0: 0.64, 1: 0.27, 2: 0.25, 3: 0.25]Per Epoch: 4m,44s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 86.96%, Comp: 0.13, 0.93 4m,59s\n",
      "Train Loss Components: C: 3.646, E: 2.706, I: 0.29\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 87.31%, 13.36 s\n",
      "Post-prune Test  Corrects: Top-1: 87.31%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.064453125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.414207288355273e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 4.573, Losses [0: 4.52, 1: 1.47, 2: 0.99, 3: 3.17]Per Epoch: 3m,16s , Alloc: 5.13GiB  \n",
      "Train Corrects: Top-1: 78.98%, 3m,30s\n",
      "Test  Corrects: Top-1: 55.89%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 3.365, Losses [0: 3.28, 1: 1.35, 2: 0.77, 3: 2.28]Per Epoch: 3m,22s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 73.29%, 3m,29s\n",
      "Test  Corrects: Top-1: 53.99%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.677, Losses [0: 3.16, 1: 1.41, 2: 0.68, 3: 1.63]Per Epoch: 3m,17s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 76.73%, 3m,30s\n",
      "Test  Corrects: Top-1: 74.87%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.033, Losses [0: 2.41, 1: 1.17, 2: 0.58, 3: 1.2]Per Epoch: 3m,16s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 76.05%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 78.53%, 13.33 s\n",
      "Post-prune Test  Corrects: Top-1: 78.53%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.377, Losses [0: 2.87, 1: 1.0, 2: 0.43, 3: 0.52]Per Epoch: 3m,21s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 80.14%, 3m,30s\n",
      "Test  Corrects: Top-1: 81.97%, 13.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.145, Losses [0: 2.69, 1: 0.77, 2: 0.29, 3: 0.39]Per Epoch: 3m,25s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 83.73%, 3m,29s\n",
      "Test  Corrects: Top-1: 85.68%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.543, Losses [0: 1.18, 1: 0.51, 2: 0.18, 3: 0.17]Per Epoch: 3m,30s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 86.03%, 3m,30s\n",
      "Test  Corrects: Top-1: 86.74%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.273, Losses [0: 1.44, 1: 0.74, 2: 0.51, 3: 0.73]Per Epoch: 3m,17s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.23%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 88.13%, 13.32 s\n",
      "Post-prune Test  Corrects: Top-1: 88.13%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.000], Loss Comp: [C: 4.113, E: 2.759, I: 0.00], Losses [0: 1.04, 1: 0.48, 2: 0.47, 3: 0.96]Per Epoch: 4m,50s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.92%, Comp: 0.13, 1.00 4m,57s\n",
      "Train Loss Components: C: 3.665, E: 2.791, I: 0.00\n",
      "Test  Corrects: Top-1: 88.51%, 13.31 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 10.696, E: 2.791, I: 2.70], Losses [0: 2.68, 1: 0.99, 2: 1.25, 3: 4.22]Per Epoch: 5m,3s  , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 76.33%, Comp: 0.13, 1.60 4m,59s\n",
      "Train Loss Components: C: 7.660, E: 2.791, I: 2.70\n",
      "Test  Corrects: Top-1: 82.09%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 4.575, E: 2.764, I: 0.30], Losses [0: 1.84, 1: 0.97, 2: 0.41, 3: 0.87]Per Epoch: 4m,39s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 73.14%, Comp: 0.13, 1.60 4m,57s\n",
      "Train Loss Components: C: 11.097, E: 2.764, I: 2.70\n",
      "Test  Corrects: Top-1: 70.50%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 4.942, E: 2.791, I: 0.30], Losses [0: 3.77, 1: 0.89, 2: 0.52, 3: 0.81]Per Epoch: 4m,49s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 73.77%, Comp: 0.13, 0.93 4m,56s\n",
      "Train Loss Components: C: 5.159, E: 2.791, I: 0.30\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 78.27%, 13.32 s\n",
      "Post-prune Test  Corrects: Top-1: 78.27%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.400], Loss Comp: [C: 10.126, E: 2.764, I: 1.80], Losses [0: 2.38, 1: 1.27, 2: 2.37, 3: 4.36]Per Epoch: 4m,38s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 79.11%, Comp: 0.13, 0.93 4m,56s\n",
      "Train Loss Components: C: 6.571, E: 2.764, I: 0.30\n",
      "Test  Corrects: Top-1: 79.67%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 3.858, E: 2.764, I: 0.30], Losses [0: 1.22, 1: 0.46, 2: 0.31, 3: 0.4]Per Epoch: 4m,59s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 81.92%, Comp: 0.13, 1.40 4m,58s\n",
      "Train Loss Components: C: 6.968, E: 2.764, I: 1.80\n",
      "Test  Corrects: Top-1: 84.59%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.067], Loss Comp: [C: 4.164, E: 2.764, I: 0.30], Losses [0: 1.81, 1: 0.59, 2: 0.41, 3: 0.54]Per Epoch: 4m,53s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 81.88%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 4.099, E: 2.764, I: 0.30\n",
      "Test  Corrects: Top-1: 78.15%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.067], Loss Comp: [C: 3.928, E: 2.791, I: 0.30], Losses [0: 1.19, 1: 0.61, 2: 0.39, 3: 0.4]Per Epoch: 4m,52s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 81.67%, Comp: 0.13, 1.07 4m,58s\n",
      "Train Loss Components: C: 3.683, E: 2.791, I: 0.30\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 83.67%, 13.35 s\n",
      "Post-prune Test  Corrects: Top-1: 83.67%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.056640625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.0606554662664548e-06\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 4.310, Losses [0: 3.69, 1: 1.65, 2: 0.99, 3: 3.04]Per Epoch: 3m,22s , Alloc: 5.13GiB   \n",
      "Train Corrects: Top-1: 69.06%, 3m,30s\n",
      "Test  Corrects: Top-1: 66.29%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.837, Losses [0: 3.52, 1: 1.24, 2: 0.81, 3: 1.72]Per Epoch: 3m,10s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 72.79%, 3m,30s\n",
      "Test  Corrects: Top-1: 71.51%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 2.418, Losses [0: 3.12, 1: 1.19, 2: 0.65, 3: 1.43]Per Epoch: 3m,24s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 76.14%, 3m,30s\n",
      "Test  Corrects: Top-1: 63.29%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 0.563, Losses [0: 1.44, 1: 0.41, 2: 0.16, 3: 0.16]Per Epoch: 3m,26s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 78.77%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 69.78%, 13.33 s\n",
      "Post-prune Test  Corrects: Top-1: 69.78%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.498, Losses [0: 1.17, 1: 0.95, 2: 0.48, 3: 0.98]Per Epoch: 3m,20s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 80.54%, 3m,30s\n",
      "Test  Corrects: Top-1: 78.01%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.202, Losses [0: 1.65, 1: 0.92, 2: 0.47, 3: 0.59]Per Epoch: 3m,9s  , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 83.87%, 3m,29s\n",
      "Test  Corrects: Top-1: 80.33%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.276, Losses [0: 1.71, 1: 0.66, 2: 0.45, 3: 0.71]Per Epoch: 3m,15s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 85.70%, 3m,30s\n",
      "Test  Corrects: Top-1: 85.77%, 13.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.785, Losses [0: 1.02, 1: 0.31, 2: 0.31, 3: 0.46]Per Epoch: 3m,24s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.09%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 87.35%, 13.34 s\n",
      "Post-prune Test  Corrects: Top-1: 87.35%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.067], Loss Comp: [C: 3.750, E: 2.842, I: 0.31], Losses [0: 0.6, 1: 0.45, 2: 0.3, 3: 0.33]Per Epoch: 5m,0s  , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 87.78%, Comp: 0.13, 1.07 4m,57s\n",
      "Train Loss Components: C: 4.809, E: 2.842, I: 0.31\n",
      "Test  Corrects: Top-1: 87.38%, 13.34 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 8.213, E: 2.876, I: 2.78], Losses [0: 2.98, 1: 1.52, 2: 0.76, 3: 1.5]Per Epoch: 4m,49s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 79.93%, Comp: 0.13, 1.60 4m,56s\n",
      "Train Loss Components: C: 10.601, E: 2.876, I: 2.78\n",
      "Test  Corrects: Top-1: 55.85%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 6.812, E: 2.848, I: 0.31], Losses [0: 3.04, 1: 1.13, 2: 0.6, 3: 2.7]Per Epoch: 4m,38s , Alloc: 5.26GiB     \n",
      "Train Corrects: Top-1: 66.78%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 8.411, E: 2.848, I: 0.31\n",
      "Test  Corrects: Top-1: 27.79%, 13.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 5.605, E: 2.848, I: 0.31], Losses [0: 2.98, 1: 1.04, 2: 0.66, 3: 1.51]Per Epoch: 4m,57s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 72.06%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 4.305, E: 2.848, I: 0.31\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 35.77%, 13.32 s\n",
      "Post-prune Test  Corrects: Top-1: 35.77%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 4.623, E: 2.848, I: 0.31], Losses [0: 2.24, 1: 0.84, 2: 0.49, 3: 0.75]Per Epoch: 4m,48s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 76.52%, Comp: 0.13, 1.33 4m,57s\n",
      "Train Loss Components: C: 5.758, E: 2.848, I: 1.55\n",
      "Test  Corrects: Top-1: 68.20%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 6.948, E: 2.876, I: 2.78], Losses [0: 1.75, 1: 0.87, 2: 0.54, 3: 0.66]Per Epoch: 4m,48s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 78.72%, Comp: 0.13, 1.40 4m,58s\n",
      "Train Loss Components: C: 5.864, E: 2.876, I: 1.85\n",
      "Test  Corrects: Top-1: 75.56%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 4.172, E: 2.876, I: 0.31], Losses [0: 1.29, 1: 0.64, 2: 0.39, 3: 0.52]Per Epoch: 4m,52s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 82.26%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 5.483, E: 2.876, I: 0.31\n",
      "Test  Corrects: Top-1: 82.83%, 13.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 3.972, E: 2.848, I: 0.31], Losses [0: 0.85, 1: 0.59, 2: 0.38, 3: 0.45]Per Epoch: 4m,44s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 83.86%, Comp: 0.13, 1.00 4m,57s\n",
      "Train Loss Components: C: 4.274, E: 2.848, I: 0.00\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,793 -> 2,998,793\n",
      "Pre-prune Test  Corrects: Top-1: 84.09%, 13.32 s\n",
      "Post-prune Test  Corrects: Top-1: 84.09%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.068359375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 7.954915996998411e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.809, Losses [0: 2.62, 1: 1.66, 2: 0.86, 3: 1.78]Per Epoch: 3m,26s , Alloc: 5.13GiB  \n",
      "Train Corrects: Top-1: 76.35%, 3m,29s\n",
      "Test  Corrects: Top-1: 58.78%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 3.392, Losses [0: 4.26, 1: 1.86, 2: 0.84, 3: 2.0]Per Epoch: 3m,14s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 72.83%, 3m,30s\n",
      "Test  Corrects: Top-1: 32.69%, 13.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 3.507, Losses [0: 4.15, 1: 1.37, 2: 0.7, 3: 2.26]Per Epoch: 3m,28s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 76.58%, 3m,30s\n",
      "Test  Corrects: Top-1: 68.02%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.338, Losses [0: 3.19, 1: 1.17, 2: 0.61, 3: 1.34]Per Epoch: 3m,16s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 78.61%, 3m,29s\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,998,793 -> 2,998,792\n",
      "Pre-prune Test  Corrects: Top-1: 77.74%, 13.35 s\n",
      "Post-prune Test  Corrects: Top-1: 77.74%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.362, Losses [0: 1.73, 1: 0.91, 2: 0.54, 3: 0.73]Per Epoch: 3m,25s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 81.35%, 3m,30s\n",
      "Test  Corrects: Top-1: 78.88%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.948, Losses [0: 1.46, 1: 0.61, 2: 0.29, 3: 0.47]Per Epoch: 3m,26s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 83.54%, 3m,30s\n",
      "Test  Corrects: Top-1: 82.08%, 13.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.527, Losses [0: 1.95, 1: 0.81, 2: 0.6, 3: 0.86]Per Epoch: 3m,26s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 85.58%, 3m,30s\n",
      "Test  Corrects: Top-1: 83.28%, 13.37 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.821, Losses [0: 1.13, 1: 0.4, 2: 0.37, 3: 0.44]Per Epoch: 3m,16s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.08%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,792 -> 2,998,792\n",
      "Pre-prune Test  Corrects: Top-1: 85.04%, 13.33 s\n",
      "Post-prune Test  Corrects: Top-1: 85.04%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 0.933], Loss Comp: [C: 3.855, E: 2.960, I: 0.29], Losses [0: 0.86, 1: 0.52, 2: 0.27, 3: 0.27]Per Epoch: 4m,50s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.49%, Comp: 0.13, 1.00 4m,57s\n",
      "Train Loss Components: C: 3.769, E: 2.960, I: 0.43\n",
      "Test  Corrects: Top-1: 87.89%, 13.32 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 2.267], Loss Comp: [C: 8.311, E: 2.960, I: 4.09], Losses [0: 1.79, 1: 0.71, 2: 0.39, 3: 0.69]Per Epoch: 4m,48s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 79.10%, Comp: 0.13, 2.27 4m,56s\n",
      "Train Loss Components: C: 10.902, E: 2.960, I: 4.09\n",
      "Test  Corrects: Top-1: 77.73%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.600], Loss Comp: [C: 7.218, E: 2.932, I: 2.93], Losses [0: 2.74, 1: 1.16, 2: 0.38, 3: 0.5]Per Epoch: 4m,48s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 79.82%, Comp: 0.13, 0.87 4m,58s\n",
      "Train Loss Components: C: 6.837, E: 2.932, I: 0.43\n",
      "Test  Corrects: Top-1: 78.54%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.127, I: 1.600], Loss Comp: [C: 7.370, E: 2.960, I: 2.93], Losses [0: 2.42, 1: 0.61, 2: 0.37, 3: 0.8]Per Epoch: 4m,44s , Alloc: 5.26GiB   \n",
      "Train Corrects: Top-1: 80.07%, Comp: 0.13, 0.87 4m,57s\n",
      "Train Loss Components: C: 6.733, E: 2.960, I: 0.43\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,792 -> 2,998,792\n",
      "Pre-prune Test  Corrects: Top-1: 49.77%, 13.31 s\n",
      "Post-prune Test  Corrects: Top-1: 49.77%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 0.867], Loss Comp: [C: 4.478, E: 2.912, I: 0.43], Losses [0: 1.55, 1: 0.79, 2: 0.42, 3: 0.58]Per Epoch: 4m,51s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 81.84%, Comp: 0.13, 0.87 4m,58s\n",
      "Train Loss Components: C: 4.806, E: 2.912, I: 0.43\n",
      "Test  Corrects: Top-1: 73.62%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 0.933], Loss Comp: [C: 3.842, E: 2.912, I: 0.29], Losses [0: 1.05, 1: 0.3, 2: 0.27, 3: 0.31]Per Epoch: 4m,49s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 84.26%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 3.390, E: 2.912, I: 0.29\n",
      "Test  Corrects: Top-1: 85.58%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 0.933], Loss Comp: [C: 4.398, E: 2.912, I: 0.29], Losses [0: 1.61, 1: 0.91, 2: 0.49, 3: 0.59]Per Epoch: 4m,51s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 86.28%, Comp: 0.12, 1.67 4m,58s\n",
      "Train Loss Components: C: 6.216, E: 2.877, I: 2.92\n",
      "Test  Corrects: Top-1: 84.91%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.333], Loss Comp: [C: 5.195, E: 2.941, I: 1.46], Losses [0: 1.05, 1: 0.62, 2: 0.39, 3: 0.38]Per Epoch: 4m,42s , Alloc: 5.26GiB  \n",
      "Train Corrects: Top-1: 87.58%, Comp: 0.13, 1.33 4m,57s\n",
      "Train Loss Components: C: 6.390, E: 2.941, I: 1.46\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,998,792 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 85.22%, 13.31 s\n",
      "Post-prune Test  Corrects: Top-1: 85.22%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.044921875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 5.966186997748809e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.853, Losses [0: 3.5, 1: 1.29, 2: 0.57, 3: 0.78]Per Epoch: 3m,25s , Alloc: 5.11GiB  \n",
      "Train Corrects: Top-1: 81.62%, 3m,28s\n",
      "Test  Corrects: Top-1: 76.73%, 13.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.868, Losses [0: 3.07, 1: 1.15, 2: 0.43, 3: 0.94]Per Epoch: 3m,23s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 78.49%, 3m,30s\n",
      "Test  Corrects: Top-1: 79.71%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.763, Losses [0: 2.79, 1: 1.27, 2: 0.53, 3: 0.85]Per Epoch: 3m,11s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 78.92%, 3m,29s\n",
      "Test  Corrects: Top-1: 76.63%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.664, Losses [0: 2.02, 1: 0.73, 2: 0.51, 3: 1.01]Per Epoch: 3m,15s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 81.29%, 3m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,791 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 81.37%, 13.34 s\n",
      "Post-prune Test  Corrects: Top-1: 81.37%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.704, Losses [0: 1.14, 1: 0.66, 2: 0.28, 3: 0.29]Per Epoch: 3m,21s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 83.54%, 3m,29s\n",
      "Test  Corrects: Top-1: 82.82%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.743, Losses [0: 1.58, 1: 0.53, 2: 0.24, 3: 0.27]Per Epoch: 3m,27s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 85.85%, 3m,30s\n",
      "Test  Corrects: Top-1: 86.90%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.711, Losses [0: 1.37, 1: 0.48, 2: 0.27, 3: 0.29]Per Epoch: 3m,22s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 87.76%, 3m,28s\n",
      "Test  Corrects: Top-1: 88.37%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.007, Losses [0: 1.46, 1: 0.58, 2: 0.45, 3: 0.51]Per Epoch: 3m,15s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.06%, 3m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,791 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 88.54%, 13.33 s\n",
      "Post-prune Test  Corrects: Top-1: 88.54%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 4.094, E: 3.016, I: 0.30], Losses [0: 1.39, 1: 0.45, 2: 0.35, 3: 0.34]Per Epoch: 4m,47s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.62%, Comp: 0.13, 1.33 4m,57s\n",
      "Train Loss Components: C: 5.429, E: 3.016, I: 1.50\n",
      "Test  Corrects: Top-1: 88.67%, 13.31 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 0.933], Loss Comp: [C: 5.407, E: 2.978, I: 0.30], Losses [0: 3.04, 1: 1.4, 2: 0.73, 3: 1.1]Per Epoch: 4m,32s , Alloc: 5.23GiB    \n",
      "Train Corrects: Top-1: 81.31%, Comp: 0.12, 1.33 4m,55s\n",
      "Train Loss Components: C: 6.818, E: 2.978, I: 1.50\n",
      "Test  Corrects: Top-1: 72.52%, 13.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.333], Loss Comp: [C: 6.194, E: 3.016, I: 1.50], Losses [0: 3.45, 1: 1.15, 2: 0.6, 3: 0.64]Per Epoch: 4m,38s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 81.48%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 3.600, E: 3.016, I: 0.30\n",
      "Test  Corrects: Top-1: 68.89%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 1.667], Loss Comp: [C: 7.407, E: 2.980, I: 3.00], Losses [0: 2.32, 1: 1.01, 2: 0.49, 3: 0.66]Per Epoch: 5m,2s  , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 82.12%, Comp: 0.13, 0.93 4m,58s\n",
      "Train Loss Components: C: 5.804, E: 2.980, I: 0.30\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,791 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 79.16%, 13.31 s\n",
      "Post-prune Test  Corrects: Top-1: 79.16%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.333], Loss Comp: [C: 5.678, E: 3.016, I: 1.50], Losses [0: 2.08, 1: 0.8, 2: 0.51, 3: 0.48]Per Epoch: 4m,55s , Alloc: 5.23GiB   \n",
      "Train Corrects: Top-1: 84.80%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 4.880, E: 2.980, I: 0.30\n",
      "Test  Corrects: Top-1: 80.98%, 13.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 3.969, E: 3.016, I: 0.30], Losses [0: 1.36, 1: 0.47, 2: 0.25, 3: 0.24]Per Epoch: 4m,54s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 86.09%, Comp: 0.13, 1.33 4m,57s\n",
      "Train Loss Components: C: 7.275, E: 3.016, I: 1.50\n",
      "Test  Corrects: Top-1: 84.47%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 4.041, E: 3.016, I: 0.30], Losses [0: 1.29, 1: 0.63, 2: 0.32, 3: 0.28]Per Epoch: 4m,37s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 88.01%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 5.220, E: 3.016, I: 0.30\n",
      "Test  Corrects: Top-1: 86.09%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 1.333], Loss Comp: [C: 5.138, E: 2.980, I: 1.50], Losses [0: 1.28, 1: 0.35, 2: 0.3, 3: 0.27]Per Epoch: 4m,39s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.17%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 3.793, E: 2.980, I: 0.30\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,791 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 87.10%, 13.34 s\n",
      "Post-prune Test  Corrects: Top-1: 87.10%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.056640625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 4.4746402483116066e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.615, Losses [0: 3.07, 1: 0.92, 2: 0.49, 3: 0.72]Per Epoch: 3m,19s , Alloc: 5.11GiB  \n",
      "Train Corrects: Top-1: 81.64%, 3m,29s\n",
      "Test  Corrects: Top-1: 79.49%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.713, Losses [0: 2.46, 1: 1.09, 2: 0.58, 3: 0.89]Per Epoch: 3m,25s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 80.38%, 3m,29s\n",
      "Test  Corrects: Top-1: 71.05%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.949, Losses [0: 2.31, 1: 1.44, 2: 0.55, 3: 1.09]Per Epoch: 3m,24s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 80.87%, 3m,29s\n",
      "Test  Corrects: Top-1: 71.14%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.340, Losses [0: 2.77, 1: 0.97, 2: 0.34, 3: 0.52]Per Epoch: 3m,17s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 82.71%, 3m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,791 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 72.18%, 13.31 s\n",
      "Post-prune Test  Corrects: Top-1: 72.18%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.039, Losses [0: 1.98, 1: 0.72, 2: 0.58, 3: 1.38]Per Epoch: 3m,15s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 84.38%, 3m,29s\n",
      "Test  Corrects: Top-1: 80.36%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.375, Losses [0: 2.07, 1: 1.04, 2: 0.49, 3: 0.66]Per Epoch: 3m,26s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 87.19%, 3m,29s\n",
      "Test  Corrects: Top-1: 86.18%, 13.34 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.780, Losses [0: 0.98, 1: 0.49, 2: 0.33, 3: 0.42]Per Epoch: 3m,24s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 88.47%, 3m,29s\n",
      "Test  Corrects: Top-1: 87.64%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.536, Losses [0: 1.16, 1: 0.39, 2: 0.2, 3: 0.19]Per Epoch: 3m,26s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.63%, 3m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,791 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 89.02%, 13.35 s\n",
      "Post-prune Test  Corrects: Top-1: 89.02%, 13.35 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.333], Loss Comp: [C: 4.991, E: 3.099, I: 1.54], Losses [0: 0.51, 1: 0.16, 2: 0.19, 3: 0.18]Per Epoch: 4m,52s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 90.20%, Comp: 0.13, 0.93 4m,57s\n",
      "Train Loss Components: C: 4.046, E: 3.099, I: 0.31\n",
      "Test  Corrects: Top-1: 89.41%, 13.29 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 0.933], Loss Comp: [C: 5.054, E: 3.099, I: 0.31], Losses [0: 2.48, 1: 0.96, 2: 0.53, 3: 0.85]Per Epoch: 4m,48s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 80.37%, Comp: 0.13, 0.93 4m,56s\n",
      "Train Loss Components: C: 5.910, E: 3.099, I: 0.31\n",
      "Test  Corrects: Top-1: 77.25%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.126, I: 1.333], Loss Comp: [C: 6.788, E: 3.099, I: 1.54], Losses [0: 3.52, 1: 1.65, 2: 0.61, 3: 0.99]Per Epoch: 4m,51s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 78.68%, Comp: 0.13, 0.93 4m,56s\n",
      "Train Loss Components: C: 8.489, E: 3.099, I: 0.31\n",
      "Test  Corrects: Top-1: 78.55%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 0.933], Loss Comp: [C: 4.908, E: 3.035, I: 0.31], Losses [0: 3.12, 1: 1.31, 2: 0.46, 3: 0.59]Per Epoch: 4m,45s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 80.52%, Comp: 0.12, 0.93 4m,57s\n",
      "Train Loss Components: C: 5.335, E: 3.035, I: 0.31\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,998,791 -> 2,998,791\n",
      "Pre-prune Test  Corrects: Top-1: 74.36%, 13.32 s\n",
      "Post-prune Test  Corrects: Top-1: 74.36%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 1.333], Loss Comp: [C: 5.624, E: 3.072, I: 1.54], Losses [0: 1.87, 1: 0.69, 2: 0.35, 3: 0.43]Per Epoch: 4m,53s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 83.76%, Comp: 0.13, 1.33 4m,57s\n",
      "Train Loss Components: C: 6.358, E: 3.072, I: 1.54\n",
      "Test  Corrects: Top-1: 78.95%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 1.333], Loss Comp: [C: 5.382, E: 3.035, I: 1.54], Losses [0: 1.45, 1: 0.6, 2: 0.32, 3: 0.33]Per Epoch: 4m,48s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 85.83%, Comp: 0.12, 1.33 4m,58s\n",
      "Train Loss Components: C: 9.181, E: 3.035, I: 1.54\n",
      "Test  Corrects: Top-1: 82.29%, 13.33 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 0.933], Loss Comp: [C: 3.953, E: 3.072, I: 0.31], Losses [0: 1.15, 1: 0.42, 2: 0.17, 3: 0.22]Per Epoch: 4m,46s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 88.11%, Comp: 0.13, 1.33 4m,56s\n",
      "Train Loss Components: C: 4.963, E: 3.072, I: 1.54\n",
      "Test  Corrects: Top-1: 87.11%, 13.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 1.333], Loss Comp: [C: 5.257, E: 3.072, I: 1.54], Losses [0: 1.21, 1: 0.42, 2: 0.27, 3: 0.26]Per Epoch: 4m,51s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.31%, Comp: 0.12, 1.33 4m,55s\n",
      "Train Loss Components: C: 4.965, E: 3.035, I: 1.54\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,998,791 -> 2,996,230\n",
      "Pre-prune Test  Corrects: Top-1: 85.30%, 13.30 s\n",
      "Post-prune Test  Corrects: Top-1: 85.30%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 5.037109375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 3.355980186233705e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.88GiB\n",
      "6: 3.97GiB\n",
      "7: 4.09GiB\n",
      "8: 4.36GiB\n",
      "9: 4.59GiB\n",
      "10: 4.66GiB\n",
      "11: 4.66GiB\n",
      "12: 4.66GiB\n",
      "13: 4.81GiB\n",
      "14: 4.93GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.277, Losses [0: 1.84, 1: 0.93, 2: 0.45, 3: 0.63]Per Epoch: 3m,25s , Alloc: 5.11GiB  \n",
      "Train Corrects: Top-1: 81.88%, 3m,29s\n",
      "Test  Corrects: Top-1: 64.94%, 13.28 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.156, Losses [0: 2.23, 1: 0.77, 2: 0.29, 3: 0.5]Per Epoch: 3m,16s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 78.12%, 3m,29s\n",
      "Test  Corrects: Top-1: 70.84%, 13.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.334, Losses [0: 2.71, 1: 1.06, 2: 0.49, 3: 0.48]Per Epoch: 3m,25s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 77.22%, 3m,29s\n",
      "Test  Corrects: Top-1: 60.53%, 13.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.341, Losses [0: 2.19, 1: 0.92, 2: 0.48, 3: 0.62]Per Epoch: 3m,23s , Alloc: 5.23GiB   \n",
      "Train Corrects: Top-1: 79.94%, 3m,29s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,996,230 -> 2,996,230\n",
      "Pre-prune Test  Corrects: Top-1: 78.36%, 13.29 s\n",
      "Post-prune Test  Corrects: Top-1: 78.36%, 13.29 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.980, Losses [0: 1.57, 1: 0.66, 2: 0.35, 3: 0.46]Per Epoch: 3m,17s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 84.36%, 3m,29s\n",
      "Test  Corrects: Top-1: 82.46%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.708, Losses [0: 1.26, 1: 0.3, 2: 0.33, 3: 0.33]Per Epoch: 3m,13s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 86.58%, 3m,28s\n",
      "Test  Corrects: Top-1: 85.00%, 13.32 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.530, Losses [0: 1.12, 1: 0.31, 2: 0.23, 3: 0.2]Per Epoch: 3m,9s  , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 88.17%, 3m,28s\n",
      "Test  Corrects: Top-1: 87.05%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.745, Losses [0: 1.42, 1: 0.34, 2: 0.33, 3: 0.33]Per Epoch: 3m,20s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.45%, 3m,30s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,996,230 -> 2,996,230\n",
      "Pre-prune Test  Corrects: Top-1: 88.54%, 13.36 s\n",
      "Post-prune Test  Corrects: Top-1: 88.54%, 13.36 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 0.933], Loss Comp: [C: 4.149, E: 3.155, I: 0.32], Losses [0: 0.84, 1: 0.33, 2: 0.39, 3: 0.36]Per Epoch: 4m,54s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.64%, Comp: 0.13, 1.33 5m,1s\n",
      "Train Loss Components: C: 5.719, E: 3.155, I: 1.58\n",
      "Test  Corrects: Top-1: 89.08%, 13.29 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 1.333], Loss Comp: [C: 6.035, E: 3.155, I: 1.58], Losses [0: 2.5, 1: 1.02, 2: 0.43, 3: 0.51]Per Epoch: 4m,42s , Alloc: 5.23GiB    \n",
      "Train Corrects: Top-1: 81.53%, Comp: 0.13, 0.93 4m,55s\n",
      "Train Loss Components: C: 4.883, E: 3.155, I: 0.32\n",
      "Test  Corrects: Top-1: 83.20%, 13.26 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 0.867], Loss Comp: [C: 5.028, E: 3.155, I: 0.47], Losses [0: 2.38, 1: 1.42, 2: 0.49, 3: 0.55]Per Epoch: 4m,33s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 80.93%, Comp: 0.13, 0.93 4m,56s\n",
      "Train Loss Components: C: 5.754, E: 3.155, I: 0.32\n",
      "Test  Corrects: Top-1: 82.22%, 13.25 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.125, I: 1.067], Loss Comp: [C: 5.348, E: 3.155, I: 0.76], Losses [0: 2.25, 1: 1.02, 2: 0.53, 3: 0.67]Per Epoch: 4m,51s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 82.10%, Comp: 0.13, 0.87 4m,57s\n",
      "Train Loss Components: C: 4.796, E: 3.155, I: 0.47\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,996,230 -> 2,996,230\n",
      "Pre-prune Test  Corrects: Top-1: 85.05%, 13.28 s\n",
      "Post-prune Test  Corrects: Top-1: 85.05%, 13.31 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.267], Loss Comp: [C: 6.246, E: 3.096, I: 1.62], Losses [0: 2.23, 1: 0.91, 2: 0.54, 3: 0.79]Per Epoch: 4m,48s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 83.95%, Comp: 0.12, 1.33 4m,55s\n",
      "Train Loss Components: C: 6.761, E: 3.096, I: 1.58\n",
      "Test  Corrects: Top-1: 85.37%, 13.26 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.333], Loss Comp: [C: 5.685, E: 3.096, I: 1.58], Losses [0: 1.76, 1: 0.78, 2: 0.35, 3: 0.43]Per Epoch: 4m,58s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 86.67%, Comp: 0.12, 1.33 4m,56s\n",
      "Train Loss Components: C: 5.707, E: 3.096, I: 1.58\n",
      "Test  Corrects: Top-1: 84.54%, 13.30 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 1.400], Loss Comp: [C: 5.417, E: 3.117, I: 1.62], Losses [0: 0.79, 1: 0.43, 2: 0.34, 3: 0.37]Per Epoch: 4m,47s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 88.83%, Comp: 0.12, 1.00 4m,56s\n",
      "Train Loss Components: C: 5.682, E: 3.117, I: 0.47\n",
      "Test  Corrects: Top-1: 88.82%, 13.24 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 1.400], Loss Comp: [C: 5.135, E: 3.117, I: 1.62], Losses [0: 0.88, 1: 0.28, 2: 0.17, 3: 0.13]Per Epoch: 5m,19s , Alloc: 5.23GiB  \n",
      "Train Corrects: Top-1: 89.58%, Comp: 0.12, 1.40 4m,57s\n",
      "Train Loss Components: C: 6.343, E: 3.117, I: 1.62\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,996,230 -> 2,960,389\n",
      "Pre-prune Test  Corrects: Top-1: 89.26%, 13.27 s\n",
      "Post-prune Test  Corrects: Top-1: 89.26%, 13.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.974609375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 2.5169851396752785e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.64GiB\n",
      "3: 2.36GiB\n",
      "4: 3.22GiB\n",
      "5: 3.80GiB\n",
      "6: 3.89GiB\n",
      "7: 4.01GiB\n",
      "8: 4.28GiB\n",
      "9: 4.51GiB\n",
      "10: 4.58GiB\n",
      "11: 4.58GiB\n",
      "12: 4.60GiB\n",
      "13: 4.76GiB\n",
      "14: 4.85GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 3.772, Losses [0: 3.75, 1: 1.85, 2: 0.77, 3: 2.5]Per Epoch: 3m,16s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 81.48%, 3m,26s\n",
      "Test  Corrects: Top-1: 80.14%, 13.16 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.603, Losses [0: 2.57, 1: 0.84, 2: 0.49, 3: 0.82]Per Epoch: 3m,24s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 77.18%, 3m,27s\n",
      "Test  Corrects: Top-1: 79.91%, 13.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.558, Losses [0: 2.18, 1: 1.41, 2: 0.37, 3: 0.77]Per Epoch: 3m,23s , Alloc: 5.17GiB   \n",
      "Train Corrects: Top-1: 78.07%, 3m,27s\n",
      "Test  Corrects: Top-1: 79.03%, 13.14 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 0.814, Losses [0: 1.39, 1: 0.54, 2: 0.26, 3: 0.38]Per Epoch: 3m,25s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 79.89%, 3m,25s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,960,389 -> 2,960,389\n",
      "Pre-prune Test  Corrects: Top-1: 82.85%, 13.18 s\n",
      "Post-prune Test  Corrects: Top-1: 82.85%, 13.18 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 0.968, Losses [0: 1.66, 1: 0.76, 2: 0.34, 3: 0.42]Per Epoch: 3m,13s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 83.10%, 3m,27s\n",
      "Test  Corrects: Top-1: 85.91%, 13.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 0.773, Losses [0: 1.8, 1: 0.66, 2: 0.25, 3: 0.23]Per Epoch: 3m,15s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 85.39%, 3m,26s\n",
      "Test  Corrects: Top-1: 86.30%, 13.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.400, Losses [0: 0.6, 1: 0.29, 2: 0.2, 3: 0.18]Per Epoch: 3m,22s , Alloc: 5.17GiB   \n",
      "Train Corrects: Top-1: 87.43%, 3m,26s\n",
      "Test  Corrects: Top-1: 88.18%, 13.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.807, Losses [0: 1.11, 1: 0.55, 2: 0.38, 3: 0.4]Per Epoch: 3m,16s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 88.85%, 3m,26s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,960,389 -> 2,960,389\n",
      "Pre-prune Test  Corrects: Top-1: 88.99%, 13.17 s\n",
      "Post-prune Test  Corrects: Top-1: 88.99%, 13.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 1.000], Loss Comp: [C: 6.428, E: 3.137, I: 0.48], Losses [0: 1.55, 1: 0.87, 2: 0.7, 3: 2.18]Per Epoch: 4m,32s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 89.30%, Comp: 0.12, 0.87 4m,53s\n",
      "Train Loss Components: C: 4.177, E: 3.177, I: 0.48\n",
      "Test  Corrects: Top-1: 88.33%, 13.15 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 0.867], Loss Comp: [C: 4.782, E: 3.199, I: 0.48], Losses [0: 2.52, 1: 0.57, 2: 0.34, 3: 0.42]Per Epoch: 4m,40s , Alloc: 5.17GiB   \n",
      "Train Corrects: Top-1: 81.34%, Comp: 0.12, 1.13 4m,54s\n",
      "Train Loss Components: C: 7.462, E: 3.199, I: 1.11\n",
      "Test  Corrects: Top-1: 83.03%, 13.16 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 0.867], Loss Comp: [C: 5.604, E: 3.199, I: 0.48], Losses [0: 2.29, 1: 0.78, 2: 0.4, 3: 1.23]Per Epoch: 4m,59s , Alloc: 5.17GiB    \n",
      "Train Corrects: Top-1: 79.34%, Comp: 0.12, 0.87 4m,54s\n",
      "Train Loss Components: C: 4.785, E: 3.199, I: 0.48\n",
      "Test  Corrects: Top-1: 75.73%, 13.14 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.124, I: 1.133], Loss Comp: [C: 5.274, E: 3.199, I: 1.11], Losses [0: 1.95, 1: 0.66, 2: 0.25, 3: 0.39]Per Epoch: 4m,31s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 79.64%, Comp: 0.12, 0.87 4m,54s\n",
      "Train Loss Components: C: 5.406, E: 3.199, I: 0.48\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,960,389 -> 2,960,389\n",
      "Pre-prune Test  Corrects: Top-1: 78.60%, 13.15 s\n",
      "Post-prune Test  Corrects: Top-1: 78.60%, 13.16 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 0.867], Loss Comp: [C: 10.568, E: 3.127, I: 0.48], Losses [0: 3.45, 1: 1.16, 2: 1.66, 3: 5.7]Per Epoch: 4m,34s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 81.64%, Comp: 0.12, 0.87 4m,53s\n",
      "Train Loss Components: C: 6.394, E: 3.127, I: 0.48\n",
      "Test  Corrects: Top-1: 51.48%, 13.15 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 0.933], Loss Comp: [C: 4.681, E: 3.160, I: 0.32], Losses [0: 1.75, 1: 0.79, 2: 0.51, 3: 0.59]Per Epoch: 4m,27s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 78.86%, Comp: 0.12, 1.33 4m,54s\n",
      "Train Loss Components: C: 5.252, E: 3.160, I: 1.63\n",
      "Test  Corrects: Top-1: 83.75%, 13.17 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 0.933], Loss Comp: [C: 4.512, E: 3.160, I: 0.32], Losses [0: 1.33, 1: 0.74, 2: 0.44, 3: 0.52]Per Epoch: 4m,44s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 85.49%, Comp: 0.12, 1.33 4m,53s\n",
      "Train Loss Components: C: 5.903, E: 3.160, I: 1.63\n",
      "Test  Corrects: Top-1: 86.84%, 13.16 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 0.933], Loss Comp: [C: 5.245, E: 3.160, I: 0.32], Losses [0: 1.38, 1: 0.7, 2: 0.65, 3: 1.21]Per Epoch: 4m,35s , Alloc: 5.17GiB  \n",
      "Train Corrects: Top-1: 87.25%, Comp: 0.12, 1.33 4m,54s\n",
      "Train Loss Components: C: 6.598, E: 3.160, I: 1.63\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,960,389 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 88.12%, 13.16 s\n",
      "Post-prune Test  Corrects: Top-1: 88.12%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.861328125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.8877388547564587e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.51GiB\n",
      "3: 2.23GiB\n",
      "4: 3.09GiB\n",
      "5: 3.67GiB\n",
      "6: 3.77GiB\n",
      "7: 3.88GiB\n",
      "8: 4.15GiB\n",
      "9: 4.38GiB\n",
      "10: 4.46GiB\n",
      "11: 4.46GiB\n",
      "12: 4.47GiB\n",
      "13: 4.63GiB\n",
      "14: 4.73GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 8.117, Losses [0: 5.89, 1: 3.54, 2: 1.79, 3: 5.87]Per Epoch: 3m,15s , Alloc: 4.92GiB   \n",
      "Train Corrects: Top-1: 65.19%, 3m,21s\n",
      "Test  Corrects: Top-1: 49.48%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.971, Losses [0: 3.83, 1: 1.97, 2: 0.93, 3: 1.63]Per Epoch: 3m,15s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 58.13%, 3m,22s\n",
      "Test  Corrects: Top-1: 68.36%, 12.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 4.219, Losses [0: 3.2, 1: 1.23, 2: 0.97, 3: 3.14]Per Epoch: 3m,20s , Alloc: 5.05GiB    \n",
      "Train Corrects: Top-1: 64.94%, 3m,22s\n",
      "Test  Corrects: Top-1: 57.62%, 12.99 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 3.616, Losses [0: 1.85, 1: 1.17, 2: 1.04, 3: 2.8]Per Epoch: 3m,9s  , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 67.57%, 3m,21s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 69.16%, 12.94 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-prune Test  Corrects: Top-1: 69.16%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.359, Losses [0: 1.93, 1: 0.88, 2: 0.45, 3: 0.71]Per Epoch: 3m,11s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 73.70%, 3m,22s\n",
      "Test  Corrects: Top-1: 68.51%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.636, Losses [0: 1.71, 1: 0.77, 2: 0.58, 3: 1.02]Per Epoch: 3m,6s  , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 78.06%, 3m,22s\n",
      "Test  Corrects: Top-1: 78.27%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.243, Losses [0: 2.15, 1: 0.86, 2: 0.53, 3: 0.54]Per Epoch: 3m,7s  , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 81.16%, 3m,22s\n",
      "Test  Corrects: Top-1: 80.26%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.401, Losses [0: 1.57, 1: 0.99, 2: 0.57, 3: 0.78]Per Epoch: 3m,7s  , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 82.63%, 3m,21s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 84.69%, 12.95 s\n",
      "Post-prune Test  Corrects: Top-1: 84.69%, 12.96 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 0.933], Loss Comp: [C: 4.199, E: 3.241, I: 0.33], Losses [0: 0.69, 1: 0.45, 2: 0.4, 3: 0.32]Per Epoch: 4m,34s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 83.79%, Comp: 0.12, 0.93 4m,49s\n",
      "Train Loss Components: C: 5.159, E: 3.241, I: 0.33\n",
      "Test  Corrects: Top-1: 85.51%, 12.92 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 0.933], Loss Comp: [C: 7.894, E: 3.241, I: 0.33], Losses [0: 3.07, 1: 1.85, 2: 0.85, 3: 3.17]Per Epoch: 4m,44s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 72.93%, Comp: 0.12, 0.93 4m,48s\n",
      "Train Loss Components: C: 5.567, E: 3.241, I: 0.33\n",
      "Test  Corrects: Top-1: 75.38%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 1.333], Loss Comp: [C: 8.199, E: 3.218, I: 1.67], Losses [0: 3.58, 1: 2.03, 2: 0.83, 3: 2.03]Per Epoch: 4m,33s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 70.41%, Comp: 0.12, 1.33 4m,47s\n",
      "Train Loss Components: C: 8.769, E: 3.218, I: 1.67\n",
      "Test  Corrects: Top-1: 73.55%, 12.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.333], Loss Comp: [C: 9.973, E: 3.198, I: 1.67], Losses [0: 2.89, 1: 1.7, 2: 1.15, 3: 3.96]Per Epoch: 4m,34s , Alloc: 5.05GiB     \n",
      "Train Corrects: Top-1: 44.77%, Comp: 0.12, 0.93 4m,48s\n",
      "Train Loss Components: C: 10.335, E: 3.198, I: 0.33\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 47.01%, 12.93 s\n",
      "Post-prune Test  Corrects: Top-1: 47.01%, 12.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 0.933], Loss Comp: [C: 8.543, E: 3.241, I: 0.33], Losses [0: 3.26, 1: 1.92, 2: 1.1, 3: 3.71]Per Epoch: 4m,37s , Alloc: 5.05GiB   \n",
      "Train Corrects: Top-1: 51.12%, Comp: 0.12, 0.93 4m,48s\n",
      "Train Loss Components: C: 11.042, E: 3.241, I: 0.33\n",
      "Test  Corrects: Top-1: 60.64%, 12.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 1.333], Loss Comp: [C: 9.733, E: 3.218, I: 1.67], Losses [0: 3.54, 1: 1.83, 2: 1.16, 3: 3.54]Per Epoch: 4m,33s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 59.04%, Comp: 0.12, 1.33 4m,49s\n",
      "Train Loss Components: C: 9.887, E: 3.218, I: 1.67\n",
      "Test  Corrects: Top-1: 62.88%, 12.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.133], Loss Comp: [C: 6.612, E: 3.241, I: 1.14], Losses [0: 2.08, 1: 1.25, 2: 0.88, 3: 1.39]Per Epoch: 4m,28s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 64.49%, Comp: 0.12, 0.87 4m,47s\n",
      "Train Loss Components: C: 6.724, E: 3.241, I: 0.49\n",
      "Test  Corrects: Top-1: 70.30%, 12.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.000], Loss Comp: [C: 6.039, E: 3.241, I: 0.49], Losses [0: 1.51, 1: 1.13, 2: 0.93, 3: 1.59]Per Epoch: 4m,54s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 68.77%, Comp: 0.12, 0.87 4m,48s\n",
      "Train Loss Components: C: 5.491, E: 3.241, I: 0.49\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 73.63%, 12.92 s\n",
      "Post-prune Test  Corrects: Top-1: 73.63%, 12.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.849609375, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.415804141067344e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.51GiB\n",
      "3: 2.23GiB\n",
      "4: 3.09GiB\n",
      "5: 3.67GiB\n",
      "6: 3.77GiB\n",
      "7: 3.88GiB\n",
      "8: 4.15GiB\n",
      "9: 4.38GiB\n",
      "10: 4.46GiB\n",
      "11: 4.46GiB\n",
      "12: 4.47GiB\n",
      "13: 4.63GiB\n",
      "14: 4.73GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 3.850, Losses [0: 3.81, 1: 2.27, 2: 0.85, 3: 2.46]Per Epoch: 3m,14s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 56.63%, 3m,22s\n",
      "Test  Corrects: Top-1: 63.13%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 4.307, Losses [0: 3.6, 1: 1.91, 2: 1.04, 3: 3.0]Per Epoch: 3m,7s  , Alloc: 5.05GiB   \n",
      "Train Corrects: Top-1: 59.30%, 3m,22s\n",
      "Test  Corrects: Top-1: 66.57%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 6.453, Losses [0: 4.51, 1: 2.13, 2: 1.23, 3: 4.88]Per Epoch: 3m,13s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 62.05%, 3m,22s\n",
      "Test  Corrects: Top-1: 68.43%, 12.97 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 6.208, Losses [0: 4.93, 1: 1.91, 2: 1.28, 3: 4.59]Per Epoch: 3m,23s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 66.04%, 3m,21s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 69.83%, 12.95 s\n",
      "Post-prune Test  Corrects: Top-1: 69.83%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 3.437, Losses [0: 3.56, 1: 1.63, 2: 0.89, 3: 2.22]Per Epoch: 3m,11s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 68.98%, 3m,22s\n",
      "Test  Corrects: Top-1: 73.39%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 3.717, Losses [0: 3.12, 1: 1.65, 2: 0.92, 3: 2.58]Per Epoch: 3m,12s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 72.05%, 3m,21s\n",
      "Test  Corrects: Top-1: 74.80%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.770, Losses [0: 1.83, 1: 1.16, 2: 0.63, 3: 1.05]Per Epoch: 3m,8s  , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 74.91%, 3m,21s\n",
      "Test  Corrects: Top-1: 78.52%, 12.96 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.880, Losses [0: 1.2, 1: 0.86, 2: 0.75, 3: 1.32]Per Epoch: 3m,18s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 77.42%, 3m,21s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 80.27%, 12.97 s\n",
      "Post-prune Test  Corrects: Top-1: 80.27%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 1.267], Loss Comp: [C: 6.208, E: 3.298, I: 1.75], Losses [0: 1.11, 1: 0.69, 2: 0.54, 3: 0.69]Per Epoch: 4m,43s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 78.87%, Comp: 0.12, 1.27 4m,49s\n",
      "Train Loss Components: C: 5.827, E: 3.298, I: 1.75\n",
      "Test  Corrects: Top-1: 81.31%, 12.94 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.867], Loss Comp: [C: 13.495, E: 3.322, I: 3.44], Losses [0: 3.51, 1: 1.35, 2: 1.2, 3: 5.52]Per Epoch: 4m,28s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 66.98%, Comp: 0.12, 1.40 4m,49s\n",
      "Train Loss Components: C: 12.762, E: 3.322, I: 1.75\n",
      "Test  Corrects: Top-1: 68.18%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.667], Loss Comp: [C: 9.957, E: 3.322, I: 2.53], Losses [0: 4.3, 1: 1.48, 2: 0.95, 3: 2.76]Per Epoch: 4m,37s , Alloc: 5.05GiB   \n",
      "Train Corrects: Top-1: 67.55%, Comp: 0.12, 1.27 4m,48s\n",
      "Train Loss Components: C: 7.577, E: 3.322, I: 1.75\n",
      "Test  Corrects: Top-1: 71.62%, 12.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 0.867], Loss Comp: [C: 6.911, E: 3.322, I: 0.51], Losses [0: 3.47, 1: 1.11, 2: 0.66, 3: 2.04]Per Epoch: 4m,47s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 70.18%, Comp: 0.12, 0.87 4m,49s\n",
      "Train Loss Components: C: 8.895, E: 3.322, I: 0.51\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 75.03%, 12.92 s\n",
      "Post-prune Test  Corrects: Top-1: 75.03%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.333], Loss Comp: [C: 6.949, E: 3.322, I: 1.71], Losses [0: 3.07, 1: 1.24, 2: 0.52, 3: 0.95]Per Epoch: 4m,40s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 72.54%, Comp: 0.12, 1.33 4m,48s\n",
      "Train Loss Components: C: 6.371, E: 3.322, I: 1.71\n",
      "Test  Corrects: Top-1: 76.68%, 12.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.333], Loss Comp: [C: 6.609, E: 3.322, I: 1.71], Losses [0: 2.53, 1: 1.3, 2: 0.57, 3: 0.7]Per Epoch: 4m,41s , Alloc: 5.05GiB   \n",
      "Train Corrects: Top-1: 75.39%, Comp: 0.12, 1.33 4m,49s\n",
      "Train Loss Components: C: 9.412, E: 3.322, I: 1.71\n",
      "Test  Corrects: Top-1: 79.58%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.333], Loss Comp: [C: 6.899, E: 3.322, I: 1.71], Losses [0: 2.61, 1: 1.29, 2: 0.74, 3: 0.94]Per Epoch: 4m,37s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 78.08%, Comp: 0.12, 1.33 4m,48s\n",
      "Train Loss Components: C: 6.689, E: 3.322, I: 1.71\n",
      "Test  Corrects: Top-1: 80.79%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.333], Loss Comp: [C: 6.213, E: 3.322, I: 1.71], Losses [0: 1.14, 1: 0.61, 2: 0.47, 3: 0.74]Per Epoch: 4m,32s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 79.92%, Comp: 0.12, 0.93 4m,48s\n",
      "Train Loss Components: C: 6.069, E: 3.322, I: 0.34\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 82.32%, 12.92 s\n",
      "Post-prune Test  Corrects: Top-1: 82.32%, 12.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.853515625, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 1.061853105800508e-07\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 78.00MiB\n",
      "1: 862.00MiB\n",
      "2: 1.51GiB\n",
      "3: 2.23GiB\n",
      "4: 3.09GiB\n",
      "5: 3.67GiB\n",
      "6: 3.77GiB\n",
      "7: 3.88GiB\n",
      "8: 4.15GiB\n",
      "9: 4.38GiB\n",
      "10: 4.46GiB\n",
      "11: 4.46GiB\n",
      "12: 4.47GiB\n",
      "13: 4.63GiB\n",
      "14: 4.73GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.928, Losses [0: 3.57, 1: 1.96, 2: 0.78, 3: 1.67]Per Epoch: 3m,16s , Alloc: 4.92GiB  \n",
      "Train Corrects: Top-1: 69.77%, 3m,22s\n",
      "Test  Corrects: Top-1: 74.28%, 12.97 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.077, Losses [0: 2.96, 1: 1.14, 2: 0.46, 3: 1.16]Per Epoch: 3m,16s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 70.67%, 3m,22s\n",
      "Test  Corrects: Top-1: 75.02%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 4.147, Losses [0: 5.05, 1: 2.68, 2: 1.04, 3: 2.39]Per Epoch: 3m,16s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 71.32%, 3m,22s\n",
      "Test  Corrects: Top-1: 74.41%, 12.99 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.574, Losses [0: 2.96, 1: 1.14, 2: 0.79, 3: 1.6]Per Epoch: 3m,2s  , Alloc: 5.05GiB   \n",
      "Train Corrects: Top-1: 72.25%, 3m,22s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 76.96%, 12.99 s\n",
      "Post-prune Test  Corrects: Top-1: 76.96%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.029, Losses [0: 2.77, 1: 1.3, 2: 0.65, 3: 1.08]Per Epoch: 3m,14s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 75.11%, 3m,22s\n",
      "Test  Corrects: Top-1: 79.56%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.471, Losses [0: 1.75, 1: 0.89, 2: 0.69, 3: 0.81]Per Epoch: 3m,15s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 78.12%, 3m,22s\n",
      "Test  Corrects: Top-1: 80.65%, 12.95 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.434, Losses [0: 1.68, 1: 0.91, 2: 0.61, 3: 0.79]Per Epoch: 3m,9s  , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 80.70%, 3m,21s\n",
      "Test  Corrects: Top-1: 80.92%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.923, Losses [0: 1.24, 1: 0.65, 2: 0.46, 3: 0.45]Per Epoch: 3m,6s  , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 82.11%, 3m,22s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 83.68%, 12.95 s\n",
      "Post-prune Test  Corrects: Top-1: 83.68%, 12.96 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.123, I: 1.333], Loss Comp: [C: 6.154, E: 3.403, I: 1.75], Losses [0: 1.37, 1: 0.73, 2: 0.48, 3: 0.49]Per Epoch: 4m,41s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 83.02%, Comp: 0.12, 0.93 4m,49s\n",
      "Train Loss Components: C: 4.999, E: 3.403, I: 0.35\n",
      "Test  Corrects: Top-1: 84.19%, 12.92 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 0.933], Loss Comp: [C: 6.178, E: 3.368, I: 0.35], Losses [0: 3.25, 1: 1.28, 2: 0.53, 3: 1.45]Per Epoch: 4m,35s , Alloc: 5.05GiB   \n",
      "Train Corrects: Top-1: 72.30%, Comp: 0.12, 0.93 4m,46s\n",
      "Train Loss Components: C: 8.641, E: 3.368, I: 0.35\n",
      "Test  Corrects: Top-1: 75.92%, 12.92 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 1.333], Loss Comp: [C: 6.851, E: 3.368, I: 1.75], Losses [0: 2.94, 1: 0.74, 2: 0.52, 3: 0.89]Per Epoch: 4m,45s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 70.80%, Comp: 0.12, 0.93 4m,47s\n",
      "Train Loss Components: C: 8.968, E: 3.368, I: 0.35\n",
      "Test  Corrects: Top-1: 76.16%, 12.96 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 1.333], Loss Comp: [C: 7.328, E: 3.368, I: 1.75], Losses [0: 2.88, 1: 1.59, 2: 0.64, 3: 1.19]Per Epoch: 4m,34s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 71.76%, Comp: 0.12, 0.93 4m,49s\n",
      "Train Loss Components: C: 5.408, E: 3.368, I: 0.35\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,950,660 -> 2,950,660\n",
      "Pre-prune Test  Corrects: Top-1: 75.07%, 12.93 s\n",
      "Post-prune Test  Corrects: Top-1: 75.07%, 12.93 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 0.933], Loss Comp: [C: 5.475, E: 3.343, I: 0.35], Losses [0: 3.38, 1: 1.21, 2: 0.57, 3: 0.75]Per Epoch: 4m,24s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 76.09%, Comp: 0.12, 0.93 4m,48s\n",
      "Train Loss Components: C: 5.492, E: 3.343, I: 0.35\n",
      "Test  Corrects: Top-1: 78.43%, 12.90 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 0.933], Loss Comp: [C: 4.812, E: 3.343, I: 0.35], Losses [0: 1.07, 1: 0.81, 2: 0.5, 3: 0.65]Per Epoch: 4m,38s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 78.92%, Comp: 0.12, 1.33 4m,48s\n",
      "Train Loss Components: C: 5.780, E: 3.343, I: 1.75\n",
      "Test  Corrects: Top-1: 78.12%, 12.94 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 0.933], Loss Comp: [C: 4.899, E: 3.368, I: 0.35], Losses [0: 1.68, 1: 0.89, 2: 0.48, 3: 0.57]Per Epoch: 4m,38s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 80.89%, Comp: 0.12, 1.33 4m,49s\n",
      "Train Loss Components: C: 6.381, E: 3.368, I: 1.75\n",
      "Test  Corrects: Top-1: 83.66%, 12.91 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 0.933], Loss Comp: [C: 5.527, E: 3.368, I: 0.35], Losses [0: 2.24, 1: 1.07, 2: 0.89, 3: 0.97]Per Epoch: 4m,48s , Alloc: 5.05GiB  \n",
      "Train Corrects: Top-1: 82.28%, Comp: 0.12, 1.33 4m,48s\n",
      "Train Loss Components: C: 5.584, E: 3.368, I: 1.75\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,950,660 -> 2,813,443\n",
      "Pre-prune Test  Corrects: Top-1: 84.16%, 12.93 s\n",
      "Post-prune Test  Corrects: Top-1: 84.16%, 12.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.8203125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 7.96389829350381e-08\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 76.00MiB\n",
      "1: 860.00MiB\n",
      "2: 1.51GiB\n",
      "3: 2.23GiB\n",
      "4: 3.09GiB\n",
      "5: 3.67GiB\n",
      "6: 3.77GiB\n",
      "7: 3.88GiB\n",
      "8: 4.15GiB\n",
      "9: 4.38GiB\n",
      "10: 4.45GiB\n",
      "11: 4.45GiB\n",
      "12: 4.45GiB\n",
      "13: 4.59GiB\n",
      "14: 4.71GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.974, Losses [0: 3.79, 1: 1.58, 2: 0.9, 3: 1.72]Per Epoch: 3m,9s  , Alloc: 4.88GiB    \n",
      "Train Corrects: Top-1: 69.12%, 3m,20s\n",
      "Test  Corrects: Top-1: 58.66%, 12.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.396, Losses [0: 3.62, 1: 1.4, 2: 0.48, 3: 1.3]Per Epoch: 3m,0s  , Alloc: 5.00GiB   \n",
      "Train Corrects: Top-1: 69.14%, 3m,20s\n",
      "Test  Corrects: Top-1: 69.31%, 12.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 4.458, Losses [0: 2.49, 1: 0.82, 2: 0.8, 3: 3.64]Per Epoch: 3m,13s , Alloc: 5.00GiB    \n",
      "Train Corrects: Top-1: 68.99%, 3m,20s\n",
      "Test  Corrects: Top-1: 71.29%, 12.87 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.973, Losses [0: 3.22, 1: 1.51, 2: 0.79, 3: 1.87]Per Epoch: 3m,15s , Alloc: 5.00GiB   \n",
      "Train Corrects: Top-1: 66.27%, 3m,20s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,813,443 -> 2,813,443\n",
      "Pre-prune Test  Corrects: Top-1: 67.03%, 12.86 s\n",
      "Post-prune Test  Corrects: Top-1: 67.03%, 12.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.955, Losses [0: 2.61, 1: 1.81, 2: 0.94, 3: 1.88]Per Epoch: 3m,4s  , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 69.60%, 3m,20s\n",
      "Test  Corrects: Top-1: 73.47%, 12.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.874, Losses [0: 2.17, 1: 0.98, 2: 0.68, 3: 1.11]Per Epoch: 3m,7s  , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 75.43%, 3m,20s\n",
      "Test  Corrects: Top-1: 80.32%, 12.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.106, Losses [0: 1.27, 1: 0.76, 2: 0.46, 3: 0.61]Per Epoch: 3m,9s  , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 78.06%, 3m,19s\n",
      "Test  Corrects: Top-1: 81.66%, 12.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 1.019, Losses [0: 0.82, 1: 0.53, 2: 0.42, 3: 0.66]Per Epoch: 3m,9s  , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 80.20%, 3m,20s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,813,443 -> 2,813,443\n",
      "Pre-prune Test  Corrects: Top-1: 83.08%, 12.88 s\n",
      "Post-prune Test  Corrects: Top-1: 83.08%, 12.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 1.333], Loss Comp: [C: 5.961, E: 3.448, I: 1.79], Losses [0: 0.78, 1: 0.56, 2: 0.36, 3: 0.38]Per Epoch: 4m,51s , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 81.33%, Comp: 0.12, 1.33 4m,47s\n",
      "Train Loss Components: C: 6.528, E: 3.448, I: 1.79\n",
      "Test  Corrects: Top-1: 83.32%, 12.85 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 0.933], Loss Comp: [C: 6.113, E: 3.448, I: 0.36], Losses [0: 3.83, 1: 1.71, 2: 0.57, 3: 1.08]Per Epoch: 4m,43s , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 71.15%, Comp: 0.12, 0.93 4m,46s\n",
      "Train Loss Components: C: 6.781, E: 3.448, I: 0.36\n",
      "Test  Corrects: Top-1: 74.36%, 12.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.121, I: 0.933], Loss Comp: [C: 7.536, E: 3.448, I: 0.36], Losses [0: 2.29, 1: 1.23, 2: 0.92, 3: 2.84]Per Epoch: 4m,42s , Alloc: 5.00GiB   \n",
      "Train Corrects: Top-1: 70.19%, Comp: 0.12, 0.93 4m,46s\n",
      "Train Loss Components: C: 7.381, E: 3.448, I: 0.36\n",
      "Test  Corrects: Top-1: 74.82%, 12.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.867], Loss Comp: [C: 8.739, E: 3.423, I: 3.60], Losses [0: 2.87, 1: 1.15, 2: 0.56, 3: 0.8]Per Epoch: 4m,26s , Alloc: 5.00GiB   \n",
      "Train Corrects: Top-1: 73.65%, Comp: 0.12, 1.87 4m,45s\n",
      "Train Loss Components: C: 8.195, E: 3.423, I: 3.60\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,813,443 -> 2,813,443\n",
      "Pre-prune Test  Corrects: Top-1: 74.79%, 12.84 s\n",
      "Post-prune Test  Corrects: Top-1: 74.79%, 12.88 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.119, I: 1.333], Loss Comp: [C: 6.627, E: 3.401, I: 1.79], Losses [0: 2.15, 1: 1.01, 2: 0.47, 3: 0.71]Per Epoch: 4m,29s , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 75.50%, Comp: 0.12, 1.33 4m,46s\n",
      "Train Loss Components: C: 7.529, E: 3.401, I: 1.79\n",
      "Test  Corrects: Top-1: 77.48%, 12.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.119, I: 1.333], Loss Comp: [C: 6.795, E: 3.401, I: 1.79], Losses [0: 2.44, 1: 1.08, 2: 0.72, 3: 0.75]Per Epoch: 4m,47s , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 78.61%, Comp: 0.12, 0.93 4m,47s\n",
      "Train Loss Components: C: 5.575, E: 3.423, I: 0.36\n",
      "Test  Corrects: Top-1: 81.77%, 12.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.119, I: 1.333], Loss Comp: [C: 6.296, E: 3.401, I: 1.79], Losses [0: 1.59, 1: 0.97, 2: 0.56, 3: 0.48]Per Epoch: 4m,33s , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 81.02%, Comp: 0.12, 1.33 4m,46s\n",
      "Train Loss Components: C: 6.342, E: 3.401, I: 1.79\n",
      "Test  Corrects: Top-1: 83.22%, 12.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.119, I: 0.933], Loss Comp: [C: 4.791, E: 3.401, I: 0.36], Losses [0: 1.33, 1: 0.75, 2: 0.46, 3: 0.53]Per Epoch: 4m,29s , Alloc: 5.00GiB  \n",
      "Train Corrects: Top-1: 82.24%, Comp: 0.12, 0.93 4m,46s\n",
      "Train Loss Components: C: 4.865, E: 3.401, I: 0.36\n",
      "\n",
      "Deadheaded 1 operations\n",
      "Param Delta: 2,813,443 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 84.30%, 12.85 s\n",
      "Post-prune Test  Corrects: Top-1: 84.30%, 12.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.8046875, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 5.972923720127858e-08\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 76.00MiB\n",
      "1: 860.00MiB\n",
      "2: 1.51GiB\n",
      "3: 2.23GiB\n",
      "4: 3.09GiB\n",
      "5: 3.67GiB\n",
      "6: 3.77GiB\n",
      "7: 3.88GiB\n",
      "8: 4.15GiB\n",
      "9: 4.38GiB\n",
      "10: 4.45GiB\n",
      "11: 4.45GiB\n",
      "12: 4.45GiB\n",
      "13: 4.59GiB\n",
      "14: 4.69GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.133, Losses [0: 2.3, 1: 1.43, 2: 0.6, 3: 1.27]Per Epoch: 3m,7s  , Alloc: 4.86GiB   \n",
      "Train Corrects: Top-1: 72.72%, 3m,20s\n",
      "Test  Corrects: Top-1: 74.72%, 12.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 2.782, Losses [0: 3.62, 1: 1.4, 2: 0.67, 3: 1.65]Per Epoch: 3m,15s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 70.08%, 3m,20s\n",
      "Test  Corrects: Top-1: 74.70%, 12.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 1.838, Losses [0: 1.94, 1: 1.13, 2: 0.57, 3: 1.11]Per Epoch: 3m,9s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 70.41%, 3m,20s\n",
      "Test  Corrects: Top-1: 76.32%, 12.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 2.010, Losses [0: 2.84, 1: 1.32, 2: 0.47, 3: 1.08]Per Epoch: 3m,14s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 73.12%, 3m,20s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 74.09%, 12.81 s\n",
      "Post-prune Test  Corrects: Top-1: 74.09%, 12.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 2.083, Losses [0: 2.22, 1: 1.0, 2: 0.57, 3: 1.32]Per Epoch: 3m,3s  , Alloc: 4.98GiB   \n",
      "Train Corrects: Top-1: 75.06%, 3m,20s\n",
      "Test  Corrects: Top-1: 78.76%, 12.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.884, Losses [0: 1.96, 1: 1.22, 2: 0.73, 3: 1.1]Per Epoch: 3m,4s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 76.39%, 3m,20s\n",
      "Test  Corrects: Top-1: 78.49%, 12.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 1.185, Losses [0: 1.73, 1: 0.75, 2: 0.6, 3: 0.57]Per Epoch: 3m,8s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 79.34%, 3m,19s\n",
      "Test  Corrects: Top-1: 81.83%, 12.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.996, Losses [0: 1.26, 1: 0.63, 2: 0.53, 3: 0.51]Per Epoch: 3m,3s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 81.14%, 3m,19s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 82.94%, 12.84 s\n",
      "Post-prune Test  Corrects: Top-1: 82.94%, 12.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.333], Loss Comp: [C: 6.573, E: 3.502, I: 1.83], Losses [0: 1.17, 1: 0.73, 2: 0.62, 3: 0.73]Per Epoch: 4m,24s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 82.24%, Comp: 0.12, 0.93 4m,46s\n",
      "Train Loss Components: C: 4.850, E: 3.502, I: 0.37\n",
      "Test  Corrects: Top-1: 83.27%, 12.82 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.467], Loss Comp: [C: 8.348, E: 3.502, I: 2.00], Losses [0: 3.68, 1: 1.79, 2: 0.89, 3: 1.58]Per Epoch: 4m,37s , Alloc: 4.98GiB   \n",
      "Train Corrects: Top-1: 69.05%, Comp: 0.12, 1.27 4m,46s\n",
      "Train Loss Components: C: 7.778, E: 3.502, I: 1.88\n",
      "Test  Corrects: Top-1: 69.67%, 12.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.467], Loss Comp: [C: 8.069, E: 3.502, I: 2.00], Losses [0: 3.2, 1: 1.43, 2: 0.69, 3: 1.5]Per Epoch: 4m,29s , Alloc: 4.98GiB     \n",
      "Train Corrects: Top-1: 66.94%, Comp: 0.12, 1.27 4m,45s\n",
      "Train Loss Components: C: 10.704, E: 3.502, I: 1.88\n",
      "Test  Corrects: Top-1: 73.27%, 12.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 0.867], Loss Comp: [C: 6.833, E: 3.502, I: 0.54], Losses [0: 2.31, 1: 0.68, 2: 0.53, 3: 2.08]Per Epoch: 4m,24s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 71.66%, Comp: 0.12, 1.40 4m,46s\n",
      "Train Loss Components: C: 18.278, E: 3.502, I: 2.82\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 71.91%, 12.80 s\n",
      "Post-prune Test  Corrects: Top-1: 71.91%, 12.82 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.600], Loss Comp: [C: 8.471, E: 3.502, I: 2.43], Losses [0: 2.89, 1: 1.59, 2: 0.89, 3: 1.46]Per Epoch: 4m,44s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 72.77%, Comp: 0.12, 0.93 4m,45s\n",
      "Train Loss Components: C: 5.860, E: 3.502, I: 0.37\n",
      "Test  Corrects: Top-1: 76.59%, 12.80 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.267], Loss Comp: [C: 8.684, E: 3.502, I: 1.88], Losses [0: 1.57, 1: 1.06, 2: 0.76, 3: 2.63]Per Epoch: 4m,29s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 76.38%, Comp: 0.12, 0.87 4m,46s\n",
      "Train Loss Components: C: 6.046, E: 3.502, I: 0.54\n",
      "Test  Corrects: Top-1: 74.41%, 12.82 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.333], Loss Comp: [C: 6.355, E: 3.502, I: 1.83], Losses [0: 0.94, 1: 0.61, 2: 0.44, 3: 0.62]Per Epoch: 4m,22s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 78.38%, Comp: 0.12, 0.93 4m,46s\n",
      "Train Loss Components: C: 6.312, E: 3.502, I: 0.37\n",
      "Test  Corrects: Top-1: 81.64%, 12.82 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 0.933], Loss Comp: [C: 4.646, E: 3.502, I: 0.37], Losses [0: 0.77, 1: 0.49, 2: 0.43, 3: 0.44]Per Epoch: 4m,36s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 81.06%, Comp: 0.12, 1.33 4m,44s\n",
      "Train Loss Components: C: 6.154, E: 3.502, I: 1.83\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 82.37%, 12.83 s\n",
      "Post-prune Test  Corrects: Top-1: 82.37%, 12.83 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.80078125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 4.479692790095893e-08\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 76.00MiB\n",
      "1: 860.00MiB\n",
      "2: 1.51GiB\n",
      "3: 2.23GiB\n",
      "4: 3.09GiB\n",
      "5: 3.67GiB\n",
      "6: 3.77GiB\n",
      "7: 3.88GiB\n",
      "8: 4.15GiB\n",
      "9: 4.38GiB\n",
      "10: 4.45GiB\n",
      "11: 4.45GiB\n",
      "12: 4.45GiB\n",
      "13: 4.59GiB\n",
      "14: 4.69GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 2.822, Losses [0: 2.55, 1: 1.23, 2: 0.66, 3: 1.94]Per Epoch: 3m,14s , Alloc: 4.86GiB   \n",
      "Train Corrects: Top-1: 66.18%, 3m,19s\n",
      "Test  Corrects: Top-1: 73.21%, 12.84 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 1   [49984 /50000  (100%)]\tLoss: 1.995, Losses [0: 3.25, 1: 1.59, 2: 0.55, 3: 0.92]Per Epoch: 3m,5s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 71.43%, 3m,20s\n",
      "Test  Corrects: Top-1: 73.71%, 12.82 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 2   [49984 /50000  (100%)]\tLoss: 4.872, Losses [0: 4.83, 1: 1.77, 2: 1.14, 3: 3.32]Per Epoch: 3m,5s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 72.92%, 3m,19s\n",
      "Test  Corrects: Top-1: 67.20%, 12.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n",
      "Train Epoch: 3   [49984 /50000  (100%)]\tLoss: 1.746, Losses [0: 2.5, 1: 1.37, 2: 0.6, 3: 0.85]Per Epoch: 3m,13s , Alloc: 4.98GiB   \n",
      "Train Corrects: Top-1: 74.73%, 3m,20s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 77.18%, 12.87 s\n",
      "Post-prune Test  Corrects: Top-1: 77.18%, 12.85 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 4   [49984 /50000  (100%)]\tLoss: 1.765, Losses [0: 2.17, 1: 1.33, 2: 0.6, 3: 0.94]Per Epoch: 3m,1s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 76.70%, 3m,20s\n",
      "Test  Corrects: Top-1: 79.19%, 12.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 5   [49984 /50000  (100%)]\tLoss: 1.882, Losses [0: 1.76, 1: 0.99, 2: 0.64, 3: 1.2]Per Epoch: 3m,4s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 79.20%, 3m,20s\n",
      "Test  Corrects: Top-1: 80.98%, 12.90 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 6   [49984 /50000  (100%)]\tLoss: 0.782, Losses [0: 1.26, 1: 0.52, 2: 0.33, 3: 0.36]Per Epoch: 3m,5s  , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 81.68%, 3m,20s\n",
      "Test  Corrects: Top-1: 82.75%, 12.89 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 7   [49984 /50000  (100%)]\tLoss: 0.826, Losses [0: 0.9, 1: 0.59, 2: 0.45, 3: 0.44]Per Epoch: 3m,15s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 82.95%, 3m,20s\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 84.33%, 12.88 s\n",
      "Post-prune Test  Corrects: Top-1: 84.33%, 12.88 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Train Epoch: 8   [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.333], Loss Comp: [C: 6.014, E: 3.582, I: 1.88], Losses [0: 0.81, 1: 0.47, 2: 0.33, 3: 0.24]Per Epoch: 4m,46s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 83.79%, Comp: 0.12, 1.33 4m,46s\n",
      "Train Loss Components: C: 6.974, E: 3.582, I: 1.88\n",
      "Test  Corrects: Top-1: 84.52%, 12.85 s\n",
      "\n",
      "\u001b[31mRestarting Learning Rate, setting new cycle length to 8\u001b[0m\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.01\u001b[0m\n",
      "Train Epoch: 9   [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 0.867], Loss Comp: [C: 8.575, E: 3.582, I: 0.55], Losses [0: 3.07, 1: 1.54, 2: 1.27, 3: 3.26]Per Epoch: 4m,44s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 74.02%, Comp: 0.12, 1.73 4m,45s\n",
      "Train Loss Components: C: 9.201, E: 3.582, I: 3.09\n",
      "Test  Corrects: Top-1: 72.86%, 12.81 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.009619397662556433\u001b[0m\n",
      "Train Epoch: 10  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 0.867], Loss Comp: [C: 6.476, E: 3.582, I: 0.55], Losses [0: 3.34, 1: 1.35, 2: 0.75, 3: 1.25]Per Epoch: 4m,33s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 71.42%, Comp: 0.12, 1.33 4m,47s\n",
      "Train Loss Components: C: 9.538, E: 3.582, I: 2.48\n",
      "Test  Corrects: Top-1: 77.23%, 12.86 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.008535533905932738\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11  [49984 /50000  (100%)]\tComp Ratio: [E: 0.119, I: 0.867], Loss Comp: [C: 5.437, E: 3.539, I: 0.55], Losses [0: 1.89, 1: 0.86, 2: 0.57, 3: 0.68]Per Epoch: 4m,36s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 75.39%, Comp: 0.12, 0.87 4m,46s\n",
      "Train Loss Components: C: 6.979, E: 3.582, I: 0.55\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 80.45%, 12.82 s\n",
      "Post-prune Test  Corrects: Top-1: 80.45%, 12.82 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.00691341716182545\u001b[0m\n",
      "Train Epoch: 12  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 1.267], Loss Comp: [C: 7.030, E: 3.582, I: 1.92], Losses [0: 2.36, 1: 1.06, 2: 0.55, 3: 0.74]Per Epoch: 4m,42s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 77.50%, Comp: 0.12, 1.73 4m,51s\n",
      "Train Loss Components: C: 8.375, E: 3.582, I: 3.09\n",
      "Test  Corrects: Top-1: 80.83%, 13.59 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.005\u001b[0m\n",
      "Train Epoch: 13  [49984 /50000  (100%)]\tComp Ratio: [E: 0.119, I: 1.267], Loss Comp: [C: 6.844, E: 3.531, I: 1.92], Losses [0: 1.39, 1: 0.62, 2: 0.59, 3: 0.87]Per Epoch: 4m,48s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 80.57%, Comp: 0.12, 1.27 5m,3s\n",
      "Train Loss Components: C: 9.527, E: 3.531, I: 1.92\n",
      "Test  Corrects: Top-1: 82.46%, 13.27 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0030865828381745515\u001b[0m\n",
      "Train Epoch: 14  [49984 /50000  (100%)]\tComp Ratio: [E: 0.120, I: 0.867], Loss Comp: [C: 5.289, E: 3.582, I: 0.55], Losses [0: 1.45, 1: 0.76, 2: 0.56, 3: 0.6]Per Epoch: 4m,52s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 82.40%, Comp: 0.12, 1.40 5m,1s\n",
      "Train Loss Components: C: 6.302, E: 3.555, I: 1.92\n",
      "Test  Corrects: Top-1: 83.58%, 13.53 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0014644660940672626\u001b[0m\n",
      "Train Epoch: 15  [49984 /50000  (100%)]\tComp Ratio: [E: 0.119, I: 0.867], Loss Comp: [C: 4.984, E: 3.531, I: 0.55], Losses [0: 1.17, 1: 0.68, 2: 0.47, 3: 0.43]Per Epoch: 4m,46s , Alloc: 4.98GiB  \n",
      "Train Corrects: Top-1: 83.54%, Comp: 0.12, 1.00 5m,2s\n",
      "Train Loss Components: C: 5.219, E: 3.531, I: 0.55\n",
      "\n",
      "Deadheaded 0 operations\n",
      "Param Delta: 2,812,930 -> 2,812,930\n",
      "Pre-prune Test  Corrects: Top-1: 84.62%, 13.67 s\n",
      "Post-prune Test  Corrects: Top-1: 84.62%, 13.50 s\n",
      "\n",
      "\u001b[31mAdjusting lr to 0.0003806023374435663\u001b[0m\n",
      "Est size: 4.80078125, Batch: 64\n",
      "Restarting pruning at scale level 6, new comp ratio: 3.35976959257192e-08\n",
      "=== Training Carlton McClure Banbury ===\n",
      "0: 76.00MiB\n",
      "1: 860.00MiB\n",
      "2: 1.51GiB\n",
      "3: 2.23GiB\n",
      "4: 3.09GiB\n",
      "5: 3.67GiB\n",
      "6: 3.77GiB\n",
      "7: 3.88GiB\n",
      "8: 4.15GiB\n",
      "9: 4.38GiB\n",
      "10: 4.45GiB\n",
      "11: 4.45GiB\n",
      "12: 4.45GiB\n",
      "13: 4.59GiB\n",
      "14: 4.69GiB\n",
      "Train Epoch: 0   [49984 /50000  (100%)]\tLoss: 1.668, Losses [0: 3.47, 1: 1.53, 2: 0.53, 3: 0.56]Per Epoch: 3m,22s , Alloc: 4.86GiB   \n",
      "Train Corrects: Top-1: 76.66%, 3m,29s\n"
     ]
    }
   ],
   "source": [
    "if search:\n",
    "    prev_output() if not init_or_finish else wipe_output()\n",
    "    search_start = time.time()\n",
    "    \n",
    "    # search parameters\n",
    "    schedule = {'cycle_len':4,\n",
    "                'transition_after':2,\n",
    "                'n_cycles':4}\n",
    "    epochs = schedule['cycle_len']*schedule['n_cycles']\n",
    "    transition = schedule['cycle_len']*schedule['transition_after']\n",
    "    lr_schedule = {'lr_min': hypers['lr_schedule']['lr_min'],\n",
    "                   'lr_max': hypers['lr_schedule']['lr_max'],\n",
    "                   't_0': transition,\n",
    "                   't_mult': 1}    \n",
    "    # search loop\n",
    "    for scaling in range(hypers['scale']['init'],hypers['scale']['final']):\n",
    "        tries = 1\n",
    "        while 1:\n",
    "            init_or_finish = full_train(\n",
    "                model,\n",
    "                data,\n",
    "                resume=not init_or_finish,\n",
    "                epochs=epochs,\n",
    "                drop_prob=0,\n",
    "                comp_lambdas=TransitionDict({0: None,\n",
    "                                             transition: {'edge': .15*tries, 'input': .1*tries}}),\n",
    "                comp_ratio=comp_ratio,\n",
    "                prune_interval=schedule['cycle_len'],\n",
    "                lr_schedule=lr_schedule\n",
    "            );\n",
    "            clean(verbose=False)\n",
    "            size, overflow = size_test(model,data)\n",
    "            print(\"Est size: {}, Batch: {}\".format(size,batch_size))\n",
    "            if size > gpu_space/2 and batch_size==hypers['batch_size']['final']:\n",
    "                comp_ratio*=.75 \n",
    "                tries+=1\n",
    "                print(\"Restarting pruning at scale level {}, new comp ratio: {}\".format(scaling,comp_ratio))\n",
    "            elif size>(gpu_space/2) and batch_size>hypers['batch_size']['final']:\n",
    "                batch_size=batch_size//2\n",
    "                data, data_shape  = load_data(batch_size,dataset)\n",
    "                print(\"Lowering batch size to {} for scaling\".format(batch_size))\n",
    "                break\n",
    "            else:\n",
    "                break   \n",
    "\n",
    "        if init_or_finish:\n",
    "            model.save_genotype()\n",
    "            clean(\"Prescale\")\n",
    "            model.scale_up()\n",
    "            model_id = model.model_id\n",
    "        else:\n",
    "            clean()\n",
    "            break\n",
    "    print(\"Search Time:\",show_time(time.time()-search_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_shape = load_data(hypers['batch_size']['final'], dataset)\n",
    "params, genotype = pkl.load(open('genotypes/genotype_{}.pkl'.format(name.replace(\" \",\"_\")),'rb'))\n",
    "\n",
    "params['genotype']=genotype\n",
    "params['scale']=hypers['scale']['final']\n",
    "params['prune']=False\n",
    "params['auxiliary']=True\n",
    "params['dim']=data_shape\n",
    "model = Net(**params)\n",
    "print(model)\n",
    "\n",
    "init_or_finish = True\n",
    "size_test(model,data)\n",
    "actual_comp_ratio = model.genotype_compression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev_output() if not init_or_finish else wipe_output()\n",
    "init_or_finish = full_train(\n",
    "    model, data,\n",
    "    lr_schedule = hypers['lr_schedule'],\n",
    "    resume=not init_or_finish,\n",
    "    epochs=hypers['epochs'],\n",
    "    drop_prob=hypers['drop_prob'],\n",
    ");\n",
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,data_shape = load_data(hypers['batch_size']['final'], dataset)\n",
    "model = Net(dim=data_shape, \n",
    "            classes=classes, \n",
    "            scale=hypers['scale']['final'],\n",
    "            reductions=hypers['reductions'], \n",
    "            spacing=hypers['spacing'],\n",
    "            nodes=hypers['nodes'],\n",
    "            random_ops=actual_comp_ratio, \n",
    "            prune=False,\n",
    "            auxiliary=True)\n",
    "model.save_genotype()\n",
    "print(model)\n",
    "print(size_test(model,data))\n",
    "model.genotype_compression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train(\n",
    "    model, data,\n",
    "    lr_schedule = hypers['lr_schedule'],\n",
    "    epochs=hypers['epochs'],\n",
    "    drop_prob=hypers['drop_prob'],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
